{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Feature Rich Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train dataset...\n",
      "Reading data...\n",
      "Downloading val dataset...\n",
      "Reading data...\n",
      "Data loaded!\n",
      "Train Data Shape: (891, 128000)\n"
     ]
    }
   ],
   "source": [
    "import HelperFuncs as hfuncs\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "#Bucket with clean data\n",
    "key_id, secret_key = hfuncs.GetAWSCredentials()\n",
    "client = hfuncs.GetAWSClient(key_id,secret_key)\n",
    "bucket = client.Bucket(hfuncs.CLEAN_DATA_BUCKET)\n",
    "\n",
    "# Grab train data\n",
    "# Download dataset\n",
    "print(\"Downloading train dataset...\")\n",
    "mode = 'train'\n",
    "key_suffix = \"{}_data.hdf5\".format(mode)\n",
    "filename = os.path.join(hfuncs.TEMP_DIR,key_suffix)\n",
    "key = \"{}/{}\".format(hfuncs.CLEAN_DATA_DIR,key_suffix)\n",
    "\n",
    "bucket.download_file(Key=key,Filename=filename)\n",
    "\n",
    "# Open downloaded file and load data\n",
    "with h5py.File(filename,\"r\") as f:    \n",
    "    #Get train data\n",
    "    print(\"Reading data...\")\n",
    "    \n",
    "    d = f['/features']\n",
    "    X_train = d[:]\n",
    "  \n",
    "    d = f['/labels']\n",
    "    y_train = d[:]\n",
    "\n",
    "# Grab val data\n",
    "# Download dataset\n",
    "print(\"Downloading val dataset...\")\n",
    "mode = 'val'\n",
    "key_suffix = \"{}_data.hdf5\".format(mode)\n",
    "filename = os.path.join(hfuncs.TEMP_DIR,key_suffix)\n",
    "key = \"{}/{}\".format(hfuncs.CLEAN_DATA_DIR,key_suffix)\n",
    "\n",
    "\n",
    "bucket.download_file(Key=key,Filename=filename)\n",
    "    \n",
    "# Open downloaded file and load data\n",
    "with h5py.File(filename,\"r\") as f:    \n",
    "    #Get train data\n",
    "    print(\"Reading data...\")\n",
    "    \n",
    "    d = f['/features']\n",
    "    X_val = d[:]\n",
    "  \n",
    "    d = f['/labels']\n",
    "    y_val = d[:]\n",
    "    \n",
    "print(\"Data loaded!\")\n",
    "print(\"Train Data Shape:\",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 Total Samples.\n",
      "544.0 Total positives, corresponding to 61.1% of the data\n"
     ]
    }
   ],
   "source": [
    "print(\"{} Total Samples.\".format(len(y_train)))\n",
    "print(\"{0} Total positives, corresponding to {1:.1f}% of the data\".format(sum(y_train),sum(y_train)*100/len(y_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Balance classes\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train,y_train = ros.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088 Total Samples.\n",
      "544.0 Total positives, corresponding to 50.0% of the data\n"
     ]
    }
   ],
   "source": [
    "print(\"{} Total Samples.\".format(len(y_train)))\n",
    "print(\"{0} Total positives, corresponding to {1:.1f}% of the data\".format(sum(y_train),sum(y_train)*100/len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.3087           0.0532           20.60m\n",
      "         2           1.2422           0.0422           20.39m\n",
      "         3           1.1833           0.0363           20.23m\n",
      "         4           1.1365           0.0312           19.99m\n",
      "         5           1.0864           0.0277           19.79m\n",
      "         6           1.0531           0.0306           19.58m\n",
      "         7           1.0193           0.0229           19.35m\n",
      "         8           0.9802           0.0239           19.13m\n",
      "         9           0.9554           0.0150           18.93m\n",
      "        10           0.9079           0.0110           18.72m\n",
      "        11           0.8877           0.0166           18.48m\n",
      "        12           0.8581           0.0127           18.29m\n",
      "        13           0.8419           0.0133           18.06m\n",
      "        14           0.8177           0.0124           17.85m\n",
      "        15           0.7813           0.0086           17.65m\n",
      "        16           0.7614           0.0124           17.48m\n",
      "        17           0.7317           0.0066           17.28m\n",
      "        18           0.7207           0.0065           17.06m\n",
      "        19           0.6880           0.0016           16.86m\n",
      "        20           0.6675           0.0141           16.66m\n",
      "        21           0.6421           0.0040           16.45m\n",
      "        22           0.6222           0.0041           16.25m\n",
      "        23           0.6113          -0.0002           16.03m\n",
      "        24           0.5957           0.0086           15.81m\n",
      "        25           0.5753           0.0035           15.59m\n",
      "        26           0.5638           0.0052           15.38m\n",
      "        27           0.5563           0.0045           15.18m\n",
      "        28           0.5378          -0.0011           14.97m\n",
      "        29           0.5185           0.0050           14.77m\n",
      "        30           0.5186           0.0037           14.56m\n",
      "        31           0.4982           0.0029           14.35m\n",
      "        32           0.4804          -0.0003           14.15m\n",
      "        33           0.4682           0.0056           13.94m\n",
      "        34           0.4501           0.0019           13.73m\n",
      "        35           0.4438           0.0045           13.53m\n",
      "        36           0.4304           0.0002           13.32m\n",
      "        37           0.4152           0.0050           13.12m\n",
      "        38           0.4041           0.0029           12.92m\n",
      "        39           0.3918           0.0025           12.71m\n",
      "        40           0.3721           0.0009           12.51m\n",
      "        41           0.3789           0.0023           12.30m\n",
      "        42           0.3652           0.0038           12.09m\n",
      "        43           0.3539           0.0019           11.89m\n",
      "        44           0.3493           0.0039           11.68m\n",
      "        45           0.3401          -0.0018           11.47m\n",
      "        46           0.3279           0.0034           11.26m\n",
      "        47           0.3206           0.0036           11.05m\n",
      "        48           0.3081           0.0008           10.84m\n",
      "        49           0.3013           0.0004           10.63m\n",
      "        50           0.2951           0.0027           10.43m\n",
      "        51           0.2885           0.0003           10.22m\n",
      "        52           0.2821           0.0017           10.01m\n",
      "        53           0.2779           0.0005            9.80m\n",
      "        54           0.2750           0.0016            9.58m\n",
      "        55           0.2643           0.0001            9.37m\n",
      "        56           0.2565           0.0004            9.16m\n",
      "        57           0.2477           0.0007            8.96m\n",
      "        58           0.2435          -0.0003            8.75m\n",
      "        59           0.2396           0.0017            8.54m\n",
      "        60           0.2332           0.0009            8.34m\n",
      "        61           0.2255           0.0011            8.13m\n",
      "        62           0.2208           0.0004            7.92m\n",
      "        63           0.2225           0.0017            7.71m\n",
      "        64           0.2105           0.0005            7.50m\n",
      "        65           0.2083           0.0000            7.30m\n",
      "        66           0.2004           0.0004            7.09m\n",
      "        67           0.1978           0.0018            6.88m\n",
      "        68           0.1935          -0.0004            6.67m\n",
      "        69           0.1882           0.0013            6.45m\n",
      "        70           0.1861           0.0007            6.24m\n",
      "        71           0.1840           0.0010            6.04m\n",
      "        72           0.1826           0.0002            5.83m\n",
      "        73           0.1744          -0.0006            5.62m\n",
      "        74           0.1724           0.0005            5.41m\n",
      "        75           0.1672          -0.0011            5.20m\n",
      "        76           0.1675          -0.0005            4.99m\n",
      "        77           0.1634           0.0002            4.78m\n",
      "        78           0.1598          -0.0001            4.57m\n",
      "        79           0.1559          -0.0005            4.36m\n",
      "        80           0.1533           0.0007            4.15m\n",
      "        81           0.1490           0.0012            3.95m\n",
      "        82           0.1479           0.0003            3.74m\n",
      "        83           0.1425          -0.0000            3.53m\n",
      "        84           0.1432           0.0010            3.32m\n",
      "        85           0.1404           0.0004            3.11m\n",
      "        86           0.1364           0.0007            2.90m\n",
      "        87           0.1276          -0.0004            2.70m\n",
      "        88           0.1304           0.0008            2.49m\n",
      "        89           0.1290           0.0004            2.28m\n",
      "        90           0.1245          -0.0003            2.07m\n",
      "        91           0.1214          -0.0000            1.87m\n",
      "        92           0.1208           0.0004            1.66m\n",
      "        93           0.1192          -0.0000            1.45m\n",
      "        94           0.1194          -0.0005            1.24m\n",
      "        95           0.1136           0.0001            1.03m\n",
      "        96           0.1138           0.0005           49.69s\n",
      "        97           0.1106           0.0011           37.27s\n",
      "        98           0.1094          -0.0003           24.84s\n",
      "        99           0.1065          -0.0003           12.42s\n",
      "       100           0.1025           0.0002            0.00s\n",
      "Validation Scores:\n",
      "Log-Loss: 0.4093718867874228\n",
      "Positive Label\n",
      "Precision: 0.8214285714285714, Recall: 0.92, F1: 0.8679245283018867, Support: 150\n",
      "Negative Label\n",
      "Precision: 0.7857142857142857, Recall: 0.5945945945945946, F1: 0.676923076923077, Support: 74\n",
      "Accuracy: 0.8125\n",
      "\n",
      "Training Scores:\n",
      "Log-Loss: 0.051553797048642026\n",
      "Positive Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Negative Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Retrain using best params\n",
    "gbc = GradientBoostingClassifier(random_state=0,max_features=None,n_estimators=100,subsample=0.8,verbose=2)\n",
    "gbc.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_val_pred = gbc.predict(X_val)\n",
    "y_val_proba = gbc.predict_proba(X_val)\n",
    "y_train_pred = gbc.predict(X_train)\n",
    "y_train_proba = gbc.predict_proba(X_train)\n",
    "\n",
    "# Validation scores\n",
    "logl = log_loss(y_val,y_val_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_val,y_val_pred)\n",
    "acc = accuracy_score(y_val,y_val_pred)\n",
    "print(\"Validation Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\\n\".format(acc))\n",
    "\n",
    "# Training Scores\n",
    "logl = log_loss(y_train,y_train_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_train,y_train_pred)\n",
    "acc = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4VNXWwOHfSkIavV+kNylSNVJEAQtFsKMCIpbLvUqz\ngBcBQVEUCygIUkWRz8pVFOVKExBEVKQoRYqAgBBEOqEmpKzvj3MShpAygUwmk6z3efIwp69zmJk1\ne+9z9hZVxRhjjElPkL8DMMYYk7tZojDGGJMhSxTGGGMyZInCGGNMhixRGGOMyZAlCmOMMRmyRJEH\niEg3EfnG33H4m4hUEpGTIhKcg8esIiIqIiE5dUxfEpGNItL6IrbLs+9BEWktItH+jsOfLFFkMxHZ\nJSJn3C+sv0VkuogU8uUxVfUjVW3ry2PkRu61vil5WlV3q2ohVU30Z1z+4iasGpeyD1W9QlWXZnKc\nC5Jjfn0P5heWKHzjVlUtBDQCGgOD/RzPRfHnr+S88gs9K+x6m9zKEoUPqerfwAKchAGAiISJyOsi\nsltE9ovIZBGJ8Fh+u4isFZHjIvKHiLR35xcVkXdFZJ+I7BWRl5KrWETkIRFZ7r6eJCKve8YhIl+J\nSH/39WUi8rmIHBSRnSLyuMd6z4vITBH5UESOAw+lPic3jvfd7f8UkaEiEuQRxw8iMl5EYkRki4jc\nmGrbjM7hBxEZIyKHgedFpLqIfCsih0XkkIh8JCLF3PU/ACoB/3NLb0+n/qUrIktF5EV3vydE5BsR\nKeURzwPuORwWkWdTl1BSnXeEiLzhrh8jIss9/9+Abu7/6SERGeKxXRMR+UlEjrnnPV5EQj2Wq4j0\nEZFtwDZ33lgR2eO+B9aIyHUe6weLyDPue+OEu7yiiCxzV1nnXo/O7vq3uO+nYyLyo4g08NjXLhEZ\nKCLrgVMiEuJ5DdzYV7tx7BeR0e6mycc65h6rued70N32ChFZKCJH3G2fSee6pvt5cGP72eP/s5c4\nVWPh7vRn4pTaY0RkmYhc4bHf6SIyUUTmuTH+ICL/EJE3ReSo+95snOpaDBaRTe7y95KPk0bM6X6G\n8ixVtb9s/AN2ATe5rysAG4CxHsvHALOBEkBh4H/AK+6yJkAM0AYniZcHarvLZgFTgIJAGWAl8Ki7\n7CFgufu6JbAHEHe6OHAGuMzd5xrgOSAUqAbsANq56z4PxAN3uOtGpHF+7wNfubFXAbYCPTziSAD6\nAQWAzu75lPDyHBKAx4AQIAKo4V6LMKA0zhfUm2lda3e6CqBAiDu9FPgDuNzd31LgVXdZXeAkcK17\nLV53z/2mdP5fJ7jblweCgWvcuJKPOdU9RkMgDqjjbncV0Mw9pyrAZuBJj/0qsBDn/RDhzrsfKOlu\n8xTwNxDuLhuA856qBYh7vJIe+6rhse/GwAGgqRvzg+41C/O4fmuBih7HTrmmwE9Ad/d1IaBZWtc5\njfdgYWCfG3u4O900neua0echyP0/fx6oCRwFGnts+093mzDgTWCtx7LpwCH3+ocD3wI7gQfca/ES\nsCTVe+k391qUAH4AXnKXtQaiPWJK9zOUV//8HkBe+3PfcCeBE+6HaTFQzF0mwCmgusf6zYGd7usp\nwJg09lkW58snwmNe1+Q3eqoPqQC7gZbu9L+Bb93XTYHdqfY9GHjPff08sCyDcwsGzgJ1PeY9Ciz1\niOMv3CTlzlsJdPfyHHand2x3nTuAX1Nd68wSxVCP5b2B+e7r54BPPJZFuud2QaJwvxzOAA3TWJZ8\nzAqpzrlLOufwJDDLY1qBGzI576PJxwZ+B25PZ73UiWIS8GKqdX4HWnlcv3+m8f5NThTLgBeAUumc\nc3qJoqvn/1MG55Xh58HjWEdwEuzgDPZVzI2pqDs9HZjqsfwxYLPHdH3gWKrz7ukx3QH4w33dmnOJ\nIsPPUF79s3pJ37hDVReJSCvgY6AUcAznV3EksEZEktcVnC9gcH7NzE1jf5VxfqHv89guCKfkcB5V\nVRGZgfNhXQbcB3zosZ/LROSYxybBwPce0xfs00MpN44/Peb9ifMrO9ledT89Hssv8/Iczju2iJQF\nxgLX4fxyDML50syKvz1en8b5ZYwbU8rxVPW0OFVeaSmF86v0j6weR0QuB0YDUTj/9yE4v0g9pT7v\n/wA93BgVKOLGAM57JKM4PFUGHhSRxzzmhbr7TfPYqfQAhgNbRGQn8IKqfu3Fcb2NMbPPA6q6S0SW\n4HxxT0hZyamyHAHc4+4nyV1UCqcUC7Df41hn0phOfZOJ57VIft+m5s1nKM+xNgofUtXvcH7ZJLcZ\nHMJ5g16hqsXcv6LqNHyD80atnsau9uD8Gi/lsV0RVb0ijXUBPgHuFpHKOL+APvfYz06PfRRT1cKq\n2sEz7AxO6RBO9Uxlj3mVgL0e0+XF41PvLv/Ly3NIfeyX3Xn1VbUITpWMZLB+VuzDqRoEnDYInOqe\ntBwCYkn7/yYzk4AtQE33HJ7h/HMAj/Nw2yOeBu4FiqtqMZwvvuRt0nuPpGUPMCLV/3ekqn6S1rFT\nU9VtqtoVp5rwNWCmiBTMaBuP41bzIr7MPg+ISEecUsZiYJTHtvcBtwM3AUVxSh5w4bXNiooer5Pf\nt6l58xnKcyxR+N6bQBsRaaiqSTh12WNEpAyAiJQXkXbuuu8CD4vIjSIS5C6rrar7gG+AN0SkiLus\nultiuYCq/orzIXwHWKCqyb9+VgIn3EbCCLdhtJ6IXO3Niahz2+mnwAgRKewmov6cK7GA86XyuIgU\nEJF7gDrA3Kyeg6swTjVejIiUx6mf97Qf776Q0jITuFVErhGncfl50vmScf/fpgGj3YbMYLcBN8yL\n4xQGjgMnRaQ20MuL9ROAg0CIiDyHU6JI9g7woojUFEcDEUlOcKmvx1Sgp4g0ddctKCIdRaSwF3Ej\nIveLSGn3/JPfQ0lubEmkf+2/BsqJyJNuY3VhEWmaeqXMPg/i3HjwDvAvnPaVW0Uk+Qu5MM4Pj8M4\npZKXvTmnTPQRkQoiUgIYAvw3jXUu6TMUqCxR+JiqHsRpAH7OnTUQ2A6sEOfOokU4DZOo6krgYZwG\nvhjgO879en8Ap9pgE071y0ygXAaH/hjn19bHHrEkArfg3IW1k3PJpGgWTukxnHrlHcByd//TPJb/\njNPweAinauBuVU2u0snqObwAXIlzLeYAX6Ra/gowVJw7ev6ThXNAVTe65zIDp3RxEqfhNy6dTf6D\n04i8CqfO/DW8+/z8B+fX7wmcL8W0vnw8LQDm49wk8CdOScazSmQ0TrL+BicBvYvTiA5Osvs/93rc\nq6qrcdqoxuNc7+2kcSdbBtoDG0XkJE4VYBdVPaOqp3H+b39wj9XMcyNVPYFzE8KtOFVy24Dr0zlG\nup8H4G3gK1Wd676HegDvuInxfff67MV5P63Iwnml52Oc67oDp+rspdQrZNNnKOAk3xljzCUTkYeA\nf6nqtf6OJavEeSjyGE4V0U5/x2NylojswnnvLvJ3LLmRlShMviUit4pIpFvv/jpOiWGXf6MyJvex\nRGHys9txGiz/wqku66JWxDbmAlb1ZIwxJkNWojDGGJOhgHvgrlSpUlqlShV/h2GMMQFlzZo1h1S1\n9MVsG3CJokqVKqxevdrfYRhjTEARkT8zXyttVvVkjDEmQ5YojDHGZMgShTHGmAxZojDGGJMhSxTG\nGGMyZInCGGNMhnyWKERkmogcEJHf0lkuIjJORLaLyHoRudJXsRhjjLl4vixRTMfppjg9N+P0r1MT\neARngBdjjDHZ7OzZxEva3mcP3KnqMhGpksEqtwPvu52wrRCRYiJSzh3gxhhj4IuOsDOt0YGNtwb8\nrw2//pXRsC+Z8+eT2eU5f0CWaHfeBYlCRB7BKXVQqVKlHAnOmIBnX7IGqPePA4xbfsEAg1kSEF14\nqOrbOKNdERUVZd3dGpOfkkDVDnDXHH9HETA2bTrIL7/s4/77GwDwgCqtXo2hatULBuzzmj8TxV7O\nH8y8gjvPGJMZb5OEfcnmG6dPx/PSS8sYNepHgoOFZs0qUKNGCUSEKlWKXdK+/ZkoZgN9RWQG0BSI\nsfYJk6fkxK/+p6yAbWDevG306TOXnTuPAdCjx1WULBmRyVbe81miEJFPgNZAKRGJBoYBBQBUdTIw\nF+iAM7D6aeBhX8VijF/4OklU7eDb/Ztcb+/e4zz55AJmztwEQIMGZZk8uSPNm1fMZMus8eVdT10z\nWa5AH18d35hcw371Gx/p02cuX331O5GRBRg+vDVPPNGMkJDsf+ohIBqzjclR+amh2ASchISklGTw\n2ms3UaBAMG+80ZZKlYr67JiWKEz+5uukYNVDJpvExMQydOi3bN16hPnzuyEi1KpVis8+u8fnx7ZE\nYfK39JKE3S1kcglV5bPPNvHkk/PZt+8kwcHC2rV/07jxpT1ElxWWKIwBa0cwudIffxyhb995zJ+/\nHYDmzSswefItNGhQNkfjsERhjDG50Ouv/8izzy4hNjaBYsXCee21m/jXv64kKEhyPBZLFCZ/sYZq\nEyBOn44nNjaB7t0b8PrrbSlTpqDfYrFEYfKXtJKENTibXODgwVP8/vthrr3W6c9u4MAWtG5dhZYt\nK/s5MksUJr+yNgmTSyQlKdOm/crTTy8kJCSILVv6UqJEBGFhIbkiSYAlCpOXWLWSCTC//XaAnj2/\n5ocfnI6027SpxunT8ZQokX3db2QHSxQm78hKR3nG+NGpU2cZPvw7Ro9eQUJCEmXLFuTNN9vTufMV\niOR8Y3VmLFGYvMeqlUwud/fdnzF//nZEoHfvKEaMuJFixcL9HVa6LFEYY0wOGziwBfv3n2TSpI40\nbVrB3+FkyhKFMcb4UEJCEm+99TO7dh1j7NibAWjdugqrVz/il2ciLoYlChOYrOHaBICVK/fy6KNf\ns3bt3wA88shVXHFFGYCASRIA2d8frTE5IaM+mozxs2PHYundew7Nmr3D2rV/U7lyUf73v64pSSLQ\nWInCBDZruDa5zIwZv/Hkk/PZv/8UISFBPPVUc559tiUFC4b6O7SLZonCBAarajIB4ptv/mD//lO0\naFGRSZM6Ur9+znbg5wuWKExgsK43TC4VF5fA3r0nqFatOAAjR7bhuusq8eCDjQKqHSIjlihM7pNR\n6cGqmkwu8u23O+nVaw5BQcK6dT0JDQ2mVKlIHn64sb9Dy1bWmG1yH2uoNrnc/v0n6d59Fjfe+D5b\ntx4GIDr6uJ+j8h0rURj/S68EYaUHk8skJSlTp65h0KDFHDsWS3h4CEOHXseAAS0IDQ32d3g+Y4nC\n+J+1P5gAceed/2X27N8BaNeuOhMmdKB69RJ+jsr3LFGYnGXtDyaA3XVXbVau3MvYse255566ubID\nP1+wRGFylrU/mAAye/bvREcfp3fvqwF44IGG3HVXHQoXDvNzZDnLEoW5eJfybIOVHkwutnt3DI8/\nPo+vvvqdsLBg2revQbVqxRGRfJckwBKFuRQXmySs9GByqfj4RMaN+5lhw5Zy6lQ8hQuH8tJLN1C5\nclF/h+ZXlijMpbPSgckDVqyI5tFHv2b9+v0A3HNPXcaMaUf58kX8HJn/WaIwxhjg2WeXsH79fqpW\nLcb48R3o0KGmv0PKNSxRGGPyJVXlxImzFCnitDmMH38z77+/jiFDWhIZWcDP0eUuliiMdbhn8p3f\nfz9E795zEYGFC7sjItSqVYoRI270d2i5kiWKvM7XScAapk0AiY1N4JVXvufVV3/g7NlESpaMYNeu\nY1StWtzfoeVqlijyOm+TRNUOcNcc38ZijB8tXPgHvXvPZfv2IwD885+NGDmyDSVLRvo5stzPp4lC\nRNoDY4Fg4B1VfTXV8krA/wHF3HUGqarVgfiC3Zlk8ilVpUeP2bz33loA6tYtzeTJHbnuusp+jixw\n+CxRiEgwMAFoA0QDq0Rktqpu8lhtKPCpqk4SkbrAXKCKr2IyxuQ/IkKVKsWIiAjhueda0b9/8zzd\ngZ8v+LJE0QTYrqo7AERkBnA74JkoFEi+Sbko8JcP4zHG5BNr1/7Nvn0nuPlm5xbXgQNb0L17A2uL\nuEi+HI+iPLDHYzranefpeeB+EYnGKU08ltaOROQREVktIqsPHjzoi1iNMXnAiRNx9O+/gKuuepsH\nH/ySI0fOABAWFmJJ4hL4e+CirsB0Va0AdAA+EJELYlLVt1U1SlWjSpcuneNBGmNyN1Vl1qzN1K07\nkTFjVgBw3331KVDA319xeYMvq572AhU9piu48zz1ANoDqOpPIhIOlAIO+DCuvMOefzCGP/88Rt++\n8/j6660AREVdxpQpt3DlleX8HFne4ct0uwqoKSJVRSQU6ALMTrXObuBGABGpA4QDVrfkrazc+mpM\nHqSqdOr0KV9/vZUiRcIYP/5mVqzoYUkim/msRKGqCSLSF1iAc+vrNFXdKCLDgdWqOht4CpgqIv1w\nGrYfUlW7jzOr7NZXk88kJSlBQYKI8PrrbZk8eTVjxrSjXLnC/g4tT5JA+16OiorS1atX+zuM3OEN\nd3QtSxQmnzh8+DSDBi0CYOrU2/wcTWARkTWqGnUx29qT2YHC2iNMPqaqvP/+Ov7zn4UcOnSa0NBg\nhg1rTYUK1gV4TrBEEShsCFGTT23efJBevebw3Xd/AtC6dRUmTepoSSIHWaIINFbNZPIJVeW555bw\n2ms/EB+fRKlSkbzxRlu6d2+AiPg7vHzFEoUxJlcSEfbuPUF8fBL//veVvPrqTZQoEeHvsPIlSxTG\nmFzjr79OcOjQaRo0KAvAyJFt6NGjMS1aVPJzZPmbPbZojPG7xMQkxo9fSZ06E+jSZSZnzyYCUKpU\npCWJXMBKFLmV3eVk8olfftnHo49+zerVTp+gLVtW5vjxOEqVsnEicguvEoX7ZHUlVd3u43hMsrSS\nhN3hZPKQ48fjePbZbxk/fhVJSUqFCkUYN649d9xR2xqrc5lME4WIdARGA6FAVRFpBAxT1Tt9HZzB\n7nIyeZKq0rLle6xbt5/gYKF//2Y8/3xrChcO83doJg3etFEMB5oCxwBUdS1Qw5dBGWPyNhGhX79m\nNGlSntWrH+GNN9pZksjFvKl6ilfVY6mKgvYz1xjjtbNnExk9+ieCg4UBA1oA8MADDbn//gYEB9s9\nNbmdN4lis4jcCwSJSFXgcWCFb8MyxuQV33//Jz17zmHTpoOEhQXzwAMNKVu2ECJCcLC1RQQCbxJF\nX+A5IAn4Aqc32Gd8GVS+Y3c4mTzo0KHTPP30Qt57by0ANWuWYOLEjpQtW8jPkZms8iZRtFPVgcDA\n5BkichdO0jDZwfpxMnmIqjJ9+loGDFjI4cNnCA0NZvDgaxk06FrCw+2O/EDkzf/aUC5MCkPSmGcu\nld3hZPKIDz/cwOHDZ7jhhqpMnNiBWrVK+TskcwnSTRQi0g5nmNLyIjLaY1ERnGooY4wB4PTpeGJi\nYilXrjAiwsSJHVi16i+6datvz0TkARmVKA4AvwGxwEaP+SeAQb4MyhgTOObN20afPnOpVq04Cxd2\nR0SoVauUlSLykHQThar+CvwqIh+pamwOxmSMCQB79x7nyScXMHPmJgAKFw7j8OEz1vVGHuRNG0V5\nERkB1AXCk2eq6uU+i8oYk2slJiYxYcIqhg79lhMnzlKwYAGGD7+exx9vSkiIPRORF3mTKKYDLwGv\nAzcDD2MP3BmTLyUlKa1aTeeHH/YAcMcdtRk7tj2VKhX1c2TGl7xJ/5GqugBAVf9Q1aE4CcMYk88E\nBQlt21anYsUifPVVF2bN6mxJIh/wpkQRJyJBwB8i0hPYCxT2bVjGmNxAVfn0042EhATRqVNdAAYO\nbEH//s0pVCjUz9GZnOJNougHFMTpumMEUBT4py+DMsb43x9/HKF377l8880flC4dyQ03VKV48QjC\nwkIIs/778pVME4Wq/uy+PAF0BxCR8r4MyhjjP3FxCYwa9SMjRnxPbGwCxYuHM2LEDRQtGp75xiZP\nyjBRiMjVQHlguaoeEpErcLryuAGokAPxGWNy0NKlu+jVaw5bthwCoHv3Brz+elvKlCno58iMP6Xb\nmC0irwAfAd2A+SLyPLAEWAfYrbHG5DGJiUn07u0kiVq1SvLttw/w/vt3WpIwGZYobgcaquoZESkB\n7AHqq+qOnAnNGONrSUlKbGwCkZEFCA4OYtKkjixb9idPP92CsDDrwM84MnonxKrqGQBVPSIiWy1J\nGJN3bNiwn54951C7dkneffd2AFq1qkKrVlX8G5jJdTJKFNVEJLmHWMEZLzulx1hVvcunkRljfOLU\nqbMMH/4do0evICEhiZ07j3L06BmKF4/wd2gml8ooUXRKNT3el4HkKzZQkfGT//3vd/r2ncfu3TGI\nQO/eUYwYcSPFitkdTSZ9GXUKuDgnA8lX0koSNkiR8aGEhCQ6d57JF19sBqBRo38wZcotNGlid7qb\nzFlrlT/ZQEUmh4SEBFG0aBiFCoXy4ovX07dvE+vAz3jNp+8UEWkvIr+LyHYRSXMMCxG5V0Q2ichG\nEfnYl/EYk5/8/HM0P/8cnTI9alQbNm/uw5NPNrMkYbLE6xKFiISpalwW1g8GJgBtgGhglYjMVtVN\nHuvUBAYDLVT1qIiU8T50Y0xajh2LZfDgRUyZsobatUuxdm1PQkODKVnSxokwFyfTnxUi0kRENgDb\n3OmGIvKWF/tuAmxX1R2qehaYgfNshqd/AxNU9SiAqh7IUvTGmBSqyscfb6B27fFMnryG4OAgbrut\nFomJNnKxuTTelCjGAbcAXwKo6joRud6L7crjPKSXLBpommqdywFE5AcgGHheVed7sW9jjIdt2w7T\nu/dcFi1yHnVq0aIikyffQr16Vkg3l86bRBGkqn+mGiA9MRuPXxNojdN31DIRqa+qxzxXEpFHgEcA\nKlWqlE2HNiZviI9P5IYb3ic6+jglSkQwcuRNPPxwY4KCJPONjfGCN4lij4g0AdRtd3gM2OrFdnuB\nih7TFdx5nqKBn1U1HtgpIltxEscqz5VU9W3gbYCoqCi7VcgYnKomEaFAgWBGjLiBJUt2MXLkTZQu\nbX0zmezlza0PvYD+QCVgP9DMnZeZVUBNEakqIqFAF2B2qnW+xClNICKlcKqirJsQYzKwf/9Junef\nxUsvLUuZ98ADDXnvvdstSRif8KZEkaCqXbK6Y1VNEJG+wAKc9odpqrpRRIYDq1V1trusrYhswqnO\nGqCqh7N6LGPyg6QkZerUNQwatJhjx2IpViycJ59sRuHCNoqQ8S1vEsUqEfkd+C/whaqe8HbnqjoX\nmJtq3nMerxWntNLf230GHOuuw2SDdev+pmfPOaxY4TwX0b59DSZM6GBJwuQIb0a4qy4i1+BUHb0g\nImuBGao6w+fRBSJvE4N12WG8EB+fyODBi3nzzRUkJirlyhVi7Nj23H13XVLdYGKMz3j1wJ2q/gj8\n6A5e9CbOgEaWKNKSXj9Od83J+VhMwAsJCeLXX/8mKUl57LEmvPji9TYkqclxmSYKESmE86BcF6AO\n8BVwjY/jCnzWj5O5SLt3x5CYmETVqsURESZP7khMTBxRUZf5OzSTT3lTovgN+B8wUlW/93E8xuRb\n8fGJjB37M8OGLaV58wosXNgdEaFmzZL+Ds3kc94kimqqan0AGONDP/20h54957B+/X4ASpSI4PTp\neAoWDPVzZMZkkChE5A1VfQr4XEQuqEexEe6wO5rMJTt69AyDBi3i7bd/AaBq1WJMmNCBm2+u6efI\njDknoxLFf91/bWS79KSXJOyOJuOFuLgEGjWawu7dMRQoEMSAAdcwZEhLIiML+Ds0Y86T0Qh3K92X\ndVT1vGThPkiXt0fAy0ppwRquzUUICwuhR4/GLF68k0mTOlK3bml/h2RMmrzpwuOfaczrkd2B5Dre\nJgkrPRgvxcYmMGzYEj7+eEPKvGeeuY6lSx+0JGFytYzaKDrj3BJbVUS+8FhUGDiW9lZ5kJUWTDZY\nuPAPeveey/btRyhTpiB33lmbiIgCNtKcCQgZtVGsBA7j9Po6wWP+CeBXXwZlTF7x998n6d9/AZ98\n8hsAV1xRmsmTbyEiwtohTODIqI1iJ7ATWJRz4RiTNyQmJjFlyhqeeWYxMTFxRESEMGxYK/r1a05o\naLC/wzMmSzKqevpOVVuJyFHAs/5FcPrzK+Hz6IwJUImJyltvrSQmJo4OHWoyfvzNVK1a3N9hGXNR\nMqp6Sh7utFROBGJMoDtxIo7ERKVYsXBCQ4OZOvVW9u8/yV131bEO/ExAy6jqKflp7IrAX6p6VkSu\nBRoAHwLHcyC+nGMPz5mLpKrMmrWFxx+fR7t21Xn33dsBuPZaG7bX5A3e3HLxJc4wqNWB93CGKv3Y\np1H5Q3q9vhqTgV27jnHbbTPo1OlT9u49wW+/HSQ2NsHfYRmTrbzp6ylJVeNF5C7gLVUdJyJ5964n\nux3WeCE+PpHRo3/ihRe+48yZBIoUCePll2+gZ88ogoPtlleTt3g1FKqI3AN0B+5w59m9fSbfOn06\nnmbN3mHDhgMAdOlSj9Gj21KuXGE/R2aMb3iTKP4J9MbpZnyHiFQFPvFtWMbkXpGRBYiKuozTp+OZ\nOLEjbdtW93dIxviUN0Oh/iYijwM1RKQ2sF1VR/g+NGNyB1Xl/ffXUb16iZQG6jFj2hEaGmwPzpl8\nwZsR7q4DPgD24jxD8Q8R6a6qP/g6OGP8bfPmg/TqNYfvvvuTOnVKsXZtT0JDg204UpOveFP1NAbo\noKqbAESkDk7iiPJlYMb405kz8YwY8T0jR/5AfHwSpUtHMnjwtRQoYA3VJv/xJlGEJicJAFXdLCI2\n7JbJs+bP306fPnPZseMoAP/+95W8+upNlCgR4efIjPEPbxLFLyIyGechO4BuBHqngPZwnUnHyZNn\n6d59FocOnaZevTJMntyRFi3swTmTv3mTKHoCjwNPu9PfA2/5LKKcYCPTGQ+JiUkkJSkFCgRTqFAo\nY8e2Jzr6OP36NaNAAevAz5gME4WI1AeqA7NUdWTOhJSD7OG6fG/Nmr949NGvuf32Wjz7bCsA7ruv\nvp+jMiZ3SbdlTkSewem+oxuwUETSGunOmIB0/HgcTzwxjyZN3mHNmn188MF64uMT/R2WMblSRiWK\nbkADVT2ogGPUAAAeuklEQVQlIqWBucC0nAnLGN9QVWbO3MQTT8xn376TBAcL/fs344UXrrdqJmPS\nkVGiiFPVUwCqelBE7L5AE9BOnIijc+eZzJu3HYCmTcszefItNGr0Dz9HZkzullGiqOYxVrYA1T3H\nzlbVu3wamTHZrFChUOLiEilaNIxXX72JRx65iqAgGyfCmMxklCg6pZoe78tAjPGFZcv+pFy5QtSs\nWRIRYdq02wgPD6Fs2UL+Ds2YgJHRwEWLczIQY7LToUOnefrphbz33lpuvLEqCxd2R0SoXLmYv0Mz\nJuB48xyFMQEjKUmZPn0tAwYs5MiRM4SGBnPddZVITFRCQqyayZiL4dMGahFpLyK/i8h2ERmUwXqd\nRERFxPqPMhdt48YDtG49nR49ZnPkyBluvLEqGzb0Ytiw1oSE2L0Yxlwsr0sUIhKmqnFZWD8YmAC0\nAaKBVSIy27PfKHe9wsATwM/e7tuY1GJiYmnW7F1OnjxLmTIFGT26LffdVx8RK0UYc6ky/ZklIk1E\nZAOwzZ1uKCLedOHRBGfsih2qehaYAdyexnovAq8Bsd6HbYxD1Xm6vmjRcAYObEHPnlexZUsfunVr\nYEnCmGziTXl8HHALcBhAVdcB13uxXXlgj8d0tDsvhYhcCVRU1TkZ7UhEHhGR1SKy+uDBg14c2uR1\ne/ce5+67P+XDD9enzBsy5DomTbqF4sWtl1djspM3iSJIVf9MNe+S+zpwH+AbDTyV2bqq+raqRqlq\nVOnSpS/10CaAJSQkMXbsCmrXnsDnn29m2LClJCYmAVgJwhgf8aaNYo+INAHUbXd4DNjqxXZ7gYoe\n0xXceckKA/WApe4H/B/AbBG5TVVXexO8yV9WrdpLz55z+OWXfQDccUdtxo1rT3CwNVQb40veJIpe\nONVPlYD9wCJ3XmZWATVFpCpOgugC3Je8UFVjgFLJ0yKyFPiPJQmT2qlTZxk4cBETJ65CFSpVKspb\nb93MbbfV8ndoxuQLmSYKVT2A8yWfJaqaICJ9gQVAMDBNVTeKyHBgtarOznK0Jl8KCQli0aIdBAUJ\n/fs3Z9iwVhQsaIMsGpNTMk0UIjIVuGDgBlV9JLNtVXUuTq+znvOeS2fd1pntz+Qff/xxhGLFwilZ\nMpKwsBA++OBOwsNDqF+/rL9DMybf8abqaZHH63DgTs6/myn3s6FPA0ZcXAKjRv3IiBHf061bfd55\n5zYArr66fCZbGmN8xZuqp/96TovIB8Byn0XkC2klCRv2NNdZunQXvXrNYcuWQ4Bzh1NiYpI1Vhvj\nZxfT11NVIDDL/zb0aa504MApBgxYyPvvrwOgVq2STJrUkeuvr+rnyIwx4F0bxVHOtVEEAUeAdPtt\nMiYrDh06TZ06Ezhy5AxhYcEMGXIdTz/dgrAw66/SmNwiw0+jOA84NOTc8w9JmtxngjHZoFSpSG6/\nvRbR0ceZOLEjNWqU8HdIxphUMkwUqqoiMldV6+VUQCZvO3XqLMOHf0fHjpfTsmVlACZO7EhYWLA9\nWW1MLuVNK+FaEWns80hMnve///1O3boTGTnyR3r3nkNSklM4DQ8PsSRhTC6WbolCREJUNQFojNNF\n+B/AKZzxs1VVr8yhGE2A27MnhieemM+sWVsAaNz4H0yZcouNV21MgMio6mklcCVwWw7FYvKYhIQk\nxo37meeeW8KpU/EUKhTKSy9dT58+TWwgIWMCSEaJQgBU9Y8cisXkMcePx/HKK8s5dSqeTp3q8Oab\n7alQoYi/wzLGZFFGiaK0iPRPb6GqjvZBPJfOnsL2q2PHYomICCEsLIQSJSKYMuUWwsKC6djxcn+H\nZoy5SBmV/4OBQjjdgaf1lzullyTsSWyfUlU+/ngDtWqNZ+TIH1Lm33VXHUsSxgS4jEoU+1R1eI5F\nkt3sKewcs3XrYXr3nsPixTsBWLZsN6pqdzIZk0dk2kZhTHpiYxN47bXlvPzycs6eTaREiQhGjWrD\nQw81siRhTB6SUaK4MceiuBTWJuEXf/99kpYt32PbtiMAPPRQI0aNakOpUpF+jswYk93STRSqeiQn\nA7lo1jOsX5QtW5CKFYsSEhLEpEkdadWqir9DMsb4SN7pec3aJHwqKUmZOnUN119flcsvL4mI8PHH\nd1G8eAShocH+Ds8Y40P21JPJ1Lp1f9OixTR69pxD795zSO4XsmzZQpYkjMkH8k6JwmS7kyfP8vzz\nS3nzzRUkJiqXXVaYnj2j/B2WMSaHWaIwafryyy089tg8oqOPExQkPPZYE1566QaKFAnzd2jGmBxm\nicJcYO/e43TpMpO4uESuuqockyffQlTUZf4OyxjjJ5YoDADx8YmEhAQhIpQvX4QRI24gNDSY3r2v\ntjGrjcnn7BvA8OOPe7jqqrf58MP1KfOeeuoaHnusqSUJY4wlivzsyJEzPPro/2jRYhobNhxg4sTV\n2Ei3xpjUrOopH1JVPvxwPU899Q0HD56mQIEgnn66BUOGXGddbxhjLmCJIp/Zv/8kXbt+zpIluwBo\n1aoykyZ1pE6d0v4NzBiTa1miyGeKFQtn376TlCoVyeuvt+GBBxpaKcIYk6HASxT718Ab9sWWFQsX\n/sGVV5ajZMlIwsJC+OyzeyhXrhAlS1oHfsaYzOWNxmzrBDBN+/adoGvXz2nb9kMGDlyUMr9evTKW\nJIwxXgu8EgVYB4CZSExMYsqUNQwevJjjx+OIiAihVq2SNpiQMeaiBGaiMOn65Zd99Oz5NatW/QVA\nx441GT++A1WqFPNzZMaYQGWJIg/ZtesYTZpMJTFRKV++MOPG3cydd9a2UoQx5pL4NFGISHtgLBAM\nvKOqr6Za3h/4F5AAHAT+qap/+jKmvKxKlWI8/HAjChcO44UXWlO4sHXgZ4y5dD5rzBaRYGACcDNQ\nF+gqInVTrfYrEKWqDYCZwEhfxZMX7dp1jFtv/YTvvtuVMu/tt29l9Oh2liSMMdnGlyWKJsB2Vd0B\nICIzgNuBTckrqOoSj/VXAPf7MJ48Iz4+kdGjf+KFF77jzJkEDh06zU8/9QCwaiZjTLbz5e2x5YE9\nHtPR7rz09ADmpbVARB4RkdUisjob4wtIy5fvpnHjKQwatJgzZxLo0qUeX3xxr7/DMsbkYbmiMVtE\n7geigFZpLVfVt4G3AaIqSr68N/bo0TMMGLCQd9/9FYDq1YszcWJH2rat7ufIjDF5nS8TxV6gosd0\nBXfeeUTkJmAI0EpV43wYT0BLSlK++up3ChQIYtCgaxk8+FoiIgr4OyxjTD7gy0SxCqgpIlVxEkQX\n4D7PFUSkMTAFaK+qB3wYS0DasuUQVasWIywshJIlI/noo7uoVKkotWuX8ndoxph8xGdtFKqaAPQF\nFgCbgU9VdaOIDBeR29zVRgGFgM9EZK2IzPZVPIHk9Ol4hgxZTIMGkxg58oeU+W3bVrckYYzJcT5t\no1DVucDcVPOe83h9ky+PH4jmz99O795z2LnzGACHDp32c0TGmPwuVzRmG/jrrxM8+eR8PvvMuXu4\nfv0yTJ58C9dcUzGTLY0xxrcsUeQCW7ceJirqbU6cOEtkZAGef74VTz7ZjAIFgv0dmjHGWKLIDWrW\nLMHVV5enYMECvPXWzVSubB34GWNyD0sUfnD8eBzPPbeE3r2v5vLLSyIizJ7dhYIFQ/0dmjHGXMAS\nRQ5SVWbO3MQTT8xn376TbNlyiPnznV5LLEkYY3IrSxQ5ZMeOo/TtO5d587YD0KxZBV57zW76Msbk\nfpYofOzs2URef/1HXnxxGbGxCRQrFs6rr97Iv/99FUFB1oGfMSb3s0ThY3v2xDB8+HfExSXSrVt9\n3nijLWXLFvJ3WMYY4zVLFD5w9OgZihULR0SoXr0EY8e2p0aNEtx4YzV/h2aMMVnmy27G852kJGXa\ntF+pUeMtPvxwfcr8Rx+NsiRhjAlYliiyycaNB2jdejo9eszmyJEzKY3WxhgT6Kzq6RKdPh3Piy9+\nx+uv/0RCQhJlyhRkzJh2dO1az9+hGWNMtrBEcQm2bj1Mu3YfsmvXMUSgZ8+rePnlGylePMLfoRlj\nTLaxRHEJKlcuSnh4CA0blmXy5Fto1qyCv0MyuUh8fDzR0dHExsb6OxSTj4SHh1OhQgUKFMi+gc0s\nUWRBQkISkyevpmvXepQsGUlYWAjz53ejfPkihIRYc485X3R0NIULF6ZKlSqI2DMzxvdUlcOHDxMd\nHU3VqlWzbb/27eallSv30qTJVB57bB4DBy5KmV+5cjFLEiZNsbGxlCxZ0pKEyTEiQsmSJbO9FGsl\nikzExMQyZMi3TJy4ClWoVKkot99ey99hmQBhScLkNF+85yxRpENV+e9/N9Kv3wL+/vskISFB9O/f\njOeea2Ud+Blj8hWrM0nHunX76dr1c/7++yTXXFORX355hNdea2NJwgSU4OBgGjVqRL169bj11ls5\nduxYyrKNGzdyww03UKtWLWrWrMmLL76IqqYsnzdvHlFRUdStW5fGjRvz1FNP+eMUMvTrr7/So0cP\nf4eRoVdeeYUaNWpQq1YtFixYkOY6ixcv5sorr6RRo0Zce+21bN9+7jmsTz/9lLp163LFFVdw3333\nAXDw4EHat2+fI/EDzi/nQPq7qgLqKwkJiedN9+s3X6dOXaOJiUk+O6bJuzZt2uTvELRgwYIprx94\n4AF96aWXVFX19OnTWq1aNV2wYIGqqp46dUrbt2+v48ePV1XVDRs2aLVq1XTz5s2qqpqQkKATJ07M\n1tji4+MveR933323rl27NkePmRUbN27UBg0aaGxsrO7YsUOrVaumCQkJF6xXs2bNlPfLhAkT9MEH\nH1RV1a1bt2qjRo30yJEjqqq6f//+lG0eeughXb58eZrHTeu9B6zWi/zetaon15IlO+ndey5TptxC\ny5aVARg9up2fozJ5xhs+aqt4SjNfx9W8eXPWr3e6lvn4449p0aIFbdu2BSAyMpLx48fTunVr+vTp\nw8iRIxkyZAi1a9cGnJJJr169LtjnyZMneeyxx1i9ejUiwrBhw+jUqROFChXi5MmTAMycOZOvv/6a\n6dOn89BDDxEeHs6vv/5KixYt+OKLL1i7di3FijmjOtasWZPly5cTFBREz5492b17NwBvvvkmLVq0\nOO/YJ06cYP369TRs2BCAlStX8sQTTxAbG0tERATvvfcetWrVYvr06XzxxRecPHmSxMREvvvuO0aN\nGsWnn35KXFwcd955Jy+88AIAd9xxB3v27CE2NpYnnniCRx55xOvrm5avvvqKLl26EBYWRtWqValR\nowYrV66kefPm560nIhw/fhyAmJgYLrvsMgCmTp1Knz59KF68OABlypRJ2eaOO+7go48+uuC6+EK+\nTxQHDpxiwICFvP/+OgBGj/4pJVEYk1ckJiayePHilGqajRs3ctVVV523TvXq1Tl58iTHjx/nt99+\n86qq6cUXX6Ro0aJs2LABgKNHj2a6TXR0ND/++CPBwcEkJiYya9YsHn74YX7++WcqV65M2bJlue++\n++jXrx/XXnstu3fvpl27dmzevPm8/axevZp69c71gFC7dm2+//57QkJCWLRoEc888wyff/45AL/8\n8gvr16+nRIkSfPPNN2zbto2VK1eiqtx2220sW7aMli1bMm3aNEqUKMGZM2e4+uqr6dSpEyVLljzv\nuP369WPJkiUXnFeXLl0YNGjQefP27t1Ls2bNUqYrVKjA3r17L9j2nXfeoUOHDkRERFCkSBFWrFgB\nwNatWwFo0aIFiYmJPP/88ylVTlFRUQwdOjTT650d8m2iSEpS3n33FwYOXMTRo7GEhQUzdGhLBgy4\nxt+hmbwoC7/8s9OZM2do1KgRe/fupU6dOrRp0yZb979o0SJmzJiRMp38yzcj99xzD8HBwQB07tyZ\n4cOH8/DDDzNjxgw6d+6cst9NmzalbHP8+HFOnjxJoULnuujft28fpUuXTpmOiYnhwQcfZNu2bYgI\n8fHxKcvatGlDiRIlAPjmm2/45ptvaNy4MeCUirZt20bLli0ZN24cs2bNAmDPnj1s27btgkQxZswY\n7y5OFowZM4a5c+fStGlTRo0aRf/+/XnnnXdISEhg27ZtLF26lOjoaFq2bMmGDRsoVqwYZcqU4a+/\n/sr2WNKSLxPFzp1Huf/+Wfz44x4A2ratzoQJHahRo4SfIzMme0VERLB27VpOnz5Nu3btmDBhAo8/\n/jh169Zl2bJl5627Y8cOChUqRJEiRbjiiitYs2ZNSrVOVnneopn6nv6CBQumvG7evDnbt2/n4MGD\nfPnllym/kJOSklixYgXh4eEZnpvnvp999lmuv/56Zs2axa5du2jdunWax1RVBg8ezKOPPnre/pYu\nXcqiRYv46aefiIyMpHXr1mk+j5CVEkX58uXZs2dPynR0dDTly5c/b52DBw+ybt06mjZtCjjJM7nU\nUKFCBZo2bUqBAgWoWrUql19+Odu2bePqq69OqWLLCfnyrqciRcLYuvUw//hHIWbM6MT8+d0sSZg8\nLTIyknHjxvHGG2+QkJBAt27dWL58OYsWOQ+Pnjlzhscff5ynn34agAEDBvDyyy+nVH0kJSUxefLk\nC/bbpk0bJkyYkDKdXPVUtmxZNm/eTFJSUsov9LSICHfeeSf9+/enTp06Kb/e27Zty1tvvZWy3tq1\nay/Ytk6dOufdHRQTE5PyJTx9+vR0j9muXTumTZuW0oayd+9eDhw4QExMDMWLFycyMpItW7akVP+k\nNmbMGNauXXvBX+okAXDbbbcxY8YM4uLi2LlzJ9u2baNJkybnrVO8eHFiYmJSrvXChQupU6cO4LRD\nLF26FIBDhw6xdetWqlVzhizYunXreVVvvpRvEsWCBduJi0sAoGTJSGbP7sKWLX3o3LmePRRl8oXG\njRvToEEDPvnkEyIiIvjqq6946aWXqFWrFvXr1+fqq6+mb9++ADRo0IA333yTrl27UqdOHerVq8eO\nHTsu2OfQoUM5evQo9erVo2HDhim/tF999VVuueUWrrnmGsqVK5dhXJ07d+bDDz9MqXYCGDduHKtX\nr6ZBgwbUrVs3zSRVu3ZtYmJiOHHiBABPP/00gwcPpnHjxiQkJKR7vLZt23LffffRvHlz6tevz913\n382JEydo3749CQkJ1KlTh0GDBp3XtnCxrrjiCu69917q1q1L+/btmTBhQkq1W4cOHfjrr78ICQlh\n6tSpdOrUiYYNG/LBBx8watQowElqJUuWpG7dulx//fWMGjUqJZkuWbKEjh07XnKM3hBV/9SdXqyo\niqKr93gf8549MTz++Hy+/HILL754PUOHtvRhdMacs3nz5pRfhsY3xowZQ+HChfnXv/7l71ByXMuW\nLfnqq6/SbBdK670nImtUNepijpVnSxQJCUmMHv0TdepM4Msvt1CoUCglSlj338bkJb169SIsLMzf\nYeS4gwcP0r9/f69uHsgOebIxe8WKaHr2/Jp16/YD0KlTHcaObU/58kX8HJkxJjuFh4fTvXt3f4eR\n40qXLs0dd9yRY8fLc4ni55+jueaad1GFKlWKMX78zXTseLm/wzL5lKpaG5jJUb5oTshziaJJk/K0\na1eDxo3/wdChLYmMzL7BO4zJivDwcA4fPmxdjZsco+54FBndVnwxAr4xe9u2w/Trt4DRo9tx+eXO\n3QBJSUpQkH0wjX/ZCHfGH9Ib4e5SGrMDtkQRF5fAq68u55VXlhMXl0h4eAgzZ94LYEnC5ArJD0kZ\nE+h8eteTiLQXkd9FZLuIXPA0ioiEich/3eU/i0gVb/a7ePEOGjSYzPPPf0dcXCIPP9yIyZNvye7w\njTHG4MMShYgEAxOANkA0sEpEZqvqJo/VegBHVbWGiHQBXgM6X7i3c3YeKcZNN30AQJ06pZg8+Rbr\nxM8YY3zIlyWKJsB2Vd2hqmeBGcDtqda5Hfg/9/VM4EbJpNXv6JlIwsNDePnlG1i7tqclCWOM8TGf\nNWaLyN1Ae1X9lzvdHWiqqn091vnNXSfanf7DXedQqn09AiR3DF8P+M0nQQeeUsChTNfKH+xanGPX\n4hy7FufUUtXCF7NhQDRmq+rbwNsAIrL6Ylvu8xq7FufYtTjHrsU5di3OEZHVF7utL6ue9gIVPaYr\nuPPSXEdEQoCiwGEfxmSMMSaLfJkoVgE1RaSqiIQCXYDZqdaZDTzovr4b+FYD7cEOY4zJ43xW9aSq\nCSLSF1gABAPTVHWjiAzHGeR7NvAu8IGIbAeO4CSTzLztq5gDkF2Lc+xanGPX4hy7Fudc9LUIuCez\njTHG5Kw82824McaY7GGJwhhjTIZybaLwVfcfgciLa9FfRDaJyHoRWSwiefYpxMyuhcd6nURERSTP\n3hrpzbUQkXvd98ZGEfk4p2PMKV58RiqJyBIR+dX9nHTwR5y+JiLTROSA+4xaWstFRMa512m9iFzp\n1Y5VNdf94TR+/wFUA0KBdUDdVOv0Bia7r7sA//V33H68FtcDke7rXvn5WrjrFQaWASuAKH/H7cf3\nRU3gV6C4O13G33H78Vq8DfRyX9cFdvk7bh9di5bAlcBv6SzvAMwDBGgG/OzNfnNricIn3X8EqEyv\nhaouUdXT7uQKnGdW8iJv3hcAL+L0G5aX+/f25lr8G5igqkcBVPVADseYU7y5FgokD3FZFPgrB+PL\nMaq6DOcO0vTcDryvjhVAMREpl9l+c2uiKA/s8ZiOdueluY6qJgAxQMkciS5neXMtPPXA+cWQF2V6\nLdyidEVVnZOTgfmBN++Ly4HLReQHEVkhIu1zLLqc5c21eB64X0SigbnAYzkTWq6T1e8TIEC68DDe\nEZH7gSiglb9j8QcRCQJGAw/5OZTcIgSn+qk1TilzmYjUV9Vjfo3KP7oC01X1DRFpjvP8Vj1VTfJ3\nYIEgt5YorPuPc7y5FojITcAQ4DZVjcuh2HJaZteiME6nkUtFZBdOHezsPNqg7c37IhqYrarxqroT\n2IqTOPIab65FD+BTAFX9CQjH6TAwv/Hq+yS13JoorPuPczK9FiLSGJiCkyTyaj00ZHItVDVGVUup\nahVVrYLTXnObql50Z2i5mDefkS9xShOISCmcqqgdORlkDvHmWuwGbgQQkTo4ieJgjkaZO8wGHnDv\nfmoGxKjqvsw2ypVVT+q77j8CjpfXYhRQCPjMbc/fraq3+S1oH/HyWuQLXl6LBUBbEdkEJAIDVDXP\nlbq9vBZPAVNFpB9Ow/ZDefGHpYh8gvPjoJTbHjMMKACgqpNx2mc6ANuB08DDXu03D14rY4wx2Si3\nVj0ZY4zJJSxRGGOMyZAlCmOMMRmyRGGMMSZDliiMMcZkyBKFyXVEJFFE1nr8Vclg3Srp9ZSZxWMu\ndXsfXed2eVHrIvbRU0QecF8/JCKXeSx7R0TqZnOcq0SkkRfbPCkikZd6bJN/WaIwudEZVW3k8bcr\nh47bTVUb4nQ2OSqrG6vqZFV93518CLjMY9m/VHVTtkR5Ls6JeBfnk4AlCnPRLFGYgOCWHL4XkV/c\nv2vSWOcKEVnplkLWi0hNd/79HvOniEhwJodbBtRwt73RHcNgg9vXf5g7/1U5NwbI6+6850XkPyJy\nN06fWx+5x4xwSwJRbqkj5cvdLXmMv8g4f8KjQzcRmSQiq8UZe+IFd97jOAlriYgscee1FZGf3Ov4\nmYgUyuQ4Jp+zRGFyowiPaqdZ7rwDQBtVvRLoDIxLY7uewFhVbYTzRR3tdtfQGWjhzk8EumVy/FuB\nDSISDkwHOqtqfZyeDHqJSEngTuAKVW0AvOS5sarOBFbj/PJvpKpnPBZ/7m6brDMw4yLjbI/TTUey\nIaoaBTQAWolIA1Udh9Ol9vWqer3blcdQ4Cb3Wq4G+mdyHJPP5couPEy+d8b9svRUABjv1skn4vRb\nlNpPwBARqQB8oarbRORG4Cpgldu9SQRO0knLRyJyBtiF0w11LWCnqm51l/8f0AcYjzPWxbsi8jXw\ntbcnpqoHRWSH28/ONqA28IO736zEGYrTbYvndbpXRB7B+VyXwxmgZ32qbZu5839wjxOKc92MSZcl\nChMo+gH7gYY4JeELBiVS1Y9F5GegIzBXRB7FGcnr/1R1sBfH6ObZgaCIlEhrJbdvoSY4nczdDfQF\nbsjCucwA7gW2ALNUVcX51vY6TmANTvvEW8BdIlIV+A9wtaoeFZHpOB3fpSbAQlXtmoV4TT5nVU8m\nUBQF9rnjB3TH6fztPCJSDdjhVrd8hVMFsxi4W0TKuOuUEO/HFP8dqCIiNdzp7sB3bp1+UVWdi5PA\nGqax7Qmcbs/TMgtnpLGuOEmDrMbpdmj3LNBMRGrjjN52CogRkbLAzenEsgJokXxOIlJQRNIqnRmT\nwhKFCRQTgQdFZB1Odc2pNNa5F/hNRNbijEvxvnun0VDgGxFZDyzEqZbJlKrG4vSu+ZmIbACSgMk4\nX7pfu/tbTtp1/NOBycmN2an2exTYDFRW1ZXuvCzH6bZ9vIHTK+w6nPGxtwAf41RnJXsbmC8iS1T1\nIM4dWZ+4x/kJ53oaky7rPdYYY0yGrERhjDEmQ5YojDHGZMgShTHGmAxZojDGGJMhSxTGGGMyZInC\nGGNMhixRGGOMydD/AxCmrNSgyhZrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f102a189278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_val,y_val_proba[:,1],drop_intermediate=False)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 128000 features, 615 are important\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAEyCAYAAABH+Yw/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f101b622b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "sns.distplot(gbc.feature_importances_,kde=False,ax=axes[0])\n",
    "sns.distplot(gbc.feature_importances_[gbc.feature_importances_ > 0],kde=False,ax=axes[1])\n",
    "\n",
    "importance_idx = gbc.feature_importances_ > 0\n",
    "\n",
    "#Store results so that we don't lose this data again\n",
    "with h5py.File(\"feature_data.hdf5\",\"w\") as f:\n",
    "    dset = f.create_dataset(\"importance_idx\",data=importance_idx)\n",
    "    dset2 = f.create_dataset(\"feature_importances\",data=gbc.feature_importances_)\n",
    "\n",
    "print(\"Of {} features, {} are important\".format(len(gbc.feature_importances_),sum(importance_idx)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=3 \n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=3 \n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=3 \n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=3 \n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=3 \n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=3 \n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=3, total=   2.3s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=3, total=   2.5s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=3, total=   2.6s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=3, total=   3.1s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=3, total=   3.8s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=3, total=   4.3s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=3, total=   5.7s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=3, total=   4.2s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=3, total=   5.3s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=3, total=   5.7s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=3, total=   6.0s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=3, total=   5.3s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=1, max_depth=3, total=   7.0s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=1, max_depth=3, total=   6.4s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=1, max_depth=3, total=   5.3s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=3, total=   6.1s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=3, total=   6.3s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=3, total=   6.3s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=3, total=   8.8s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=3, total=   8.8s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=3, total=   9.0s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=3, total=  13.2s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=3, total=  13.4s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=3, total=  13.0s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=3, total=  14.9s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=3, total=  14.0s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=3, total=  13.9s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:   34.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=1, max_depth=3, total=  13.6s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=3, total=  11.7s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=3, total=  11.4s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=1, max_depth=3, total=  16.0s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=1, max_depth=3, total=  17.0s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=3, total=  12.5s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=3, total=  16.8s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=3, total=  18.2s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=3, total=  19.6s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=3 .\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=3, total=  24.2s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=3 .\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=3, total=  27.4s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=3 .\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=3, total=  26.2s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=3, total=  27.2s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=5, total=   3.4s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=5, total=   5.1s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.25, max_depth=5, total=   3.7s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=3, total=  27.2s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=3, total=  27.6s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=5, total=   6.5s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=5, total=   6.9s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.5, max_depth=5, total=   7.7s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=3, total=  31.6s\n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=5, total=  10.4s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=5 \n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=5, total=  10.2s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.75, max_depth=5, total=  10.2s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=5, total=   9.3s\n",
      "[CV] learning_rate=0.01, n_estimators=200, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=3, total=  33.0s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=5, total=   8.9s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=0.8, max_depth=5, total=  10.6s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=3, total=  31.8s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=1, max_depth=5, total=  10.9s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=1, max_depth=5, total=  10.6s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=200, subsample=1, max_depth=5, total=  12.9s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=5, total=  12.2s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=5, total=  12.1s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.25, max_depth=5, total=  12.7s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=5, total=  16.4s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=5, total=  19.1s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.5, max_depth=5, total=  17.1s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=5, total=  24.1s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=5, total=  26.2s\n",
      "[CV] learning_rate=0.01, n_estimators=500, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.75, max_depth=5, total=  23.5s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=5, total=  24.9s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=5, total=  26.6s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=0.8, max_depth=5, total=  25.2s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=1, max_depth=5, total=  32.3s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=5, total=  22.9s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=5, total=  20.9s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=1, max_depth=5, total=  27.9s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=500, subsample=1, max_depth=5, total=  28.3s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.25, max_depth=5, total=  23.4s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=5, total=  38.4s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=5, total=  33.4s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.5, max_depth=5, total=  38.2s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=5 .\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=5, total=  47.3s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=5 .\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=5, total=  47.1s\n",
      "[CV] learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=5 .\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.75, max_depth=5, total=  51.7s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=3, total=   2.6s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=3, total=   2.6s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=5, total=  50.4s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=3, total=   2.5s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=3, total=   4.3s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=3, total=   4.3s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=3, total=   4.3s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=3, total=   4.0s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=3, total=   5.6s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=3, total=   5.1s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=3, total=   4.4s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=3, total=   5.9s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=5, total=  54.7s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=0.8, max_depth=5, total=  50.9s\n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=3, total=   5.5s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=1, max_depth=3 ..\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=1, max_depth=3, total=   6.4s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=3, total=   4.4s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=1, max_depth=3, total=   6.4s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=1, max_depth=3, total=   6.1s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=3, total=   5.8s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=5, total=  57.1s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=3, total=   6.3s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=3, total=   8.6s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=3, total=  10.1s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=3, total=  10.6s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=3, total=  11.9s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=3, total=  13.2s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=5, total=  57.0s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=3, total=  11.2s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=3, total=  14.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=3, total=  11.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.01, n_estimators=1000, subsample=1, max_depth=5, total= 1.1min\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=3, total=  12.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=1, max_depth=3, total=  16.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3, total=  10.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=1, max_depth=3, total=  15.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=1, max_depth=3, total=  16.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3, total=  10.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3, total=  12.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=3, total=  18.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=3, total=  16.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=3, total=  17.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=3 .\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=3, total=  19.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=3 .\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3, total=  20.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=3 .\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=3, total=  20.9s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=3, total=  22.1s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=5, total=   4.5s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=5, total=   4.9s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.25, max_depth=5, total=   4.8s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3, total=  22.9s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=5, total=   7.4s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3, total=  21.7s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=5, total=   7.0s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=3, total=  20.3s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.5, max_depth=5, total=   7.6s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=3, total=  25.3s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=3, total=  21.5s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=5, total=   8.0s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=5, total=  10.3s\n",
      "[CV] learning_rate=0.05, n_estimators=200, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.75, max_depth=5, total=  10.7s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=5, total=  11.3s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=5, total=  10.3s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=0.8, max_depth=5, total=  10.2s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=1, max_depth=5, total=  11.5s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done 148 tasks      | elapsed:  5.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=1, max_depth=5, total=  12.5s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=200, subsample=1, max_depth=5, total=  12.2s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=5, total=  11.0s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=5, total=   9.4s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.25, max_depth=5, total=  11.2s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=5, total=  15.5s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=5, total=  17.0s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=5, total=  13.8s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.5, max_depth=5, total=  17.3s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=5, total=  15.6s\n",
      "[CV] learning_rate=0.05, n_estimators=500, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.75, max_depth=5, total=  18.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=5, total=  18.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=5, total=  18.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=0.8, max_depth=5, total=  17.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=1, max_depth=5, total=  16.7s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=1, max_depth=5, total=  17.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=500, subsample=1, max_depth=5, total=  16.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=5, total=  17.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=5, total=  18.7s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=5, total=  15.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=5, total=  16.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=5, total=  14.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.5, max_depth=5, total=  18.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=5 .\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=5, total=  18.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=5 .\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=5, total=  19.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=5 .\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.75, max_depth=5, total=  18.0s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=5, total=  16.8s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=3, total=   2.6s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=3, total=   2.6s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=3 .\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=5, total=  15.3s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=3 .\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=5, total=  15.3s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=3 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=3, total=   2.6s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=3, total=   4.3s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=3, total=   4.3s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=3, total=   3.8s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=3 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=3, total=   5.4s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=3 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=3, total=   4.5s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=3 .\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=5, total=  17.3s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=1, max_depth=3 ...\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=5, total=  20.3s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=1, max_depth=3 ...\n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=1, max_depth=5, total=  17.7s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=1, max_depth=3 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=3, total=   5.4s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=3, total=   5.4s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=3, total=   5.7s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=3, total=   5.4s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=3 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=1, max_depth=3, total=   5.9s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=3 .\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=3, total=   4.8s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=3 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=1, max_depth=3, total=   6.3s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=1, max_depth=3, total=   6.7s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=3, total=   5.9s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=3, total=   6.2s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=3 .\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=3, total=   7.5s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=3 .\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=3, total=   8.3s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=3 .\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=3, total=   9.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=0.1, n_estimators=500, subsample=1, max_depth=3 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=3, total=  11.6s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=1, max_depth=3 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=3, total=  11.5s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=1, max_depth=3 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=3, total=  10.8s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=3, total=  11.1s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=3, total=  10.9s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=3, total=  10.3s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=1, max_depth=3, total=   8.2s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=3, total=   8.7s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=1, max_depth=3, total=  13.4s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=3, total=   8.0s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=1, max_depth=3, total=  13.0s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=3, total=   8.7s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=3, total=   9.6s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=3, total=   9.2s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=3, total=   9.1s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=3, total=  11.5s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=3, total=   9.2s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=3 ..\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=3, total=  11.2s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=5, total=   4.0s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=3, total=  12.2s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=3, total=  11.7s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=3, total=  11.2s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=5, total=   3.2s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=3, total=  12.1s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.25, max_depth=5, total=   4.6s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=3, total=  12.0s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=3, total=  12.6s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=5, total=   7.8s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=5, total=   6.8s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.5, max_depth=5, total=   7.4s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=1, max_depth=5 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=5, total=   9.2s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=1, max_depth=5 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=5, total=   9.0s\n",
      "[CV] learning_rate=0.1, n_estimators=200, subsample=1, max_depth=5 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.75, max_depth=5, total=   8.6s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=5, total=   7.9s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=5, total=   9.1s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=0.8, max_depth=5, total=   8.5s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=1, max_depth=5, total=  10.3s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=1, max_depth=5, total=   9.5s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=200, subsample=1, max_depth=5, total=   9.0s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=5, total=   9.3s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=5, total=   7.8s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.25, max_depth=5, total=   8.4s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=5, total=   9.2s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=5, total=   8.8s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=5 .\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.5, max_depth=5, total=   9.9s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=1, max_depth=5 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=5, total=   9.9s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=1, max_depth=5 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=5, total=   7.7s\n",
      "[CV] learning_rate=0.1, n_estimators=500, subsample=1, max_depth=5 ...\n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=5, total=   8.6s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.75, max_depth=5, total=   9.5s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=5, total=   8.8s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=0.8, max_depth=5, total=   7.6s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=1, max_depth=5, total=   9.0s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=1, max_depth=5, total=   9.1s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=500, subsample=1, max_depth=5, total=   9.7s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=5, total=  10.6s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=5, total=  10.7s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.25, max_depth=5, total=  10.1s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=5, total=   9.7s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=5, total=   9.2s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=5 \n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.5, max_depth=5, total=   8.5s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=5, total=   9.2s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=5, total=   9.3s\n",
      "[CV] learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=5 ..\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.75, max_depth=5, total=   8.4s\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=5, total=   9.3s\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=5, total=   6.1s\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=5, total=   8.1s\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=5, total=  10.1s\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=0.8, max_depth=5, total=   9.5s\n",
      "[CV]  learning_rate=0.1, n_estimators=1000, subsample=1, max_depth=5, total=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done 270 out of 270 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'learning_rate': 0.05, 'n_estimators': 1000, 'subsample': 0.25, 'max_depth': 3} with a score of -0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Cross validation of gradient boosted tree classifier\n",
    "gbc = GradientBoostingClassifier(random_state=0,max_features=307)\n",
    "scorer = make_scorer(log_loss,greater_is_better=False,needs_proba=True)\n",
    "\n",
    "\n",
    "estimators_range = [200,500,1000]\n",
    "lr_range = [0.01,0.05,0.1]\n",
    "subsample_range = [0.25,0.5,0.75,0.8,1]\n",
    "max_depth_range = [3,5]\n",
    "param_grid = {'n_estimators':estimators_range,'learning_rate':lr_range,\n",
    "             'subsample':subsample_range,'max_depth':max_depth_range}\n",
    "cv = StratifiedShuffleSplit(n_splits=3,test_size = 0.2,random_state = 0)\n",
    "grid = GridSearchCV(gbc,param_grid=param_grid,cv=cv,n_jobs=7,verbose=2,scoring=scorer)\n",
    "\n",
    "grid.fit(X_train[:,importance_idx],y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>Mean_minus_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>11.169703</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>-0.092310</td>\n",
       "      <td>-0.000813</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1000, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000925</td>\n",
       "      <td>-0.106442</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>-0.109960</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>0.920623</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>1.261179e-04</td>\n",
       "      <td>-0.114830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>8.461818</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>-0.097705</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1000, '...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-0.106601</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>-0.113189</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.302902</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.017448</td>\n",
       "      <td>1.340329e-06</td>\n",
       "      <td>-0.115153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>17.462342</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>-0.105128</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1000, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>-0.095453</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.125268</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>1.121453</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.014244</td>\n",
       "      <td>8.078207e-07</td>\n",
       "      <td>-0.119373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>17.244363</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>-0.098221</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1000, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.121551</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>-0.109510</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>1.332813</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>1.562441e-06</td>\n",
       "      <td>-0.123188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5.634684</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>-0.109505</td>\n",
       "      <td>-0.001264</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 500, 's...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>-0.124414</td>\n",
       "      <td>-0.001609</td>\n",
       "      <td>-0.124206</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>0.600071</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.020937</td>\n",
       "      <td>2.444106e-04</td>\n",
       "      <td>-0.130443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "40      11.169703         0.008961        -0.092310         -0.000813   \n",
       "70       8.461818         0.006178        -0.097705         -0.000208   \n",
       "41      17.462342         0.007804        -0.105128         -0.000232   \n",
       "55      17.244363         0.010060        -0.098221         -0.000217   \n",
       "65       5.634684         0.005291        -0.109505         -0.001264   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_subsample  \\\n",
       "40                0.05               3               1000            0.25   \n",
       "70                 0.1               3               1000            0.25   \n",
       "41                0.05               3               1000             0.5   \n",
       "55                0.05               5               1000            0.25   \n",
       "65                 0.1               3                500            0.25   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "40  {'learning_rate': 0.05, 'n_estimators': 1000, ...                1   \n",
       "70  {'learning_rate': 0.1, 'n_estimators': 1000, '...                2   \n",
       "41  {'learning_rate': 0.05, 'n_estimators': 1000, ...                4   \n",
       "55  {'learning_rate': 0.05, 'n_estimators': 1000, ...                3   \n",
       "65  {'learning_rate': 0.1, 'n_estimators': 500, 's...                5   \n",
       "\n",
       "         ...        split0_train_score  split1_test_score  split1_train_score  \\\n",
       "40       ...                 -0.000925          -0.106442           -0.000877   \n",
       "70       ...                 -0.000206          -0.106601           -0.000209   \n",
       "41       ...                 -0.000233          -0.095453           -0.000231   \n",
       "55       ...                 -0.000219          -0.121551           -0.000218   \n",
       "65       ...                 -0.001081          -0.124414           -0.001609   \n",
       "\n",
       "    split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "40          -0.109960           -0.000637      0.920623        0.000084   \n",
       "70          -0.113189           -0.000208      0.302902        0.000948   \n",
       "41          -0.125268           -0.000233      1.121453        0.001347   \n",
       "55          -0.109510           -0.000215      1.332813        0.001468   \n",
       "65          -0.124206           -0.001101      0.600071        0.000031   \n",
       "\n",
       "    std_test_score  std_train_score  Mean_minus_STD  \n",
       "40        0.022520     1.261179e-04       -0.114830  \n",
       "70        0.017448     1.340329e-06       -0.115153  \n",
       "41        0.014244     8.078207e-07       -0.119373  \n",
       "55        0.024967     1.562441e-06       -0.123188  \n",
       "65        0.020937     2.444106e-04       -0.130443  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results['Mean_minus_STD']=results['mean_test_score']-results['std_test_score']\n",
    "results.sort_values('Mean_minus_STD',inplace=True,ascending=False)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "Log-Loss: 0.57830431150536\n",
      "Positive Label\n",
      "Precision: 0.8392857142857143, Recall: 0.94, F1: 0.8867924528301886, Support: 150\n",
      "Negative Label\n",
      "Precision: 0.8392857142857143, Recall: 0.6351351351351351, F1: 0.723076923076923, Support: 74\n",
      "Accuracy: 0.8392857142857143\n",
      "\n",
      "Training Scores:\n",
      "Log-Loss: 0.0008599117379503291\n",
      "Positive Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Negative Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Retrain using best params\n",
    "gbc = GradientBoostingClassifier(random_state=0,subsample=0.25,learning_rate=0.05,n_estimators=1000)\n",
    "gbc.fit(X_train[:,importance_idx],y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_val_pred = gbc.predict(X_val[:,importance_idx])\n",
    "y_val_proba = gbc.predict_proba(X_val[:,importance_idx])\n",
    "y_train_pred = gbc.predict(X_train[:,importance_idx])\n",
    "y_train_proba = gbc.predict_proba(X_train[:,importance_idx])\n",
    "\n",
    "# Validation scores\n",
    "logl = log_loss(y_val,y_val_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_val,y_val_pred)\n",
    "acc = accuracy_score(y_val,y_val_pred)\n",
    "print(\"Validation Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\\n\".format(acc))\n",
    "\n",
    "# Training Scores\n",
    "logl = log_loss(y_train,y_train_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_train,y_train_pred)\n",
    "acc = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_val,y_val_proba[:,1],drop_intermediate=False)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] learning_rate=0.025, n_estimators=750, subsample=0.1, max_depth=3 \n",
      "[CV] learning_rate=0.025, n_estimators=750, subsample=0.1, max_depth=3 \n",
      "[CV] learning_rate=0.025, n_estimators=750, subsample=0.1, max_depth=3 \n",
      "[CV] learning_rate=0.025, n_estimators=750, subsample=0.25, max_depth=3 \n",
      "[CV] learning_rate=0.025, n_estimators=750, subsample=0.25, max_depth=3 \n",
      "[CV] learning_rate=0.025, n_estimators=750, subsample=0.8, max_depth=3 \n",
      "[CV] learning_rate=0.025, n_estimators=750, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=750, subsample=0.1, max_depth=3, total=   4.4s\n",
      "[CV] learning_rate=0.025, n_estimators=750, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=750, subsample=0.1, max_depth=3, total=   4.8s\n",
      "[CV] learning_rate=0.025, n_estimators=750, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=750, subsample=0.1, max_depth=3, total=   5.3s\n",
      "[CV] learning_rate=0.025, n_estimators=1000, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=750, subsample=0.25, max_depth=3, total=   8.5s\n",
      "[CV] learning_rate=0.025, n_estimators=1000, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=750, subsample=0.25, max_depth=3, total=   8.5s\n",
      "[CV] learning_rate=0.025, n_estimators=1000, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=750, subsample=0.25, max_depth=3, total=   9.5s\n",
      "[CV] learning_rate=0.025, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1000, subsample=0.1, max_depth=3, total=   7.0s\n",
      "[CV] learning_rate=0.025, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1000, subsample=0.1, max_depth=3, total=   4.8s\n",
      "[CV] learning_rate=0.025, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1000, subsample=0.1, max_depth=3, total=   6.3s\n",
      "[CV] learning_rate=0.025, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=750, subsample=0.8, max_depth=3, total=  20.2s\n",
      "[CV] learning_rate=0.025, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1000, subsample=0.25, max_depth=3, total=  11.6s\n",
      "[CV] learning_rate=0.025, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=750, subsample=0.8, max_depth=3, total=  18.9s\n",
      "[CV] learning_rate=0.025, n_estimators=1200, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=750, subsample=0.8, max_depth=3, total=  19.5s\n",
      "[CV] learning_rate=0.025, n_estimators=1200, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1000, subsample=0.25, max_depth=3, total=  12.1s\n",
      "[CV] learning_rate=0.025, n_estimators=1200, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1000, subsample=0.25, max_depth=3, total=  12.2s\n",
      "[CV] learning_rate=0.025, n_estimators=1200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1200, subsample=0.1, max_depth=3, total=   6.4s\n",
      "[CV] learning_rate=0.025, n_estimators=1200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1200, subsample=0.1, max_depth=3, total=   7.3s\n",
      "[CV] learning_rate=0.025, n_estimators=1200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1200, subsample=0.1, max_depth=3, total=   8.2s\n",
      "[CV] learning_rate=0.025, n_estimators=1200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1200, subsample=0.25, max_depth=3, total=  11.6s\n",
      "[CV] learning_rate=0.025, n_estimators=1200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1000, subsample=0.8, max_depth=3, total=  27.9s\n",
      "[CV] learning_rate=0.025, n_estimators=1200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1200, subsample=0.25, max_depth=3, total=  14.2s\n",
      "[CV] learning_rate=0.025, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1200, subsample=0.25, max_depth=3, total=  13.4s\n",
      "[CV] learning_rate=0.025, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1000, subsample=0.8, max_depth=3, total=  28.0s\n",
      "[CV] learning_rate=0.025, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1000, subsample=0.8, max_depth=3, total=  27.2s\n",
      "[CV] learning_rate=0.025, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1500, subsample=0.1, max_depth=3, total=  10.3s\n",
      "[CV] learning_rate=0.025, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1500, subsample=0.1, max_depth=3, total=   9.9s\n",
      "[CV] learning_rate=0.025, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1500, subsample=0.1, max_depth=3, total=   7.9s\n",
      "[CV] learning_rate=0.025, n_estimators=1500, subsample=0.8, max_depth=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:   56.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.025, n_estimators=1200, subsample=0.8, max_depth=3, total=  31.7s\n",
      "[CV] learning_rate=0.025, n_estimators=1500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1500, subsample=0.25, max_depth=3, total=  15.8s\n",
      "[CV] learning_rate=0.025, n_estimators=1500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1200, subsample=0.8, max_depth=3, total=  31.6s\n",
      "[CV] learning_rate=0.05, n_estimators=750, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1500, subsample=0.25, max_depth=3, total=  18.4s\n",
      "[CV] learning_rate=0.05, n_estimators=750, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1500, subsample=0.25, max_depth=3, total=  18.8s\n",
      "[CV] learning_rate=0.05, n_estimators=750, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=750, subsample=0.1, max_depth=3, total=   5.2s\n",
      "[CV] learning_rate=0.05, n_estimators=750, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1200, subsample=0.8, max_depth=3, total=  32.5s\n",
      "[CV] learning_rate=0.05, n_estimators=750, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=750, subsample=0.1, max_depth=3, total=   4.3s\n",
      "[CV] learning_rate=0.05, n_estimators=750, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=750, subsample=0.1, max_depth=3, total=   4.6s\n",
      "[CV] learning_rate=0.05, n_estimators=750, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=750, subsample=0.25, max_depth=3, total=   9.3s\n",
      "[CV] learning_rate=0.05, n_estimators=750, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=750, subsample=0.25, max_depth=3, total=   8.5s\n",
      "[CV] learning_rate=0.05, n_estimators=750, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=750, subsample=0.25, max_depth=3, total=   9.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.1, max_depth=3, total=   6.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1500, subsample=0.8, max_depth=3, total=  41.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=750, subsample=0.8, max_depth=3, total=  20.1s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1500, subsample=0.8, max_depth=3, total=  36.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.1, max_depth=3, total=   6.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.025, n_estimators=1500, subsample=0.8, max_depth=3, total=  37.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=750, subsample=0.8, max_depth=3, total=  19.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.1, max_depth=3, total=   6.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=750, subsample=0.8, max_depth=3, total=  21.7s\n",
      "[CV] learning_rate=0.05, n_estimators=1200, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3, total=  10.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1200, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3, total=  10.7s\n",
      "[CV] learning_rate=0.05, n_estimators=1200, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1200, subsample=0.1, max_depth=3, total=   7.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.25, max_depth=3, total=  12.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1200, subsample=0.1, max_depth=3, total=   7.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1200, subsample=0.1, max_depth=3, total=   7.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3, total=  18.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3, total=  22.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3, total=  22.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1200, subsample=0.25, max_depth=3, total=  14.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1200, subsample=0.25, max_depth=3, total=  15.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1200, subsample=0.25, max_depth=3, total=  11.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3, total=   9.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3, total=   8.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3, total=   9.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1200, subsample=0.8, max_depth=3, total=  20.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1200, subsample=0.8, max_depth=3, total=  20.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3, total=  15.0s\n",
      "[CV] learning_rate=0.75, n_estimators=750, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1200, subsample=0.8, max_depth=3, total=  20.3s\n",
      "[CV] learning_rate=0.75, n_estimators=750, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=750, subsample=0.1, max_depth=3, total=   4.7s\n",
      "[CV] learning_rate=0.75, n_estimators=750, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3, total=  13.1s\n",
      "[CV] learning_rate=0.75, n_estimators=750, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3, total=  13.9s\n",
      "[CV] learning_rate=0.75, n_estimators=750, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=750, subsample=0.1, max_depth=3, total=   4.6s\n",
      "[CV] learning_rate=0.75, n_estimators=750, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=750, subsample=0.1, max_depth=3, total=   4.9s\n",
      "[CV] learning_rate=0.75, n_estimators=750, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=750, subsample=0.8, max_depth=3, total=   3.6s\n",
      "[CV] learning_rate=0.75, n_estimators=750, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=750, subsample=0.25, max_depth=3, total=   7.9s\n",
      "[CV] learning_rate=0.75, n_estimators=750, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=750, subsample=0.25, max_depth=3, total=   8.6s\n",
      "[CV] learning_rate=0.75, n_estimators=1000, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=750, subsample=0.25, max_depth=3, total=   9.4s\n",
      "[CV] learning_rate=0.75, n_estimators=1000, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.8, max_depth=3, total=  21.7s\n",
      "[CV] learning_rate=0.75, n_estimators=1000, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=750, subsample=0.8, max_depth=3, total=   3.3s\n",
      "[CV] learning_rate=0.75, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=750, subsample=0.8, max_depth=3, total=   3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=0.75, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.8, max_depth=3, total=  22.3s\n",
      "[CV] learning_rate=0.75, n_estimators=1000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.8, max_depth=3, total=  19.8s\n",
      "[CV] learning_rate=0.75, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1000, subsample=0.1, max_depth=3, total=   5.8s\n",
      "[CV] learning_rate=0.75, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1000, subsample=0.1, max_depth=3, total=   6.6s\n",
      "[CV] learning_rate=0.75, n_estimators=1000, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1000, subsample=0.8, max_depth=3, total=   3.4s\n",
      "[CV] learning_rate=0.75, n_estimators=1200, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1000, subsample=0.1, max_depth=3, total=   6.8s\n",
      "[CV] learning_rate=0.75, n_estimators=1200, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1000, subsample=0.8, max_depth=3, total=   3.4s\n",
      "[CV] learning_rate=0.75, n_estimators=1200, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1000, subsample=0.8, max_depth=3, total=   3.1s\n",
      "[CV] learning_rate=0.75, n_estimators=1200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1000, subsample=0.25, max_depth=3, total=  10.6s\n",
      "[CV] learning_rate=0.75, n_estimators=1200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1000, subsample=0.25, max_depth=3, total=  10.4s\n",
      "[CV] learning_rate=0.75, n_estimators=1200, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1000, subsample=0.25, max_depth=3, total=  11.3s\n",
      "[CV] learning_rate=0.75, n_estimators=1200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1200, subsample=0.1, max_depth=3, total=   6.5s\n",
      "[CV] learning_rate=0.75, n_estimators=1200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1200, subsample=0.1, max_depth=3, total=   8.0s\n",
      "[CV] learning_rate=0.75, n_estimators=1200, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1200, subsample=0.1, max_depth=3, total=   8.2s\n",
      "[CV] learning_rate=0.75, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1200, subsample=0.8, max_depth=3, total=   3.3s\n",
      "[CV] learning_rate=0.75, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1200, subsample=0.8, max_depth=3, total=   3.6s\n",
      "[CV] learning_rate=0.75, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1200, subsample=0.8, max_depth=3, total=   3.7s\n",
      "[CV] learning_rate=0.75, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1200, subsample=0.25, max_depth=3, total=  14.1s\n",
      "[CV] learning_rate=0.75, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1500, subsample=0.1, max_depth=3, total=   9.9s\n",
      "[CV] learning_rate=0.75, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1500, subsample=0.1, max_depth=3, total=   8.6s\n",
      "[CV] learning_rate=0.75, n_estimators=1500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1200, subsample=0.25, max_depth=3, total=  13.6s\n",
      "[CV] learning_rate=0.75, n_estimators=1500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1500, subsample=0.1, max_depth=3, total=   8.7s\n",
      "[CV] learning_rate=0.75, n_estimators=1500, subsample=0.8, max_depth=3 \n",
      "[CV]  learning_rate=0.75, n_estimators=1200, subsample=0.25, max_depth=3, total=  14.0s\n",
      "[CV]  learning_rate=0.75, n_estimators=1500, subsample=0.8, max_depth=3, total=   3.2s\n",
      "[CV]  learning_rate=0.75, n_estimators=1500, subsample=0.8, max_depth=3, total=   3.2s\n",
      "[CV]  learning_rate=0.75, n_estimators=1500, subsample=0.8, max_depth=3, total=   3.0s\n",
      "[CV]  learning_rate=0.75, n_estimators=1500, subsample=0.25, max_depth=3, total=  14.3s\n",
      "[CV]  learning_rate=0.75, n_estimators=1500, subsample=0.25, max_depth=3, total=  13.1s\n",
      "[CV]  learning_rate=0.75, n_estimators=1500, subsample=0.25, max_depth=3, total=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done 108 out of 108 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'learning_rate': 0.05, 'n_estimators': 1500, 'subsample': 0.25, 'max_depth': 3} with a score of -0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Cross validation of gradient boosted tree classifier\n",
    "gbc = GradientBoostingClassifier(random_state=0,max_features=307)\n",
    "scorer = make_scorer(log_loss,greater_is_better=False,needs_proba=True)\n",
    "\n",
    "\n",
    "estimators_range = [750,1000,1200,1500]\n",
    "lr_range = [0.025,0.05,0.75]\n",
    "subsample_range = [0.10,0.25,0.8]\n",
    "max_depth_range = [3]\n",
    "param_grid = {'n_estimators':estimators_range,'learning_rate':lr_range,\n",
    "             'subsample':subsample_range,'max_depth':max_depth_range}\n",
    "cv = StratifiedShuffleSplit(n_splits=3,test_size = 0.2,random_state = 0)\n",
    "grid = GridSearchCV(gbc,param_grid=param_grid,cv=cv,n_jobs=7,verbose=2,scoring=scorer)\n",
    "\n",
    "grid.fit(X_train[:,importance_idx],y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>Mean_minus_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14.000233</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>-0.085017</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1500, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.088336</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.114821</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>0.776023</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.025797</td>\n",
       "      <td>8.376418e-07</td>\n",
       "      <td>-0.110814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.631247</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>-0.094430</td>\n",
       "      <td>-0.002409</td>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'learning_rate': 0.025, 'n_estimators': 1500,...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.107968</td>\n",
       "      <td>-0.002420</td>\n",
       "      <td>-0.104418</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>1.346382</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.016699</td>\n",
       "      <td>3.234929e-04</td>\n",
       "      <td>-0.111129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.581832</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>-0.087881</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1200, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>-0.093942</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>-0.115244</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>1.365647</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>3.475395e-05</td>\n",
       "      <td>-0.113065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.127332</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>-0.092310</td>\n",
       "      <td>-0.000813</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1000, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000925</td>\n",
       "      <td>-0.106442</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>-0.109960</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>1.261179e-04</td>\n",
       "      <td>-0.114830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.451103</td>\n",
       "      <td>0.011604</td>\n",
       "      <td>-0.098730</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1500, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001960</td>\n",
       "      <td>-0.112083</td>\n",
       "      <td>-0.002230</td>\n",
       "      <td>-0.111168</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>0.492600</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.018241</td>\n",
       "      <td>2.265300e-04</td>\n",
       "      <td>-0.116971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "22      14.000233         0.009735        -0.085017         -0.000216   \n",
       "10      17.631247         0.010168        -0.094430         -0.002409   \n",
       "19      13.581832         0.010288        -0.087881         -0.000283   \n",
       "16      11.127332         0.008032        -0.092310         -0.000813   \n",
       "21       9.451103         0.011604        -0.098730         -0.001955   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_subsample  \\\n",
       "22                0.05               3               1500            0.25   \n",
       "10               0.025               3               1500            0.25   \n",
       "19                0.05               3               1200            0.25   \n",
       "16                0.05               3               1000            0.25   \n",
       "21                0.05               3               1500             0.1   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "22  {'learning_rate': 0.05, 'n_estimators': 1500, ...                1   \n",
       "10  {'learning_rate': 0.025, 'n_estimators': 1500,...                4   \n",
       "19  {'learning_rate': 0.05, 'n_estimators': 1200, ...                2   \n",
       "16  {'learning_rate': 0.05, 'n_estimators': 1000, ...                3   \n",
       "21  {'learning_rate': 0.05, 'n_estimators': 1500, ...                5   \n",
       "\n",
       "         ...        split0_train_score  split1_test_score  split1_train_score  \\\n",
       "22       ...                 -0.000215          -0.088336           -0.000215   \n",
       "10       ...                 -0.002800          -0.107968           -0.002420   \n",
       "19       ...                 -0.000311          -0.093942           -0.000303   \n",
       "16       ...                 -0.000925          -0.106442           -0.000877   \n",
       "21       ...                 -0.001960          -0.112083           -0.002230   \n",
       "\n",
       "    split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "22          -0.114821           -0.000217      0.776023        0.001682   \n",
       "10          -0.104418           -0.002008      1.346382        0.001734   \n",
       "19          -0.115244           -0.000234      1.365647        0.000075   \n",
       "16          -0.109960           -0.000637      0.825288        0.001302   \n",
       "21          -0.111168           -0.001675      0.492600        0.000021   \n",
       "\n",
       "    std_test_score  std_train_score  Mean_minus_STD  \n",
       "22        0.025797     8.376418e-07       -0.110814  \n",
       "10        0.016699     3.234929e-04       -0.111129  \n",
       "19        0.025184     3.475395e-05       -0.113065  \n",
       "16        0.022520     1.261179e-04       -0.114830  \n",
       "21        0.018241     2.265300e-04       -0.116971  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results['Mean_minus_STD']=results['mean_test_score']-results['std_test_score']\n",
    "results.sort_values('Mean_minus_STD',inplace=True,ascending=False)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "Log-Loss: 0.6473757215876269\n",
      "Positive Label\n",
      "Precision: 0.8373493975903614, Recall: 0.9266666666666666, F1: 0.879746835443038, Support: 150\n",
      "Negative Label\n",
      "Precision: 0.8103448275862069, Recall: 0.6351351351351351, F1: 0.712121212121212, Support: 74\n",
      "Accuracy: 0.8303571428571429\n",
      "\n",
      "Training Scores:\n",
      "Log-Loss: 0.000214689394098518\n",
      "Positive Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Negative Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Retrain using best params\n",
    "gbc = GradientBoostingClassifier(random_state=0,subsample=0.25,learning_rate=0.05,n_estimators=1500)\n",
    "gbc.fit(X_train[:,importance_idx],y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_val_pred = gbc.predict(X_val[:,importance_idx])\n",
    "y_val_proba = gbc.predict_proba(X_val[:,importance_idx])\n",
    "y_train_pred = gbc.predict(X_train[:,importance_idx])\n",
    "y_train_proba = gbc.predict_proba(X_train[:,importance_idx])\n",
    "\n",
    "# Validation scores\n",
    "logl = log_loss(y_val,y_val_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_val,y_val_pred)\n",
    "acc = accuracy_score(y_val,y_val_pred)\n",
    "print(\"Validation Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\\n\".format(acc))\n",
    "\n",
    "# Training Scores\n",
    "logl = log_loss(y_train,y_train_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_train,y_train_pred)\n",
    "acc = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcjXX7wPHPNTPMYt+SyC5L1posKbRYQqsKlUqepxAV\nPYqHUkoLRWRNi1+rp5RIIkRSyVKWLCHESHZjnTHL9fvjvmccY5YzzJkz58z1fr3m5dz7dd/OOdf5\nfr/3/f2KqmKMMcZkJMTfARhjjMnbLFEYY4zJlCUKY4wxmbJEYYwxJlOWKIwxxmTKEoUxxphMWaII\nAiJyr4h86+84/E1EKorIcREJzcVjVhYRFZGw3DqmL4nIehFpdR7bBe17UERaiUiMv+PwJ0sUOUxE\ndojIKfcL6x8RmSoihX15TFX9SFXb+PIYeZF7rW9MmVbVnapaWFWT/BmXv7gJq/qF7ENVL1fVxVkc\n55zkmF/fg/mFJQrfuFlVCwMNgUbAID/Hc178+Ss5WH6hZ4ddb5NXWaLwIVX9B5iHkzAAEJFwEXlN\nRHaKyF4RmSQikR7LbxWR1SJyVET+FJF27vxiIvKOiOwRkd0i8mJKFYuIPCgiS93XE0XkNc84RGSm\niPR3X18iIp+LyH4R2S4ij3ms95yITBeRD0XkKPBg2nNy43jf3f4vERkiIiEecfwoIuNEJFZENonI\nDWm2zewcfhSR0SJyEHhORKqJyHciclBEDojIRyJS3F3/A6Ai8JVbensq7S9dEVksIi+4+z0mIt+K\nSGmPeO53z+GgiDyTtoSS5rwjReR1d/1YEVnq+f8G3Ov+nx4QkcEe2zUWkZ9F5Ih73uNEpKDHchWR\nR0VkC7DFnTdGRHa574FVInKtx/qhIvJf971xzF1+qYgscVdZ416Pzu76Hd330xER+UlE6nvsa4eI\nPC0ia4ETIhLmeQ3c2Fe6cewVkVHupinHOuIeq5nne9Dd9nIRmS8ih9xt/5vBdc3w8+DG9ovH/2cv\ncarGItzpz8QptceKyBIRudxjv1NFZIKIfOPG+KOIXCwib4jIYfe92SjNtRgkIhvc5e+lHCedmDP8\nDAUtVbW/HPwDdgA3uq8rAOuAMR7LRwOzgJJAEeAr4GV3WWMgFmiNk8TLA7XcZTOAyUAh4CJgOfCI\nu+xBYKn7ugWwCxB3ugRwCrjE3ecq4FmgIFAV2Aa0ddd9DkgAbnPXjUzn/N4HZrqxVwY2Az084kgE\n+gEFgM7u+ZT08hwSgb5AGBAJVHevRThQBucL6o30rrU7XRlQIMydXgz8CVzm7m8x8Iq7rA5wHLjG\nvRavued+Ywb/r+Pd7csDocDVblwpx5ziHqMBEA/Udre7EmjqnlNlYCPwhMd+FZiP836IdOfdB5Ry\nt3kS+AeIcJcNwHlP1QTEPV4pj31V99h3I2Af0MSN+QH3moV7XL/VwKUex069psDPQDf3dWGgaXrX\nOZ33YBFgjxt7hDvdJIPrmtnnIcT9P38OqAEcBhp5bPuQu0048Aaw2mPZVOCAe/0jgO+A7cD97rV4\nEViU5r30u3stSgI/Ai+6y1oBMR4xZfgZCtY/vwcQbH/uG+44cMz9MC0EirvLBDgBVPNYvxmw3X09\nGRidzj7L4nz5RHrM65ryRk/zIRVgJ9DCnf438J37ugmwM82+BwHvua+fA5Zkcm6hwGmgjse8R4DF\nHnH8jZuk3HnLgW5ensPOjI7trnMb8Fuaa51Vohjisbw3MNd9/SzwiceyKPfczkkU7pfDKaBBOstS\njlkhzTl3yeAcngBmeEwrcH0W53045djAH8CtGayXNlFMBF5Is84fQEuP6/dQOu/flESxBHgeKJ3B\nOWeUKLp6/j9lcl6Zfh48jnUIJ8EOymRfxd2YirnTU4EpHsv7Ahs9pusBR9Kcd0+P6fbAn+7rVpxJ\nFJl+hoL1z+olfeM2VV0gIi2Bj4HSwBGcX8VRwCoRSVlXcL6Awfk1Myed/VXC+YW+x2O7EJySw1lU\nVUVkGs6HdQlwD/Chx34uEZEjHpuEAj94TJ+zTw+l3Tj+8pj3F86v7BS71f30eCy/xMtzOOvYIlIW\nGANci/PLMQTnSzM7/vF4fRLnlzFuTKnHU9WT4lR5pac0zq/SP7N7HBG5DBgFROP834fh/CL1lPa8\n/wP0cGNUoKgbAzjvkczi8FQJeEBE+nrMK+juN91jp9EDGAZsEpHtwPOqOtuL43obY1afB1R1h4gs\nwvniHp+6klNlORy4y91PsruoNE4pFmCvx7FOpTOd9iYTz2uR8r5Ny5vPUNCxNgofUtXvcX7ZpLQZ\nHMB5g16uqsXdv2LqNHyD80atls6uduH8Gi/tsV1RVb08nXUBPgHuFJFKOL+APvfYz3aPfRRX1SKq\n2t4z7ExO6QBO9Uwlj3kVgd0e0+XF41PvLv/by3NIe+yX3Hn1VLUoTpWMZLJ+duzBqRoEnDYInOqe\n9BwA4kj//yYrE4FNQA33HP7L2ecAHufhtkc8BdwNlFDV4jhffCnbZPQeSc8uYHia/+8oVf0kvWOn\npapbVLUrTjXhq8B0ESmU2TYex63qRXxZfR4QkQ44pYyFwEiPbe8BbgVuBIrhlDzg3GubHZd6vE55\n36blzWco6Fii8L03gNYi0kBVk3HqskeLyEUAIlJeRNq6674DdBeRG0QkxF1WS1X3AN8Cr4tIUXdZ\nNbfEcg5V/Q3nQ/g2ME9VU379LAeOuY2EkW7DaF0RucqbE1HnttNPgeEiUsRNRP05U2IB50vlMREp\nICJ3AbWBOdk9B1cRnGq8WBEpj1M/72kv3n0hpWc6cLOIXC1O4/JzZPAl4/6/vQuMchsyQ90G3HAv\njlMEOAocF5FaQC8v1k8E9gNhIvIsTokixdvACyJSQxz1RSQlwaW9HlOAniLSxF23kIh0EJEiXsSN\niNwnImXc8095DyW7sSWT8bWfDZQTkSfcxuoiItIk7UpZfR7EufHgbeBfOO0rN4tIyhdyEZwfHgdx\nSiUveXNOWXhURCqISElgMPC/dNa5oM9QoLJE4WOquh+nAfhZd9bTwFZgmTh3Fi3AaZhEVZcD3XEa\n+GKB7znz6/1+nGqDDTjVL9OBcpkc+mOcX1sfe8SSBHTEuQtrO2eSSbFsnFJfnHrlbcBSd//veiz/\nBafh8QBO1cCdqppSpZPdc3geuALnWnwNfJFm+cvAEHHu6PlPNs4BVV3vnss0nNLFcZyG3/gMNvkP\nTiPyCpw681fx7vPzH5xfv8dwvhTT+/LxNA+Yi3OTwF84JRnPKpFROMn6W5wE9A5OIzo4ye7/3Otx\nt6quxGmjGodzvbeSzp1smWgHrBeR4zhVgF1U9ZSqnsT5v/3RPVZTz41U9RjOTQg341TJbQGuy+AY\nGX4egLeAmao6x30P9QDedhPj++712Y3zflqWjfPKyMc413UbTtXZi2lXyKHPUMBJuTPGmAsmIg8C\n/1LVa/wdS3aJ81DkEZwqou3+jsfkLhHZgfPeXeDvWPIiK1GYfEtEbhaRKLfe/TWcEsMO/0ZlTN5j\nicLkZ7fiNFj+jVNd1kWtiG3MOazqyRhjTKasRGGMMSZTAffAXenSpbVy5cr+DsMYYwLKqlWrDqhq\nmfPZNuASReXKlVm5cqW/wzDGmIAiIn9lvVb6rOrJGGNMpixRGGOMyZQlCmOMMZmyRGGMMSZTliiM\nMcZkyhKFMcaYTPksUYjIuyKyT0R+z2C5iMhYEdkqImtF5ApfxWKMMeb8+bJEMRWnm+KM3ITTv04N\n4GGcAV6MMcbksNOnky5oe589cKeqS0Skciar3Aq873bCtkxEiotIOXeAG2OMSd8XHWB7eiMGm/QM\n+Ko1v/2d2bAvWfPnk9nlOXtAlhh33jmJQkQexil1ULFixVwJzhi/sS9Ck4PqXryPsUvPGWAwWwKi\nCw9VfQtntCuio6Otu1sTuCwJ5Iwq7eGOr/0dRZ60YcN+fv11D/fdVx+A+1Vp+UosVaqcM2Cf1/yZ\nKHZz9mDmFdx5xgQvb5OEfRGabDp5MoEXX1zCyJE/ERoqNG1agerVSyIiVK5c/IL27c9EMQvoIyLT\ngCZArLVPmKCSWenhSSsYm5zzzTdbePTROWzffgSAHj2upFSpyCy28p7PEoWIfAK0AkqLSAwwFCgA\noKqTgDlAe5yB1U8C3X0VizF+kVGSqNI+d+MwQWv37qM88cQ8pk/fAED9+mWZNKkDzZpdmsWW2ePL\nu566ZrFcgUd9dXxj8gwrPRgfefTROcyc+QdRUQUYNqwVjz/elLCwnH/qISAas40xxjgSE5NTk8Gr\nr95IgQKhvP56GypWLOazY1oXHsYYEwBiY+Po23cOHTp8jFMhAzVrluazz+7yaZIAK1EYkzW7pdX4\nkary2WcbeOKJuezZc5zQUGH16n9o1OjCHqLLDksUxmTlQpKENVybC/Dnn4fo0+cb5s7dCkCzZhWY\nNKkj9euXzdU4LFGY4OHrX/7WKG1y0Wuv/cQzzywiLi6R4sUjePXVG/nXv64gJERyPRZLFCYw+Lv6\nx0oGJpedPJlAXFwi3brV57XX2nDRRYX8FoslChMY7IlmE+T27z/BH38c5JprnP7snn66Oa1aVaZF\ni0p+jswShQk0Vv1jgkxysvLuu7/x1FPzCQsLYdOmPpQsGUl4eFieSBJgicLkNn9XIRmTh/z++z56\n9pzNjz86HWm3bl2VkycTKFky57rfyAmWKEzO8XUSsHYCEyROnDjNsGHfM2rUMhITkylbthBvvNGO\nzp0vRyT3G6uzYonC5BxrRzDGK3fe+Rlz525FBHr3jmb48BsoXjzC32FlyBKF8U52SgvWjmBMpp5+\nujl79x5n4sQONGlSwd/hZMkShfFOdkoLxphUiYnJvPnmL+zYcYQxY24CoFWryqxc+bBfnok4H5Yo\njJUWjPGR5ct388gjs1m9+h8AHn74Si6//CKAgEkSYJ0CGrDSgjE57MiROHr3/pqmTd9m9ep/qFSp\nGF991TU1SQQaK1GYM6y0YMwFmzbtd554Yi57954gLCyEJ59sxjPPtKBQoYL+Du28WaIwxpgc9O23\nf7J37wmaN7+UiRM7UK9e7nbg5wuWKIwx5gLExyeye/cxqlYtAcCIEa259tqKPPBAw4Bqh8iMtVEY\nY8x5+u677dSvP4kOHT7m9OkkAEqXjqJ790ZBkyTAEoUxxmTb3r3H6dZtBjfc8D6bNx8EICbmqJ+j\n8h2resqPrL8lY85LcrIyZcoqBg5cyJEjcUREhDFkyLUMGNCcggVD/R2ez1iiyI/SSxJ266sxWbr9\n9v8xa9YfALRtW43x49tTrVpJP0fle5Yo8jO7HdaYbLnjjlosX76bMWPacddddfJkB36+YInCGGMy\nMGvWH8TEHKV376sAuP/+BtxxR22KFAn3c2S5yxKFMcaksXNnLI899g0zZ/5BeHgo7dpVp2rVEohI\nvksSYInCGGNSJSQkMXbsLwwdupgTJxIoUqQgL754PZUqFfN3aH5licIYY4Bly2J45JHZrF27F4C7\n7qrD6NFtKV++qJ8j8z9LFMYYAzzzzCLWrt1LlSrFGTeuPe3b1/B3SHmGJQpjTL6kqhw7dpqiRZ02\nh3HjbuL999cweHALoqIK+Dm6vMWezDbG5Dt//HGAG2/8gDvu+B+qzm3iNWuWZvjwGyxJpMNKFMaY\nfCMuLpGXX/6BV175kdOnkyhVKpIdO45QpUoJf4eWp1miMMbkC/Pn/0nv3nPYuvUQAA891JARI1pT\nqlSUnyPL+3xa9SQi7UTkDxHZKiID01leUUQWichvIrJWRKwfCWNMjlJVHnpoJm3afMjWrYeoU6cM\nS5Y8yDvv3GpJwks+K1GISCgwHmgNxAArRGSWqm7wWG0I8KmqThSROsAcoLKvYjLG5D8iQuXKxYmM\nDOPZZ1vSv3+zoO7Azxd8WfXUGNiqqtsARGQacCvgmSgUSLlJuRjwtw/jMcbkE6tX/8OePce46Sbn\nFtenn25Ot271rS3iPPmy6qk8sMtjOsad5+k54D4RicEpTfRNb0ci8rCIrBSRlfv37/dFrMaYIHDs\nWDz9+8/jyivf4oEHvuTQoVMAhIeHWZK4AP6+PbYrMFVVKwDtgQ9E5JyYVPUtVY1W1egyZcrkepDG\nmLxNVZkxYyN16kxg9OhlANxzTz0KFPD3V1xw8GXV027gUo/pCu48Tz2AdgCq+rOIRAClgX0+jMsY\nE0T++usIffp8w+zZmwGIjr6EyZM7csUV5fwcWfDwZbpdAdQQkSoiUhDoAsxKs85O4AYAEakNRABW\nt2SM8Yqq0qnTp8yevZmiRcMZN+4mli3rYUkih/msRKGqiSLSB5gHhALvqup6ERkGrFTVWcCTwBQR\n6YfTsP2gpjwmaYwxGUhOVkJCBBHhtdfaMGnSSkaPbku5ckX8HVpQkkD7Xo6OjtaVK1f6O4zA9ro7\nKpeNcGcCzMGDJxk4cAEAU6bc4udoAouIrFLV6PPZ1p7MDnZfdEh/jGxjAoiq8v77a/jPf+Zz4MBJ\nChYMZejQVlSoYF2A5wZLFMEkO0mhij0EbwLDxo376dXra77//i8AWrWqzMSJHSxJ5CJLFMEkoyRR\npT3c8XXuxmLMBVJVnn12Ea+++iMJCcmULh3F66+3oVu3+oiIv8PLVyxRBCNrezBBQETYvfsYCQnJ\n/PvfV/DKKzdSsmSkv8PKlyxRBDJrfzBB5u+/j3HgwEnq1y8LwIgRrenRoxHNm1f0c2T5mz22GMjS\nSxLW9mACUFJSMuPGLad27fF06TKd06eTAChdOsqSRB5gJYpgYFVNJoD9+useHnlkNitXOn2CtmhR\niaNH4yld2roAzyu8ShTuk9UVVXWrj+MxGbFqJhNkjh6N55lnvmPcuBUkJysVKhRl7Nh23HZbLWus\nzmOyTBQi0gEYBRQEqohIQ2Coqt7u6+CMh8zuaDImwKgqLVq8x5o1ewkNFfr3b8pzz7WiSJFwf4dm\n0uFNiWIY0ARYBKCqq0Wkuk+jMhmzaiYTBESEfv2aMmHCSiZP7kjDhhf7OySTCW8SRYKqHklTFLRv\nK2OM106fTmLUqJ8JDRUGDGgOwP33N+C+++oTGmr31OR13iSKjSJyNxAiIlWAx4Blvg3LGBMsfvjh\nL3r2/JoNG/YTHh7K/fc3oGzZwogIoaHWFhEIvEnlfYArgWTgCyAeeNyXQRljAt+BAyd56KGZtGgx\nlQ0b9lOjRklmz76HsmUL+zs0k03elCjaqurTwNMpM0TkDpykYYwxZ1FVpk5dzYAB8zl48BQFC4Yy\naNA1DBx4DRERdkd+IPLmf20I5yaFwenMMznJboc1AezDD9dx8OAprr++ChMmtKdmzdL+DslcgAwT\nhYi0xRmmtLyIjPJYVBSnGsr4kj11bQLIyZMJxMbGUa5cEUSECRPas2LF39x7bz17JiIIZFai2Af8\nDsQB6z3mHwMG+jIo48FuhzV53DffbOHRR+dQtWoJ5s/vhohQs2ZpK0UEkQwThar+BvwmIh+palwu\nxmSMCQC7dx/liSfmMX36BgCKFAnn4MFT1vVGEPKmjaK8iAwH6gARKTNV9TKfRWWMybOSkpIZP34F\nQ4Z8x7FjpylUqADDhl3HY481ISzMnokIRt4kiqnAi8BrwE1Ad+yBu5xlDdcmQCQnKy1bTuXHH3cB\ncNtttRgzph0VKxbzc2TGl7xJ/1GqOg9AVf9U1SE4CcPkFOvHyQSIkBChTZtqXHppUWbO7MKMGZ0t\nSeQD3pQo4kUkBPhTRHoCu4Eivg0riGSntGAN1yaPUVU+/XQ9YWEhdOpUB4Cnn25O//7NKFy4oJ+j\nM7nFm0TRDyiE03XHcKAY8JAvgwoq3iYJKz2YPObPPw/Ru/ccvv32T8qUieL666tQokQk4eFhhFsn\nr/lKlolCVX9xXx4DugGISHlfBhWUrLRgAkR8fCIjR/7E8OE/EBeXSIkSEQwffj3FikVkvbEJSpkm\nChG5CigPLFXVAyJyOU5XHtcDFXIhPmNMLlq8eAe9en3Npk0HAOjWrT6vvdaGiy4q5OfIjD9l2Jgt\nIi8DHwH3AnNF5DmcMSnWAHZrrDFBJikpmd69nSRRs2Ypvvvuft5//3ZLEibTEsWtQANVPSUiJYFd\nQD1V3ZY7oRljfC05WYmLSyQqqgChoSFMnNiBJUv+4qmnmhMebh34GUdm74Q4VT0FoKqHRGSzJQlj\ngse6dXvp2fNratUqxTvv3ApAy5aVadmysn8DM3lOZomiqoik9BArOONlp/YYq6p3+DQyY4xPnDhx\nmmHDvmfUqGUkJiazffthDh8+RYkSkf4OzeRRmSWKTmmmx/kyEGOM73311R/06fMNO3fGIgK9e0cz\nfPgNFC9udzSZjGXWKeDC3AzEGOM7iYnJdO48nS++2AhAw4YXM3lyRxo3tjvdTdastcqYfCAsLIRi\nxcIpXLggL7xwHX36NLYO/IzXfPpOEZF2IvKHiGwVkXTHsBCRu0Vkg4isF5GPfRmPMfnJL7/E8Msv\nManTI0e2ZuPGR3niiaaWJEy2eF2iEJFwVY3PxvqhwHigNRADrBCRWaq6wWOdGsAgoLmqHhaRi7wP\n3RiTniNH4hg0aAGTJ6+iVq3SrF7dk4IFQylVysaJMOcny58VItJYRNYBW9zpBiLyphf7bgxsVdVt\nqnoamIbzbIanfwPjVfUwgKruy1b0xphUqsrHH6+jVq1xTJq0itDQEG65pSZJSTZysbkw3pQoxgId\ngS8BVHWNiFznxXblcR7SSxEDNEmzzmUAIvIjEAo8p6pzvdi3McbDli0H6d17DgsWOI86NW9+KZMm\ndaRuXSukmwvnTaIIUdW/0gyQnpSDx68BtMLpO2qJiNRT1SOeK4nIw8DDABUrVsyhQxsTHBISkrj+\n+veJiTlKyZKRjBhxI927NyIkRLLe2BgveJModolIY0Dddoe+wGYvttsNXOoxXcGd5ykG+EVVE4Dt\nIrIZJ3Gs8FxJVd8C3gKIjo62bliNwalqEhEKFAhl+PDrWbRoByNG3EiZMtY3k8lZ3tz60AvoD1QE\n9gJN3XlZWQHUEJEqIlIQ6ALMSrPOlzilCUSkNE5VlHUTYkwm9u49TrduM3jxxSWp8+6/vwHvvXer\nJQnjE96UKBJVtUt2d6yqiSLSB5iH0/7wrqquF5FhwEpVneUuayMiG3Cqswao6sHsHsuY/CA5WZky\nZRUDBy7kyJE4iheP4IknmlKkiI0iZHzLm0SxQkT+AP4HfKGqx7zduarOAeakmfesx2vFKa3093af\nxuRHa9b8Q8+eX7NsmfNcRLt21Rk/vr0lCZMrvBnhrpqIXI1TdfS8iKwGpqnqNJ9HZ0w+l5CQxKBB\nC3njjWUkJSnlyhVmzJh23HlnHdLcYGKMz3j1eKaq/qSqjwFXAEdxBjQyxvhYWFgIv/32D8nJSt++\njdm48VHuuutySxImV2VZohCRwjgPynUBagMzgat9HJcx+dbOnbEkJSVTpUoJRIRJkzoQGxtPdPQl\n/g7N5FPetFH8DnwFjFDVH3wcjzH5VkJCEmPG/MLQoYtp1qwC8+d3Q0SoUaOUv0Mz+Zw3iaKqqlof\nAMb40M8/76Jnz69Zu3YvACVLRnLyZAKFChX0c2TGZJIoROR1VX0S+FxEznnIzUa4M+bCHT58ioED\nF/DWW78CUKVKccaPb89NN9Xwc2TGnJFZieJ/7r82sp0xPhAfn0jDhpPZuTOWAgVCGDDgagYPbkFU\nVAF/h2bMWTIb4W65+7K2qp6VLNwH6WwEPGMuQHh4GD16NGLhwu1MnNiBOnXK+DskY9Llze2xD6Uz\nr0dOB2JMsIuLS2To0EV8/PG61Hn//e+1LF78gCUJk6dl1kbRGeeW2Coi8oXHoiLAkfS3MsakZ/78\nP+ndew5btx7ioosKcfvttYiMLGAjzZmAkFkbxXLgIE6vr+M95h8DfvNlUMYEi3/+OU7//vP45JPf\nAbj88jJMmtSRyEhrhzCBI7M2iu3AdmBB7oVjTHBISkpm8uRV/Pe/C4mNjScyMoyhQ1vSr18zChYM\n9Xd4xmRLZlVP36tqSxE5DHjeHis4/fmV9Hl0xgSopCTlzTeXExsbT/v2NRg37iaqVCnh77CMOS+Z\nVT2lDHdaOjcCMSbQHTsWT1KSUrx4BAULhjJlys3s3XucO+6obX0zmYCWYUuax9PYlwKhqpoENAMe\nAWx0FGNcqsoXX2ykdu3xPPnkvNT511xTkU6drJdXE/i8ueXiS5xhUKsB7+EMVfqxT6MyJkDs2HGE\nW26ZRqdOn7J79zF+/30/cXGJ/g7LmBzlTaJIdse0vgN4U1X7AeV9G5YxeVtCQhKvvrqUOnXGM3v2\nZooWDWfcuJv46aeHiIjwpgs1YwKHV0OhishdQDfgNnee3duXkS86wPY5Wa9nAtbJkwk0bfo269bt\nA6BLl7qMGtWGcuWK+DkyY3zDm0TxENAbp5vxbSJSBfjEt2EFsPSSRJX2uR+H8ZmoqAJER1/CyZMJ\nTJjQgTZtqvk7JGN8Spxhq7NYSSQMqO5OblVVv1XCRkdH68qVK/11+Ky97jZcPpn1dTWBQVV5//01\nVKtWkmuuqQhAbGwcBQuG2oNzJmCIyCpVjT6fbb0Z4e5a4ANgN84zFBeLSDdV/fF8DhhUrJop6G3c\nuJ9evb7m++//onbt0qxe3ZOCBUMpVizC36EZk2u8qXoaDbRX1Q0AIlIbJ3GcV2YKaN4mBqtqCnin\nTiUwfPgPjBjxIwkJyZQpE8WgQddQoID1zWTyH28SRcGUJAGgqhtFJH8Ou5VR+8MdX+d+LMZn5s7d\nyqOPzmHbtsMA/PvfV/DKKzdSsmSknyMzxj+8SRS/isgk4EN3+l7yQ6eAmZUerP0haB0/fppu3WZw\n4MBJ6ta9iEmTOtC8eUV/h2WMX3mTKHoCjwFPudM/AG/6LCJ/sWqlfCspKZnkZKVAgVAKFy7ImDHt\niIk5Sr9+TSlQwDrwMybTRCEi9YBqwAxVHZE7IfmJVSvlS6tW/c0jj8zm1ltr8swzLQG45556fo7K\nmLwls95j/4szkt2vwFUiMkxV3821yPzFqpXyhaNH43nmme8YN24FycnK0aPxDBx4jZUgjElHZiWK\ne4H6qnrpfCo6AAAeeklEQVRCRMoAc4DgTxQmqKkq06dv4PHH57Jnz3FCQ4X+/Zvy/PPXWZIwJgOZ\nJYp4VT0BoKr7RcTuCzQB7dixeDp3ns4332wFoEmT8kya1JGGDS/2c2TG5G2ZJYqqHmNlC1DNc+xs\nVb3Dp5EZk8MKFy5IfHwSxYqF88orN/Lww1cSEmJdgBuTlcwSRac00+N8GYgxvrBkyV+UK1eYGjVK\nISK8++4tRESEUbZsYX+HZkzAyGzM7IW5GYgxOenAgZM89dR83ntvNTfcUIX587shIlSqVNzfoRkT\ncPJnx/nWR1PQSk5Wpk5dzYAB8zl06BQFC4Zy7bUVSUpSwsKsmsmY8+HTBmoRaScif4jIVhEZmMl6\nnURERSR3+o/KKEnYw3QBbf36fbRqNZUePWZx6NApbrihCuvW9WLo0FaEhdm9GMacL69LFCISrqrx\n2Vg/FBgPtAZigBUiMsuz3yh3vSLA48Av3u47x9gzE0EjNjaOpk3f4fjx01x0USFGjWrDPffUs/Gq\njckBWf7MEpHGIrIO2OJONxARb7rwaIwzdsU2VT0NTANuTWe9F4BXgTjvwzbGkTKeSrFiETz9dHN6\n9rySTZse5d5761uSMCaHeFMeHwt0BA4CqOoa4DovtisP7PKYjiHNWNsicgVwqapm2k+GiDwsIitF\nZOX+/fu9OLQJdrt3H+XOOz/lww/Xps4bPPhaJk7sSIkS1surMTnJm0QRoqp/pZmXdKEHdh/gGwU8\nmdW6qvqWqkaranSZMmUu9NAmgCUmJjNmzDJq1RrP559vZOjQxSQlJQNYCcIYH/GmjWKXiDQG1G13\n6Ats9mK73cClHtMV3HkpigB1gcXuB/xiYJaI3KKqeXisU+MvK1bspmfPr/n11z0A3HZbLcaObUdo\nqDVUG+NL3iSKXjjVTxWBvcACd15WVgA1RKQKToLoAtyTslBVY4HSKdMishj4jyUJk9aJE6d5+ukF\nTJiwAlWoWLEYb755E7fcUtPfoRmTL2SZKFR1H86XfLaoaqKI9AHmAaHAu6q6XkSGAStVdVa2ozX5\nUlhYCAsWbCMkROjfvxlDh7akUKH8OciiMf6QZaIQkSnAOfeRqurDWW2rqnNwep31nPdsBuu2ymp/\nJv/4889DFC8eQalSUYSHh/HBB7cTERFGvXpl/R2aMfmON1VPCzxeRwC3c/bdTHmfPYkdMOLjExk5\n8ieGD/+Be++tx9tv3wLAVVeVz2JLY4yveFP19D/PaRH5AFjqs4h8IaPR60yesnjxDnr1+ppNmw4A\nzh1OSUnJ1lhtjJ+dT19PVYDALP/bk9h50r59JxgwYD7vv78GgJo1SzFxYgeuu66KnyMzxoB3bRSH\nOdNGEQIcAjLst8mY7Dhw4CS1a4/n0KFThIeHMnjwtTz1VHPCw/Nnf5XG5EWZfhrFecChAWeef0jW\nlD4TjMkBpUtHceutNYmJOcqECR2oXr2kv0MyxqSRaaJQVRWROapaN7cCMsHtxInTDBv2PR06XEaL\nFpUAmDChA+HhofZktTF5lDethKtFpJHPIzFB76uv/qBOnQmMGPETvXt/TXKyUziNiAizJGFMHpZh\niUJEwlQ1EWiE00X4n8AJnPGzVVWvyKUYTYDbtSuWxx+fy4wZmwBo1OhiJk/uaONVGxMgMqt6Wg5c\nAdySS7HkDHtmIs9ITExm7NhfePbZRZw4kUDhwgV58cXrePTRxjaQkDEBJLNEIQCq+mcuxZIzbPS6\nPOPo0XhefnkpJ04k0KlTbd54ox0VKhT1d1jGmGzKLFGUEZH+GS1U1VE+iCfn2DMTfnHkSByRkWGE\nh4dRsmQkkyd3JDw8lA4dLvN3aMaY85RZ+T8UKIzTHXh6f8akUlU+/ngdNWuOY8SIH1Pn33FHbUsS\nxgS4zEoUe1R1WK5FYgLW5s0H6d37axYu3A7AkiU7UVW7k8mYIJFlG4UxGYmLS+TVV5fy0ktLOX06\niZIlIxk5sjUPPtjQkoQxQSSzRHFDrkVhAs4//xynRYv32LLlEAAPPtiQkSNbU7p0lJ8jM8bktAwT\nhaoeys1ATGApW7YQl15ajLCwECZO7EDLlpX9HZIxxkcCv+c1e24iVyQnK1OmrOK666pw2WWlEBE+\n/vgOSpSIpGDBUH+HZ4zxocB/6snGmvC5NWv+oXnzd+nZ82t69/6alH4hy5YtbEnCmHwg8EsUKey5\niRx3/PhpnntuMW+8sYykJOWSS4rQs2e0v8MyxuSy4EkUJkd9+eUm+vb9hpiYo4SECH37NubFF6+n\naNFwf4dmjMlllijMOXbvPkqXLtOJj0/iyivLMWlSR6KjL/F3WMYYP7FEYQBISEgiLCwEEaF8+aIM\nH349BQuG0rv3VTZmtTH5nH0DGH76aRdXXvkWH364NnXek09eTd++TSxJGGMsUeRnhw6d4pFHvqJ5\n83dZt24fEyasxEa6NcakZVVP+ZCq8uGHa3nyyW/Zv/8kBQqE8NRTzRk8+FrresMYcw5LFPnM3r3H\n6dr1cxYt2gFAy5aVmDixA7Vrl/FvYMaYPMsSRT5TvHgEe/Ycp3TpKF57rTX339/AShHGmExZosgH\n5s//kyuuKEepUlGEh4fx2Wd3Ua5cYUqVsg78jDFZs8bsILZnzzG6dv2cNm0+5OmnF6TOr1v3IksS\nxhivWYkiCCUlJTN58ioGDVrI0aPxREaGUbNmKRtMyBhzXixRBJlff91Dz56zWbHibwA6dKjBuHHt\nqVy5uJ8jM8YEKksUQWTHjiM0bjyFpCSlfPkijB17E7ffXstKEcaYC+LTRCEi7YAxQCjwtqq+kmZ5\nf+BfQCKwH3hIVf/yZUzBrHLl4nTv3pAiRcJ5/vlWFCliHfgZYy6czxqzRSQUGA/cBNQBuopInTSr\n/QZEq2p9YDowwlfxBKMdO45w882f8P33O1LnvfXWzYwa1daShDEmx/iyRNEY2Kqq2wBEZBpwK7Ah\nZQVVXeSx/jLgPh/GEzQSEpIYNepnnn/+e06dSuTAgZP8/HMPAKtmMsbkOF8mivLALo/pGKBJJuv3\nAL5Jb4GIPAw8DFCxYsWcii8gLV26k549Z7N+/X4AunSpy6hRbfwclTEmmOWJxmwRuQ+IBlqmt1xV\n3wLeAoiOjs6XvdYdPnyKAQPm8847vwFQrVoJJkzoQJs21fwcmTEm2PkyUewGLvWYruDOO4uI3AgM\nBlqqarwP4wloycnKzJl/UKBACAMHXsOgQdcQGVnA32EZY/IBXyaKFUANEamCkyC6APd4riAijYDJ\nQDtV3efDWALSpk0HqFKlOOHhYZQqFcVHH91BxYrFqFWrtL9DM8bkIz6760lVE4E+wDxgI/Cpqq4X\nkWEicou72kigMPCZiKwWkVm+iieQnDyZwODBC6lffyIjRvyYOr9Nm2qWJIwxuc6nbRSqOgeYk2be\nsx6vb/Tl8QPR3Llb6d37a7ZvPwLAgQMn/RyRMSa/yxON2Qb+/vsYTzwxl88+c+4erlfvIiZN6sjV\nV1+axZbGGONblijygM2bDxId/RbHjp0mKqoAzz3XkieeaEqBAqH+Ds0YYyxR5AU1apTkqqvKU6hQ\nAd588yYqVbIO/IwxeYclCj84ejSeZ59dRO/eV3HZZaUQEWbN6kKhQgX9HZoxxpzDEkUuUlWmT9/A\n44/PZc+e42zadIC5c51eSyxJGGPyKksUuWTbtsP06TOHb77ZCkDTphV49VW76csYk/dZovCx06eT\neO21n3jhhSXExSVSvHgEr7xyA//+95WEhFgHfsaYvC/wEsXeVfB64HzB7toVy7Bh3xMfn8S999bj\n9dfbULZsYX+HZYwxXgu8RJGeKu39HcFZDh8+RfHiEYgI1aqVZMyYdlSvXpIbbqjq79CMMSbbRDWw\nOmONvlR05a68GXNysjJ16moGDJjPG2+0pVu3Bv4OyRhjABCRVaoafT7b+qyvp/xm/fp9tGo1lR49\nZnHo0KnURmtjjAl0wVH15EcnTybwwgvf89prP5OYmMxFFxVi9Oi2dO1a19+hGWNMjrBEcQE2bz5I\n27YfsmPHEUSgZ88reemlGyhRItLfoRljTI6xRHEBKlUqRkREGA0alGXSpI40bVrB3yGZPCQhIYGY\nmBji4uL8HYrJRyIiIqhQoQIFCuTcwGaWKLIhMTGZSZNW0rVrXUqViiI8PIy5c++lfPmihIVZc485\nW0xMDEWKFKFy5cqIBM4t3SZwqSoHDx4kJiaGKlWq5Nh+7dvNS8uX76Zx4yn07fsNTz+9IHV+pUrF\nLUmYdMXFxVGqVClLEibXiAilSpXK8VKslSiyEBsbx+DB3zFhwgpUoWLFYtx6a01/h2UChCUJk9t8\n8Z6zRJEBVeV//1tPv37z+Oef44SFhdC/f1OefbaldeBnjMlXrM4kA2vW7KVr18/555/jXH31pfz6\n68O8+mprSxImoISGhtKwYUPq1q3LzTffzJEjR1KXrV+/nuuvv56aNWtSo0YNXnjhBTwfwP3mm2+I\njo6mTp06NGrUiCeffNIfp5Cp3377jR49evg7jEy9/PLLVK9enZo1azJv3rx011m4cCFXXHEFDRs2\n5JprrmHrVuc5rH79+tGwYUMaNmzIZZddRvHizlg1+/fvp127drl2DqhqQP1dWQH1lcTEpLOm+/Wb\nq1OmrNKkpGSfHdMErw0bNvg7BC1UqFDq6/vvv19ffPFFVVU9efKkVq1aVefNm6eqqidOnNB27drp\nuHHjVFV13bp1WrVqVd24caOqqiYmJuqECRNyNLaEhIQL3sedd96pq1evztVjZsf69eu1fv36GhcX\np9u2bdOqVatqYmLiOevVqFEj9f0yfvx4feCBB85ZZ+zYsdq9e/fU6QcffFCXLl2a7nHTe+8BK/U8\nv3et6sm1aNF2eveew+TJHWnRohIAo0a19XNUJmj4qiPLJ73vzqZZs2asXbsWgI8//pjmzZvTpk0b\nAKKiohg3bhytWrXi0UcfZcSIEQwePJhatWoBTsmkV69e5+zz+PHj9O3bl5UrVyIiDB06lE6dOlG4\ncGGOHz8OwPTp05k9ezZTp07lwQcfJCIigt9++43mzZvzxRdfsHr16tRfyjVq1GDp0qWEhITQs2dP\ndu7cCcAbb7xB8+bNzzr2sWPHWLt2LQ0aOF3lLF++nMcff5y4uDgiIyN57733qFmzJlOnTuWLL77g\n+PHjJCUl8f333zNy5Eg+/fRT4uPjuf3223n++ecBuO2229i1axdxcXE8/vjjPPzww15f3/TMnDmT\nLl26EB4eTpUqVahevTrLly+nWbNmZ60nIhw9ehSA2NhYLrnkknP29cknn6TGmRLrRx99dM518YV8\nnyj27TvBgAHzef/9NQCMGvVzaqIwJlgkJSWxcOHC1Gqa9evXc+WVV561TrVq1Th+/DhHjx7l999/\n96qq6YUXXqBYsWKsW7cOgMOHD2e5TUxMDD/99BOhoaEkJSUxY8YMunfvzi+//EKlSpUoW7Ys99xz\nD/369eOaa65h586dtG3blo0bN561n5UrV1K37pkeEGrVqsUPP/xAWFgYCxYs4L///S+ff/45AL/+\n+itr166lZMmSfPvtt2zZsoXly5ejqtxyyy0sWbKEFi1a8O6771KyZElOnTrFVVddRadOnShVqtRZ\nx+3Xrx+LFi0657y6dOnCwIEDz5q3e/dumjZtmjpdoUIFdu/efc62b7/9Nu3btycyMpKiRYuybNmy\ns5b/9ddfbN++neuvvz51XnR0NEOGDMnqcueIfJsokpOVd975laefXsDhw3GEh4cyZEgLBgy42t+h\nmWCUjV/+OenUqVM0bNiQ3bt3U7t2bVq3bp2j+1+wYAHTpk1LnS5RokSW29x1112EhoYC0LlzZ4YN\nG0b37t2ZNm0anTt3Tt3vhg0bUrc5evQox48fp3DhM13079mzhzJlyqROx8bG8sADD7BlyxZEhISE\nhNRlrVu3pmTJkgB8++23fPvttzRq1AhwSkVbtmyhRYsWjB07lhkzZgCwa9cutmzZck6iGD16tHcX\nJxtGjx7NnDlzaNKkCSNHjqR///68/fbbqcunTZvGnXfemXrdAC666CL+/vvvHI8lPfkyUWzffpj7\n7pvBTz/tAqBNm2qMH9+e6tVL+jkyY3JWZGQkq1ev5uTJk7Rt25bx48fz2GOPUadOHZYsWXLWutu2\nbaNw4cIULVqUyy+/nFWrVqVW62SX5y2aae/pL1SoUOrrZs2asXXrVvbv38+XX36Z+gs5OTmZZcuW\nERERkem5ee77mWee4brrrmPGjBns2LGDVq1apXtMVWXQoEE88sgjZ+1v8eLFLFiwgJ9//pmoqCha\ntWqV7vMI2SlRlC9fnl27dqVOx8TEUL58+bPW2b9/P2vWrKFJkyaAkzzTNlRPmzaN8ePHnzUvpYot\nN+TLu56KFg1n8+aDXHxxYaZN68TcufdakjBBLSoqirFjx/L666+TmJjIvffey9KlS1mwwHl49NSp\nUzz22GM89dRTAAwYMICXXnqJzZs3A84X96RJk87Zb+vWrc/6AkupeipbtiwbN24kOTk59Rd6ekSE\n22+/nf79+1O7du3UX+9t2rThzTffTF1v9erV52xbu3bt1LuDwClRpHwJT506NcNjtm3blnfffTe1\nDWX37t3s27eP2NhYSpQoQVRUFJs2bTqn+ifF6NGjWb169Tl/aZMEwC233MK0adOIj49n+/btbNmy\nhcaNG5+1TokSJYiNjU291vPnz6d27dqpyzdt2sThw4fPadfYvHnzWVVvvpRvEsW8eVuJj08EoFSp\nKGbN6sKmTY/SuXNdeyjK5AuNGjWifv36fPLJJ0RGRjJz5kxefPFFatasSb169bjqqqvo06cPAPXr\n1+eNN96ga9eu1K5dm7p167Jt27Zz9jlkyBAOHz5M3bp1adCgQeov7VdeeYWOHTty9dVXU65cuUzj\n6ty5Mx9++GFqtRPA2LFjWblyJfXr16dOnTrpJqlatWoRGxvLsWPHAHjqqacYNGgQjRo1IjExMcPj\ntWnThnvuuYdmzZpRr1497rzzTo4dO0a7du1ITEykdu3aDBw48Ky2hfN1+eWXc/fdd1OnTh3atWvH\n+PHjU6uP2rdvz99//01YWBhTpkyhU6dONGjQgA8++ICRI0em7mPatGl06dLlnO+pRYsW0aFDhwuO\n0RtBP3DRrl2xPPbYXL78chMvvHAdQ4a08GF0xpyxcePGs34Zmpw3evRoihQpwr/+9S9/h5LrWrRo\nwcyZM9NtF0rvvWcDF6UjMTGZUaN+pnbt8Xz55SYKFy5IyZLW/bcxwaRXr16Eh4f7O4xct3//fvr3\n7+/VzQM5ISgbs5cti6Fnz9msWbMXgE6dajNmTDvKly/q58iMMTkpIiKCbt26+TuMXFemTBluu+22\nXDte0CWKX36J4eqr30EVKlcuzrhxN9Ghw2X+DsvkU6pqbWAmV/miOSHoEkXjxuVp27Y6jRpdzJAh\nLYiKyrnBO4zJjoiICA4ePGhdjZtco+54FJndVnw+Ar4xe8uWg/TrN49Ro9py2WXOrXXJyUpIiH0w\njX/ZCHfGHzIa4e5CGrMDtkQRH5/IK68s5eWXlxIfn0RERBjTp98NYEnC5AkFChTI0VHGjPEXn971\nJCLtROQPEdkqIuc8jSIi4SLyP3f5LyJS2Zv9Lly4jfr1J/Hcc98TH59E9+4NmTSpY06Hb4wxBh+W\nKEQkFBgPtAZigBUiMktVN3is1gM4rKrVRaQL8CrQ+dy9nbH9UHFuvPEDAGrXLs2kSR2tEz9jjPEh\nX5YoGgNbVXWbqp4GpgG3plnnVuD/3NfTgRski1a/w6eiiIgI46WXrmf16p6WJIwxxsd81pgtIncC\n7VT1X+50N6CJqvbxWOd3d50Yd/pPd50Dafb1MJDSMXxd4HefBB14SgMHslwrf7BrcYZdizPsWpxR\nU1WLnM+GAdGYrapvAW8BiMjK8225DzZ2Lc6wa3GGXYsz7FqcISIrz3dbX1Y97QYu9Ziu4M5Ldx0R\nCQOKAQd9GJMxxphs8mWiWAHUEJEqIlIQ6ALMSrPOLOAB9/WdwHcaaA92GGNMkPNZ1ZOqJopIH2Ae\nEAq8q6rrRWQYziDfs4B3gA9EZCtwCCeZZOUtX8UcgOxanGHX4gy7FmfYtTjjvK9FwD2ZbYwxJncF\nbTfjxhhjcoYlCmOMMZnKs4nCV91/BCIvrkV/EdkgImtFZKGIBO1TiFldC4/1OomIikjQ3hrpzbUQ\nkbvd98Z6Efk4t2PMLV58RiqKyCIR+c39nLT3R5y+JiLvisg+9xm19JaLiIx1r9NaEbnCqx2rap77\nw2n8/hOoChQE1gB10qzTG5jkvu4C/M/fcfvxWlwHRLmve+Xna+GuVwRYAiwDov0dtx/fFzWA34AS\n7vRF/o7bj9fiLaCX+7oOsMPfcfvoWrQArgB+z2B5e+AbQICmwC/e7Devlih80v1HgMryWqjqIlU9\n6U4uw3lmJRh5874AeAGn37Bg7t/bm2vxb2C8qh4GUNV9uRxjbvHmWiiQMsRlMeDvXIwv16jqEpw7\nSDNyK/C+OpYBxUWkXFb7zauJojywy2M6xp2X7jqqmgjEAqVyJbrc5c218NQD5xdDMMryWrhF6UtV\n9evcDMwPvHlfXAZcJiI/isgyEWmXa9HlLm+uxXPAfSISA8wB+uZOaHlOdr9PgADpwsN4R0TuA6KB\nlv6OxR9EJAQYBTzo51DyijCc6qdWOKXMJSJST1WP+DUq/+gKTFXV10WkGc7zW3VVNdnfgQWCvFqi\nsO4/zvDmWiAiNwKDgVtUNT6XYsttWV2LIjidRi4WkR04dbCzgrRB25v3RQwwS1UTVHU7sBkncQQb\nb65FD+BTAFX9GYjA6TAwv/Hq+yStvJoorPuPM7K8FiLSCJiMkySCtR4asrgWqhqrqqVVtbKqVsZp\nr7lFVc+7M7Q8zJvPyJc4pQlEpDROVdS23Awyl3hzLXYCNwCISG2cRLE/V6PMG2YB97t3PzUFYlV1\nT1Yb5cmqJ/Vd9x8Bx8trMRIoDHzmtufvVNVb/Ba0j3h5LfIFL6/FPKCNiGwAkoABqhp0pW4vr8WT\nwBQR6YfTsP1gMP6wFJFPcH4clHbbY4YCBQBUdRJO+0x7YCtwEuju1X6D8FoZY4zJQXm16skYY0we\nYYnCGGNMpixRGGOMyZQlCmOMMZmyRGGMMSZTlihMniMiSSKy2uOvcibrVs6op8xsHnOx2/voGrfL\ni5rnsY+eInK/+/pBEbnEY9nbIlInh+NcISINvdjmCRGJutBjm/zLEoXJi06pakOPvx25dNx7VbUB\nTmeTI7O7sapOUtX33ckHgUs8lv1LVTfkSJRn4pyAd3E+AViiMOfNEoUJCG7J4QcR+dX9uzqddS4X\nkeVuKWStiNRw59/nMX+yiIRmcbglQHV32xvcMQzWuX39h7vzX5EzY4C85s57TkT+IyJ34vS59ZF7\nzEi3JBDtljpSv9zdkse484zzZzw6dBORiSKyUpyxJ5535z2Gk7AWicgid14bEfnZvY6fiUjhLI5j\n8jlLFCYvivSodprhztsHtFbVK4DOwNh0tusJjFHVhjhf1DFudw2dgebu/CTg3iyOfzOwTkQigKlA\nZ1Wth9OTQS8RKQXcDlyuqvWBFz03VtXpwEqcX/4NVfWUx+LP3W1TdAamnWec7XC66UgxWFWjgfpA\nSxGpr6pjcbrUvk5Vr3O78hgC3Ohey5VA/yyOY/K5PNmFh8n3Trlflp4KAOPcOvkknH6L0voZGCwi\nFYAvVHWLiNwAXAmscLs3icRJOun5SEROATtwuqGuCWxX1c3u8v8DHgXG4Yx18Y6IzAZme3tiqrpf\nRLa5/exsAWoBP7r7zU6cBXG6bfG8TneLyMM4n+tyOAP0rE2zbVN3/o/ucQriXDdjMmSJwgSKfsBe\noAFOSficQYlU9WMR+QXoAMwRkUdwRvL6P1Ud5MUx7vXsQFBESqa3ktu3UGOcTubuBPoA12fjXKYB\ndwObgBmqquJ8a3sdJ7AKp33iTeAOEakC/Ae4SlUPi8hUnI7v0hJgvqp2zUa8Jp+zqicTKIoBe9zx\nA7rhdP52FhGpCmxzq1tm4lTBLATuFJGL3HVKivdjiv8BVBaR6u50N+B7t06/mKrOwUlgDdLZ9hhO\nt+fpmYEz0lhXnKRBduN0O7R7BmgqIrVwRm87AcSKSFngpgxiWQY0TzknESkkIumVzoxJZYnCBIoJ\nwAMisganuuZEOuvcDfwuIqtxxqV4373TaAjwrYisBebjVMtkSVXjcHrX/ExE1gHJwCScL93Z7v6W\nkn4d/1RgUkpjdpr9HgY2ApVUdbk7L9txum0fr+P0CrsGZ3zsTcDHONVZKd4C5orIIlXdj3NH1ifu\ncX7GuZ7GZMh6jzXGGJMpK1EYY4zJlCUKY4wxmbJEYYwxJlOWKIwxxmTKEoUxxphMWaIwxhiTKUsU\nxhhjMvX/30ygBiAKmX8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4d22e2c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_val,y_val_proba[:,1],drop_intermediate=False)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3, total=  11.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3, total=  13.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.3, max_depth=3, total=  13.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3, total=  14.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3, total=  14.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3, total=  14.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3, total=  15.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.3, max_depth=3, total=  14.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3, total=  10.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.3, max_depth=3, total=  14.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3, total=  14.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3, total=  14.3s\n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3, total=  14.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1600, subsample=0.2, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1600, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3, total=  15.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1600, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3, total=  12.1s\n",
      "[CV] learning_rate=0.05, n_estimators=1600, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.3, max_depth=3, total=  14.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1600, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1600, subsample=0.2, max_depth=3, total=  11.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1600, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.3, max_depth=3, total=  14.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1600, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.3, max_depth=3, total=  15.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1600, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1600, subsample=0.2, max_depth=3, total=  14.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1600, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1600, subsample=0.2, max_depth=3, total=  14.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1800, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1600, subsample=0.25, max_depth=3, total=  14.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1800, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1600, subsample=0.25, max_depth=3, total=  14.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1800, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1600, subsample=0.25, max_depth=3, total=  14.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1800, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1600, subsample=0.3, max_depth=3, total=  12.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1800, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1600, subsample=0.3, max_depth=3, total=  14.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1800, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1800, subsample=0.2, max_depth=3, total=  13.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1800, subsample=0.3, max_depth=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:   57.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.05, n_estimators=1600, subsample=0.3, max_depth=3, total=  15.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1800, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1800, subsample=0.2, max_depth=3, total=  14.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1800, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1800, subsample=0.2, max_depth=3, total=  14.6s\n",
      "[CV] learning_rate=0.05, n_estimators=2000, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1800, subsample=0.25, max_depth=3, total=  14.8s\n",
      "[CV] learning_rate=0.05, n_estimators=2000, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1800, subsample=0.3, max_depth=3, total=  13.3s\n",
      "[CV] learning_rate=0.05, n_estimators=2000, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1800, subsample=0.25, max_depth=3, total=  13.7s\n",
      "[CV] learning_rate=0.05, n_estimators=2000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1800, subsample=0.25, max_depth=3, total=  15.9s\n",
      "[CV] learning_rate=0.05, n_estimators=2000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1800, subsample=0.3, max_depth=3, total=  15.0s\n",
      "[CV] learning_rate=0.05, n_estimators=2000, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1800, subsample=0.3, max_depth=3, total=  14.1s\n",
      "[CV] learning_rate=0.05, n_estimators=2000, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=2000, subsample=0.2, max_depth=3, total=  13.8s\n",
      "[CV] learning_rate=0.05, n_estimators=2000, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=2000, subsample=0.2, max_depth=3, total=  15.1s\n",
      "[CV] learning_rate=0.05, n_estimators=2000, subsample=0.3, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=2000, subsample=0.2, max_depth=3, total=  13.8s\n",
      "[CV]  learning_rate=0.05, n_estimators=2000, subsample=0.25, max_depth=3, total=  12.4s\n",
      "[CV]  learning_rate=0.05, n_estimators=2000, subsample=0.25, max_depth=3, total=  14.6s\n",
      "[CV]  learning_rate=0.05, n_estimators=2000, subsample=0.25, max_depth=3, total=  13.8s\n",
      "[CV]  learning_rate=0.05, n_estimators=2000, subsample=0.3, max_depth=3, total=  11.9s\n",
      "[CV]  learning_rate=0.05, n_estimators=2000, subsample=0.3, max_depth=3, total=  10.8s\n",
      "[CV]  learning_rate=0.05, n_estimators=2000, subsample=0.3, max_depth=3, total=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  45 out of  45 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'learning_rate': 0.05, 'n_estimators': 2000, 'subsample': 0.2, 'max_depth': 3} with a score of -0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Cross validation of gradient boosted tree classifier\n",
    "gbc = GradientBoostingClassifier(random_state=0,max_features=307)\n",
    "scorer = make_scorer(log_loss,greater_is_better=False,needs_proba=True)\n",
    "\n",
    "\n",
    "estimators_range = [1400,1500,1600,1800,2000]\n",
    "lr_range = [0.05]\n",
    "subsample_range = [0.20,0.25,0.30]\n",
    "max_depth_range = [3]\n",
    "param_grid = {'n_estimators':estimators_range,'learning_rate':lr_range,\n",
    "             'subsample':subsample_range,'max_depth':max_depth_range}\n",
    "cv = StratifiedShuffleSplit(n_splits=3,test_size = 0.2,random_state = 0)\n",
    "grid = GridSearchCV(gbc,param_grid=param_grid,cv=cv,n_jobs=7,verbose=2,scoring=scorer)\n",
    "\n",
    "grid.fit(X_train[:,importance_idx],y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>Mean_minus_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.475955</td>\n",
       "      <td>0.011578</td>\n",
       "      <td>-0.076066</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1500, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>-0.086098</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.100307</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>0.099774</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.024919</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.100985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.213747</td>\n",
       "      <td>0.010928</td>\n",
       "      <td>-0.075822</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 2000, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.085290</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.101067</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>0.586978</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.025377</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.101199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.063009</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>-0.076082</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1800</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1800, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.085596</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.101169</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.396221</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.025279</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.101361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.271949</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>-0.076798</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1400, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.086640</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>-0.101219</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>1.511291</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.024948</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.101746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.463253</td>\n",
       "      <td>0.009229</td>\n",
       "      <td>-0.076757</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1600, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.086049</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.102278</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>1.480285</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.025493</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.102250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "3       14.475955         0.011578        -0.076066         -0.000215   \n",
       "12      14.213747         0.010928        -0.075822         -0.000206   \n",
       "9       14.063009         0.010663        -0.076082         -0.000207   \n",
       "0       13.271949         0.012601        -0.076798         -0.000229   \n",
       "6       13.463253         0.009229        -0.076757         -0.000211   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_subsample  \\\n",
       "3                 0.05               3               1500             0.2   \n",
       "12                0.05               3               2000             0.2   \n",
       "9                 0.05               3               1800             0.2   \n",
       "0                 0.05               3               1400             0.2   \n",
       "6                 0.05               3               1600             0.2   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "3   {'learning_rate': 0.05, 'n_estimators': 1500, ...                2   \n",
       "12  {'learning_rate': 0.05, 'n_estimators': 2000, ...                1   \n",
       "9   {'learning_rate': 0.05, 'n_estimators': 1800, ...                3   \n",
       "0   {'learning_rate': 0.05, 'n_estimators': 1400, ...                5   \n",
       "6   {'learning_rate': 0.05, 'n_estimators': 1600, ...                4   \n",
       "\n",
       "         ...        split0_train_score  split1_test_score  split1_train_score  \\\n",
       "3        ...                 -0.000218          -0.086098           -0.000213   \n",
       "12       ...                 -0.000208          -0.085290           -0.000205   \n",
       "9        ...                 -0.000210          -0.085596           -0.000207   \n",
       "0        ...                 -0.000230          -0.086640           -0.000229   \n",
       "6        ...                 -0.000213          -0.086049           -0.000210   \n",
       "\n",
       "    split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "3           -0.100307           -0.000213      0.099774        0.000152   \n",
       "12          -0.101067           -0.000204      0.586978        0.001834   \n",
       "9           -0.101169           -0.000205      0.396221        0.001711   \n",
       "0           -0.101219           -0.000227      1.511291        0.000105   \n",
       "6           -0.102278           -0.000209      1.480285        0.001746   \n",
       "\n",
       "    std_test_score  std_train_score  Mean_minus_STD  \n",
       "3         0.024919         0.000002       -0.100985  \n",
       "12        0.025377         0.000002       -0.101199  \n",
       "9         0.025279         0.000002       -0.101361  \n",
       "0         0.024948         0.000002       -0.101746  \n",
       "6         0.025493         0.000002       -0.102250  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results['Mean_minus_STD']=results['mean_test_score']-results['std_test_score']\n",
    "results.sort_values('Mean_minus_STD',inplace=True,ascending=False)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:\n",
      "Log-Loss: 0.6197104402805726\n",
      "Positive Label\n",
      "Precision: 0.8263473053892215, Recall: 0.92, F1: 0.8706624605678233, Support: 150\n",
      "Negative Label\n",
      "Precision: 0.7894736842105263, Recall: 0.6081081081081081, F1: 0.6870229007633588, Support: 74\n",
      "Accuracy: 0.8169642857142857\n",
      "\n",
      "Training Scores:\n",
      "Log-Loss: 0.00022442519545877725\n",
      "Positive Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Negative Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Retrain using best params\n",
    "gbc = GradientBoostingClassifier(random_state=0,subsample=0.20,learning_rate=0.05,n_estimators=1500)\n",
    "gbc.fit(X_train[:,importance_idx],y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_val_pred = gbc.predict(X_val[:,importance_idx])\n",
    "y_val_proba = gbc.predict_proba(X_val[:,importance_idx])\n",
    "y_train_pred = gbc.predict(X_train[:,importance_idx])\n",
    "y_train_proba = gbc.predict_proba(X_train[:,importance_idx])\n",
    "\n",
    "# Validation scores\n",
    "logl = log_loss(y_val,y_val_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_val,y_val_pred)\n",
    "acc = accuracy_score(y_val,y_val_pred)\n",
    "print(\"Validation Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\\n\".format(acc))\n",
    "\n",
    "# Training Scores\n",
    "logl = log_loss(y_train,y_train_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_train,y_train_pred)\n",
    "acc = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcjXX7wPHPNTNms4/tEdllyVqTJYUWSyiVCkmbnkJa\n6FFEm9JCEVlT8mv1lBKPRIikkqVQlhBiJLuxzpjl+v1x3zOOMcsZ5syZOXO9X695Ofd+3bdzznW+\n3+99f7+iqhhjjDEZCfJ3AMYYY/I2SxTGGGMyZYnCGGNMpixRGGOMyZQlCmOMMZmyRGGMMSZTligC\ngIj0EJFv/B2Hv4lIJRE5LiLBuXjMKiKiIhKSW8f0JRFZLyKtz2O7gH0PikhrEYnxdxz+ZIkih4nI\nDhE55X5h/SMi00SkiC+PqaofqWpbXx4jL3Kv9fUp06q6U1WLqGqSP+PyFzdh1biQfajqpaq6JIvj\nnJMcC+p7sKCwROEbN6pqEaAR0BgY7Od4zos/fyUHyi/07LDrbfIqSxQ+pKr/APNxEgYAIhImIq+L\nyE4R2Ssik0QkwmN5ZxFZIyJHReRPEWnvzi8uIu+KyB4R2S0iL6VUsYjIvSKyzH09UURe94xDRGaJ\nyAD39UUi8rmI7BeR7SLyqMd6z4vIDBH5UESOAvemPSc3jvfd7f8SkaEiEuQRxw8iMk5EYkVkk4hc\nl2bbzM7hBxEZLSIHgedFpLqIfCsiB0XkgIh8JCIl3PU/ACoB/3NLb0+m/aUrIktE5EV3v8dE5BsR\nKe0Rz93uORwUkWfSllDSnHeEiLzhrh8rIss8/9+AHu7/6QERGeKxXRMR+UlEjrjnPU5EQj2Wq4g8\nLCJbgC3uvDEisst9D6wWkas91g8Wkafd98Yxd/nFIrLUXWWtez26uut3ct9PR0TkRxFp4LGvHSLy\nlIisA06ISIjnNXBjX+XGsVdERrmbphzriHus5p7vQXfbS0VkgYgccrd9OoPrmuHnwY3tZ4//zz7i\nVI2Fu9OfiVNqjxWRpSJyqcd+p4nIBBH52o3xBxH5l4i8KSKH3fdm4zTXYrCIbHCXv5dynHRizvAz\nFLBU1f5y8A/YAVzvvq4I/AaM8Vg+GpgNRAFFgf8Br7jLmgCxQBucJF4BqO0umwlMBgoDZYEVwEPu\nsnuBZe7rlsAuQNzpksAp4CJ3n6uBZ4FQoBqwDWjnrvs8kADc7K4bkc75vQ/McmOvAmwGennEkQj0\nBwoBXd3zifLyHBKBR4AQIAKo4V6LMKAMzhfUm+lda3e6CqBAiDu9BPgTuMTd3xLgVXdZXeA4cJV7\nLV53z/36DP5fx7vbVwCCgSvduFKOOcU9RkMgHqjjbnc50Mw9pyrARuBxj/0qsADn/RDhzrsLKOVu\n8wTwDxDuLhuI856qBYh7vFIe+6rhse/GwD6gqRvzPe41C/O4fmuAiz2OnXpNgZ+Anu7rIkCz9K5z\nOu/BosAeN/Zwd7ppBtc1s89DkPt//jxQEzgMNPbY9n53mzDgTWCNx7JpwAH3+ocD3wLbgbvda/ES\nsDjNe+l391pEAT8AL7nLWgMxHjFl+BkK1D+/BxBof+4b7jhwzP0wLQJKuMsEOAFU91i/ObDdfT0Z\nGJ3OPsvhfPlEeMzrnvJGT/MhFWAn0NKd/jfwrfu6KbAzzb4HA++5r58HlmZybsHAaaCux7yHgCUe\ncfyNm6TceSuAnl6ew86Mju2uczPwa5prnVWiGOqxvC8wz339LPCJx7JI99zOSRTul8MpoGE6y1KO\nWTHNOXfL4BweB2Z6TCtwbRbnfTjl2MAfQOcM1kubKCYCL6ZZ5w+glcf1uz+d929KolgKvACUzuCc\nM0oU3T3/nzI5r0w/Dx7HOoSTYAdnsq8SbkzF3elpwBSP5Y8AGz2m6wNH0px3b4/pDsCf7uvWnEkU\nmX6GAvXP6iV942ZVXSgirYCPgdLAEZxfxZHAahFJWVdwvoDB+TUzN539Vcb5hb7HY7sgnJLDWVRV\nRWQ6zod1KXAn8KHHfi4SkSMemwQD33tMn7NPD6XdOP7ymPcXzq/sFLvV/fR4LL/Iy3M469giUg4Y\nA1yN88sxCOdLMzv+8Xh9EueXMW5MqcdT1ZPiVHmlpzTOr9I/s3scEbkEGAVE4/zfh+D8IvWU9rz/\nA/RyY1SgmBsDOO+RzOLwVBm4R0Qe8ZgX6u433WOn0QsYBmwSke3AC6o6x4vjehtjVp8HVHWHiCzG\n+eIen7qSU2U5HLjd3U+yu6g0TikWYK/HsU6lM532JhPPa5Hyvk3Lm89QwLE2Ch9S1e9wftmktBkc\nwHmDXqqqJdy/4uo0fIPzRq2ezq524fwaL+2xXTFVvTSddQE+AW4Tkco4v4A+99jPdo99lFDVoqra\nwTPsTE7pAE71TGWPeZWA3R7TFcTjU+8u/9vLc0h77JfdefVVtRhOlYxksn527MGpGgScNgic6p70\nHADiSP//JisTgU1ATfccnubscwCP83DbI54E7gBKqmoJnC++lG0yeo+kZxcwPM3/d6SqfpLesdNS\n1S2q2h2nmvA1YIaIFM5sG4/jVvMivqw+D4hIR5xSxiJgpMe2dwKdgeuB4jglDzj32mbHxR6vU963\naXnzGQo4lih8702gjYg0VNVknLrs0SJSFkBEKohIO3fdd4H7ROQ6EQlyl9VW1T3AN8AbIlLMXVbd\nLbGcQ1V/xfkQvgPMV9WUXz8rgGNuI2GE2zBaT0Su8OZE1Lnt9FNguIgUdRPRAM6UWMD5UnlURAqJ\nyO1AHWBuds/BVRSnGi9WRCrg1M972ot3X0jpmQHcKCJXitO4/DwZfMm4/29TgVFuQ2aw24Ab5sVx\nigJHgeMiUhvo48X6icB+IEREnsUpUaR4B3hRRGqKo4GIpCS4tNdjCtBbRJq66xYWkY4iUtSLuBGR\nu0SkjHv+Ke+hZDe2ZDK+9nOA8iLyuNtYXVREmqZdKavPgzg3HrwDPIDTvnKjiKR8IRfF+eFxEKdU\n8rI355SFh0WkoohEAUOA/6azzgV9hvIrSxQ+pqr7cRqAn3VnPQVsBZaLc2fRQpyGSVR1BXAfTgNf\nLPAdZ369341TbbABp/plBlA+k0N/jPNr62OPWJKATjh3YW3nTDIpno1TegSnXnkbsMzd/1SP5T/j\nNDwewKkauE1VU6p0snsOLwCX4VyLr4Av0ix/BRgqzh09/8nGOaCq691zmY5TujiO0/Abn8Em/8Fp\nRF6JU2f+Gt59fv6D8+v3GM6XYnpfPp7mA/NwbhL4C6ck41klMgonWX+Dk4DexWlEByfZ/Z97Pe5Q\n1VU4bVTjcK73VtK5ky0T7YH1InIcpwqwm6qeUtWTOP+3P7jHaua5kaoew7kJ4UacKrktwDUZHCPD\nzwPwNjBLVee676FewDtuYnzfvT67cd5Py7NxXhn5GOe6bsOpOnsp7Qo59BnKd1LujDHmgonIvcAD\nqnqVv2PJLnEeijyCU0W03d/xmNwlIjtw3rsL/R1LXmQlClNgiciNIhLp1ru/jlNi2OHfqIzJeyxR\nmIKsM06D5d841WXd1IrYxpzDqp6MMcZkykoUxhhjMpXvHrgrXbq0VqlSxd9hGGNMvrJ69eoDqlrm\nfLbNd4miSpUqrFq1yt9hGGNMviIif2W9Vvqs6skYY0ymLFEYY4zJlCUKY4wxmbJEYYwxJlOWKIwx\nxmTKEoUxxphM+SxRiMhUEdknIr9nsFxEZKyIbBWRdSJyma9iMcYYc/58WaKYhtNNcUZuwOlfpybw\nIM4AL8YYY3LY6dNJF7S9zx64U9WlIlIlk1U6A++7nbAtF5ESIlLeHeDGGJNXfdERtqc3Yq/Jiwb+\nrw2//p3ZsC9Z8+eT2RU4e0CWGHfeOYlCRB7EKXVQqVKlXAnOmFxhX7rGx+r9ax9jl50zwGC25Isu\nPFT1bZzRroiOjrbubk3+EMhJoGoHuPUrf0dh0rFhw35++WUPd93VAIC7VWn1aixVq54zYJ/X/Jko\ndnP2YOYV3XnGBAZvk4R96ZoccPJkAi+9tJSRI38kOFho1qwiNWpEISJUqVLigvbtz0QxG+gnItOB\npkCstU+YfCuz0sMTVgg2vvX111t4+OG5bN9+BIBevS6nVKmILLbyns8ShYh8ArQGSotIDPAcUAhA\nVScBc4EOOAOrnwTu81UsxvhcRkmiaofcjcMUKLt3H+Xxx+czY8YGABo0KMekSR1p3vziLLbMHl/e\n9dQ9i+UKPOyr4xvjF1Z6MLno4YfnMmvWH0RGFmLYsNY89lgzQkJy/qmHfNGYbYwxxpGYmJyaDF57\n7XoKFQrmjTfaUqlScZ8d0xKFMecjkO9oMnlSbGwcQ4d+y+bNh5g3rwciQq1apfnss9t9fmxLFMac\nj/SShLVHGB9QVT77bAOPPz6PPXuOExwsrFnzD40bX9hDdNlhicKYC2FtEsaH/vzzEP36fc28eVsB\naN68IpMmdaJBg3K5GoclCmOMyYNef/1HnnlmMXFxiZQoEc5rr13PAw9cRlCQ5HoslihMwWZtDSaP\nOnkygbi4RHr2bMDrr7elbNnCfovFEoUp2C4kSVibhMlB+/ef4I8/DnLVVU5/dk891YLWravQsmVl\nP0dmicIUNBmVIKytwfhJcrIydeqvPPnkAkJCgti0qR9RURGEhYXkiSQBlihMIPO2WslKBsZPfv99\nH717z+GHH5yOtNu0qcbJkwlEReVc9xs5wRKFyXt83W5gnfAZPztx4jTDhn3HqFHLSUxMply5wrz5\nZnu6dr0UkdxvrM6KJQqT9+RkkrCkYPKg2277jHnztiICfftGM3z4dZQoEe7vsDJkicLkXdZuYALU\nU0+1YO/e40yc2JGmTSv6O5wsWaIwvmW3n5oCLjExmbfe+pkdO44wZswNALRuXYVVqx70yzMR58MS\nhck5OZkUrIHZBIAVK3bz0ENzWLPmHwAefPByLr20LEC+SRJgicLkpMzGZLB2AlOAHDkSx9NPL2LS\npFWoQuXKxRk3rkNqkshvLFGYnGdtC6YAmz79dx5/fB57954gJCSIJ55ozjPPtKRw4VB/h3beLFEY\n71hbgzFe+eabP9m79wQtWlzMxIkdqV8/dzvw8wVLFMY73iYJa1swBUx8fCK7dx+jWrWSAIwY0Yar\nr67EPfc0ylftEJmxRGGyx6qVjEn17bfb6dPnK4KChLVrexMaGkzp0pHcd19jf4eWo3J+cFVjjAlw\ne/cep2fPmVx33fts3nwQgJiYo36OynesRGGMMV5KTlamTFnNoEGLOHIkjvDwEIYOvZqBA1sQGhrs\n7/B8xhKFMcZ46ZZb/svs2X8A0K5ddcaP70D16lF+jsr3LFGY9NldTsac49Zba7NixW7GjGnP7bfX\nzZMd+PmCJQqTvvSShN3RZAqY2bP/ICbmKH37XgHA3Xc35NZb61C0aJifI8tdlihM5qUHu8vJFEA7\nd8by6KNfM2vWH4SFBdO+fQ2qVSuJiBS4JAGWKAxk3vWGMQVIQkISY8f+zHPPLeHEiQSKFg3lpZeu\npXLl4v4Oza8sUZgzrPRgCrDly2N46KE5rFu3F4Dbb6/L6NHtqFChmJ8j8z9LFMYYAzzzzGLWrdtL\n1aolGDeuAx061PR3SHmGJQpjTIGkqhw7dppixZw2h3HjbuD999cyZEhLIiML+Tm6vMWezDbGFDh/\n/HGA66//gFtv/S+qTpVrrVqlGT78OksS6bAShTGmwIiLS+SVV77n1Vd/4PTpJEqVimDHjiNUrVrS\n36HlaZYojDEFwoIFf9K371y2bj0EwP33N2LEiDaUKhXp58jyPp9WPYlIexH5Q0S2isigdJZXEpHF\nIvKriKwTEbsf0xiTo1SV+++fRdu2H7J16yHq1i3D0qX38u67nS1JeMlnJQoRCQbGA22AGGCliMxW\n1Q0eqw0FPlXViSJSF5gLVPFVTMZl3XOYAkREqFKlBBERITz7bCsGDGge0B34+YIvq56aAFtVdRuA\niEwHOgOeiUKBlJuUiwN/+zAek8K65zABbs2af9iz5xg33ODc4vrUUy3o2bOBtUWcJ18migrALo/p\nGKBpmnWeB74RkUeAwsD16e1IRB4EHgSoVKlSjgdaYNkDdibAHDsWz3PPLWHMmJ8pVSqCTZv6ERUV\nQVhYiCWJC+Dv22O7A9NUtSLQAfhARM6JSVXfVtVoVY0uU6ZMrgdpjMnbVJWZMzdSt+4ERo9eDsCd\nd9anUCF/f8UFBl+WKHYDF3tMV3TneeoFtAdQ1Z9EJBwoDezzYVzGmADy119H6Nfva+bM2QxAdPRF\nTJ7cicsuK+/nyAKHL9PtSqCmiFQVkVCgGzA7zTo7gesARKQOEA7s92FMxpgAoqp06fIpc+Zsplix\nMMaNu4Hly3tZkshhPitRqGqiiPQD5gPBwFRVXS8iw4BVqjobeAKYIiL9cRq279WUxySNMSYDyclK\nUJAgIrz+elsmTVrF6NHtKF++qL9DC0iS376Xo6OjddWqVf4OI/+wsSZMADl48CSDBi0EYMqUm/wc\nTf4iIqtVNfp8trWWnkBnY02YAKCq/N//raF27fG8886vvP/+OmJijvo7rALDuvAoKKz0YPKpjRv3\n06fPV3z33V8AtG5dhYkTO1Kxoo0TkVssURhj8iRV5dlnF/Paaz+QkJBM6dKRvPFGW3r2bICI+Du8\nAsUSRX5mXXGYACYi7N59jISEZP7978t49dXriYqK8HdYBZIlivzM2yRh7REmn/j772McOHCSBg3K\nATBiRBt69WpMixbWI4M/WaIIBNb+YPK5pKRkJk5cxZAh31KhQlHWrOlNaGgwpUtHUrq0JQl/s0Rh\njPGrX37Zw0MPzWHVKqdP0JYtK3P0aDylS1sX4HmFV4nCfbK6kqpu9XE8JiPWHmECzNGj8TzzzLeM\nG7eS5GSlYsVijB3bnptvrm2N1XlMlolCRDoCo4BQoKqINAKeU9VbfB2c8WDPQ5gAoqq0bPkea9fu\nJThYGDCgGc8/35qiRcP8HZpJhzclimE43YMvBlDVNSJSw6dRmYxZe4QJACJC//7NmDBhFZMnd6JR\no3/5OySTCW8SRYKqHklTFLRvK2OM106fTmLUqJ8IDhYGDmwBwN13N+SuuxoQHGwdROR13iSKjSJy\nBxAkIlWBR4Hlvg3LGBMovv/+L3r3/ooNG/YTFhbM3Xc3pFy5IogIwcHWFpEfeJMo+gHPAsnAFzi9\nwT7ty6AKHGuoNgHowIGTPPnkAt57bw0ANWtGMWFCR8qVK+LnyEx2eZMo2qnqU8BTKTNE5FacpGFy\ngj04ZwKIqjJt2hoGDlzAwYOnCA0NZvDgqxg06CrCw+2O/PzIm/+1oZybFIakM8+kJzulBWuoNgHi\nww9/4+DBU1x7bVUmTOhArVql/R2SuQAZJgoRaYczTGkFERnlsagYTjWUSc/5ViNZacHkYydPJhAb\nG0f58kURESZM6MDKlX/To0d9eyYiAGRWotgH/A7EAes95h8DBvkyqHwtvSRRtQPc+lXux2JMLvj6\n6y08/PBcqlUryYIFPRERatUqbaWIAJJholDVX4FfReQjVY3LxZjyDxs9zhRgu3cf5fHH5zNjxgYA\nihYN4+DBU9b1RgDypo2igogMB+oC4SkzVfUSn0WVX9jT0qYASkpKZvz4lQwd+i3Hjp2mcOFCDBt2\nDY8+2pSQEHsmIhB5kyimAS8BrwM3APdhD9ydzUoPpoBITlZatZrGDz/sAuDmm2szZkx7KlUq7ufI\njC95k/4jVXU+gKr+qapDcRKGMaaACQoS2ratzsUXF2PWrG7MnNnVkkQB4E2JIl5EgoA/RaQ3sBso\n6tuwjDF5gary6afrCQkJokuXugA89VQLBgxoTpEioX6OzuQWbxJFf6AwTtcdw4HiwP2+DMoY439/\n/nmIvn3n8s03f1KmTCTXXluVkiUjCAsLIcw6eS1QskwUqvqz+/IY0BNARCr4MihjjP/ExycycuSP\nDB/+PXFxiZQsGc7w4ddSvHh41hubgJRpohCRK4AKwDJVPSAil+J05XEtUDEX4jPG5KIlS3bQp89X\nbNp0AICePRvw+uttKVu2sJ8jM/6UYWO2iLwCfAT0AOaJyPM4Y1KsBezWWGMCTFJSMn37OkmiVq1S\nfPvt3bz//i2WJEymJYrOQENVPSUiUcAuoL6qbsud0IwxvpacrMTFJRIZWYjg4CAmTuzI0qV/8eST\nLQgLsw78jCOzd0Kcqp4CUNVDIrLZkoQxgeO33/bSu/dX1K5dinff7QxAq1ZVaNWqin8DM3lOZomi\nmoik9BArOONlp/YYq6q3+jQyY4xPnDhxmmHDvmPUqOUkJiazffthDh8+RcmSEf4OzeRRmSWKLmmm\nx/kyEGOM7/3vf3/Qr9/X7NwZiwj07RvN8OHXUaKE3dFkMpZZp4CLcjMQY4zvJCYm07XrDL74YiMA\njRr9i8mTO9Gkid3pbrJmrVXGFAAhIUEULx5GkSKhvPjiNfTr18Q68DNeE1XfdWgnIu2BMUAw8I6q\nvprOOncAz+N0NLhWVe/MbJ/R0dG6atUqH0TrhYy6FbdOAU0e9PPPMQA0beo88nTw4ElOnUqkYsVi\n/gzL+ImIrFbV6PPZ1usShYiEqWp8NtYPBsYDbYAYYKWIzFbVDR7r1AQGAy1U9bCIlPU+dD/IaFAi\nY/KQI0fiGDx4IZMnr6Z27dKsWdOb0NBgSpWycSLM+ckyUYhIE+BdnD6eKolIQ+ABVX0ki02bAFtT\nbqkVkek4z2Zs8Fjn38B4VT0MoKr7sn8KfmAlCJMHqSqffPI7AwbMZ+/eE4SEBHHTTbVISkrGKdQb\nc368KVGMBToBXwKo6loRucaL7SrgPKSXIgZommadSwBE5Aecd/LzqjrPi30bYzxs2XKQvn3nsnCh\n86hTixYXM2lSJ+rVy9uFdJM/eJMoglT1rzQDpCfl4PFrAq1x+o5aKiL1VfWI50oi8iDwIEClSpVy\n6NDGBIaEhCSuvfZ9YmKOEhUVwYgR13PffY0JCpKsNzbGC94kil1u9ZO67Q6PAJu92G43cLHHdEV3\nnqcY4GdVTQC2i8hmnMSx0nMlVX0beBucxmwvjm1MwFNVRIRChYIZPvxaFi/ewYgR11OmjPXNZHKW\nN/fH9QEGAJWAvUAzd15WVgI1RaSqiIQC3YDZadb5Eqc0gYiUxqmKsm5CjMnE3r3H6dlzJi+9tDR1\n3t13N+S99zpbkjA+4U2JIlFVu2V3x6qaKCL9gPk47Q9TVXW9iAwDVqnqbHdZWxHZgFOdNVBVD2b3\nWMYUBMnJypQpqxk0aBFHjsRRokQ4jz/ejKJFbRQh41veJIqVIvIH8F/gC1U95u3OVXUuMDfNvGc9\nXitOaWWAt/s0piBau/Yfevf+iuXLnWcj2revwfjxHSxJmFzhzQh31UXkSpyqoxdEZA0wXVWn+zw6\nf8ro4TpjclFCQhKDBy/izTeXk5SklC9fhDFj2nPbbXVJc4OJMT7j1TP8qvqjqj4KXAYcxRnQKLBl\nlCTsATuTi0JCgvj1139ITlYeeaQJGzc+zO23X2pJwuQqbx64K4LzoFw3oA4wC7jSx3HlHfZwncll\nO3fGkpSUTNWqJRERJk3qSGxsPNHRF/k7NFNAedNG8TvwP2CEqn7v43iMKbASEpIYM+ZnnntuCc2b\nV2TBgp6ICDVrlvJ3aKaA8yZRVFPVZJ9HYkwB9tNPu+jd+yvWrdsLQFRUBCdPJlC4cKifIzMmk0Qh\nIm+o6hPA5yJyTv2LjXBnzIU7fPgUgwYt5O23fwGgatUSjB/fgRtuqOnnyIw5I7MSxX/df21kO2N8\nID4+kUaNJrNzZyyFCgUxcOCVDBnSksjIQv4OzZizZDbC3Qr3ZR1VPStZuA/S2Qh4xlyAsLAQevVq\nzKJF25k4sSN165bxd0jGpMub22PvT2der5wOxJhAFxeXyHPPLebjj39Lnff001ezZMk9liRMnpZZ\nG0VXnFtiq4rIFx6LigJH0t/KGJOeBQv+pG/fuWzdeoiyZQtzyy21iYgoZMORmnwhszaKFcBBnF5f\nx3vMPwb86sugjAkU//xznAED5vPJJ78DcOmlZZg0qRMREdYOYfKPzNootgPbgYW5F44xgSEpKZnJ\nk1fz9NOLiI2NJyIihOeea0X//s0JDbXR5kz+klnV03eq2kpEDgOet8cKTn9+UT6Pzph8KilJeeut\nFcTGxtOhQ03GjbuBqlVL+jssY85LZlVPKcOdls6NQIzJ744diycpSSlRIpzQ0GCmTLmRvXuPc+ut\ndaxvJpOvZdiS5vE09sVAsKomAc2BhwAbHcUYl6ryxRcbqVNnPE88MT91/lVXVaJLF+vl1eR/3txy\n8SXOMKjVgfdwhir92KdRGZNP7NhxhJtumk6XLp+ye/cxfv99P3Fxif4Oy5gc5U2iSHbHtL4VeEtV\n+wMVfBuWMXlbQkISr722jLp1xzNnzmaKFQtj3Lgb+PHH+wkP96YLNWPyD6+GQhWR24GewM3uPLu3\nzxRYJ08m0KzZO/z22z4AunWrx6hRbSlfvqifIzPGN7xJFPcDfXG6Gd8mIlWBT3wbljF5V2RkIaKj\nL+LkyQQmTOhI27bV/R2SMT7lzVCov4vIo0ANEakNbFXV4b4PzZi8QVV5//21VK8exVVXVQJg9Oh2\nhIYG24NzpkDwZoS7q4EPgN04z1D8S0R6quoPvg7OGH/buHE/ffp8xXff/UWdOqVZs6Y3oaHBFC8e\n7u/QjMk13lQ9jQY6qOoGABGpg5M4on0ZWK77omPG42SbAufUqQSGD/+eESN+ICEhmTJlIhk8+CoK\nFbK+mUzB402iCE1JEgCqulFEAm/YrfSSRNUOuR+H8bt587by8MNz2bbtMAD//vdlvPrq9URFRfg5\nMmP8w5tE8YuITAI+dKd7EMidAj5xzmB+pgA5fvw0PXvO5MCBk9SrV5ZJkzrSokUlf4dljF95kyh6\nA48CT7rT3wNv+Syi3GDVTMZDUlIyyclKoULBFCkSypgx7YmJOUr//s0oVMg68DMm00QhIvWB6sBM\nVR2ROyHlgoyShFU1FTirV//NQw/NoXPnWjzzTCsA7ryzvp+jMiZvyaz32KdxRrL7BbhCRIap6tRc\niyw3WDXVrJ/1AAAekUlEQVRTgXX0aDzPPPMt48atJDlZOXo0nkGDrrIShDHpyKxE0QNooKonRKQM\nMBcIrERhChxVZcaMDTz22Dz27DlOcLAwYEAzXnjhGksSxmQgs0QRr6onAFR1v4jYfYEmXzt2LJ6u\nXWfw9ddbAWjatAKTJnWiUaN/+TkyY/K2zBJFNY+xsgWo7jl2tqre6tPIjMlhRYqEEh+fRPHiYbz6\n6vU8+ODlBAVZF+DGZCWzRNElzfQ4XwZijC8sXfoX5csXoWbNUogIU6feRHh4COXKFfF3aMbkG5mN\nmb0oNwMxJicdOHCSJ59cwHvvreG666qyYEFPRITKlUv4OzRj8h3rON8ElORkZdq0NQwcuIBDh04R\nGhrM1VdXIilJCQmxaiZjzodPG6hFpL2I/CEiW0VkUCbrdRERFZHA6j/K5Kr16/fRuvU0evWazaFD\np7juuqr89lsfnnuuNSEhdi+GMefL6xKFiISpanw21g8GxgNtgBhgpYjM9uw3yl2vKPAY8LO3+zYm\nrdjYOJo1e5fjx09TtmxhRo1qy5131rfxqo3JAVn+zBKRJiLyG7DFnW4oIt504dEEZ+yKbap6GpgO\ndE5nvReB14A478M2xqHqPDRZvHg4Tz3Vgt69L2fTpofp0aOBJQljcog3JYqxQCfgSwBVXSsi13ix\nXQVgl8d0DNDUcwURuQy4WFW/EpGBGe1IRB4EHgSoVOk8Omizvp0Czu7dR3nssXl07lyLnj0bAjBk\nyNWWHIzxAW8qboNU9a8085Iu9MDuA3yjgCeyWldV31bVaFWNLlOmTPYPZl2IB4zExGTGjFlO7drj\n+fzzjTz33BKSkpIBLEkY4yPelCh2iUgTQN12h0eAzV5stxu42GO6ojsvRVGgHrDE/YD/C5gtIjep\n6ipvgs8269spX1u5cje9e3/FL7/sAeDmm2szdmx7goOtodoYX/ImUfTBqX6qBOwFFrrzsrISqCki\nVXESRDfgzpSFqhoLlE6ZFpElwH98liRMvnXixGmeemohEyasRBUqVSrOW2/dwE031fJ3aMYUCFkm\nClXdh/Mlny2qmigi/YD5QDAwVVXXi8gwYJWqzs52tN6w9oiAExISxMKF2wgKEgYMaM5zz7WicOHA\nG2TRmLwqy0QhIlOAc+psVPXBrLZV1bk4vc56zns2g3VbZ7U/r9hYEwHhzz8PUaJEOKVKRRIWFsIH\nH9xCeHgI9euX83doxhQ43lQ9LfR4HQ7cwtl3M/lXRiUIa4/Il+LjExk58keGD/+eHj3q8847NwFw\nxRUV/ByZMQWXN1VP//WcFpEPgGU+iyi77I6mgLFkyQ769PmKTZsOAM4dTklJydZYbYyfnU9fT1WB\nvFf+txJEvrVv3wkGDlzA+++vBaBWrVJMnNiRa66p6ufIjDHgXRvFYc60UQQBh4AM+20yJjsOHDhJ\nnTrjOXToFGFhwQwZcjVPPtmCsDDrr9KYvCLTT6M4Dzg05MzzD8ma0meCMTmgdOlIOneuRUzMUSZM\n6EiNGlH+DskYk0amiUJVVUTmqmq93ArIBLYTJ04zbNh3dOx4CS1bVgZgwoSOhIUF25PVxuRR3rQS\nrhGRxj6PxAS8//3vD+rWncCIET/St+9XJCc7hdPw8BBLEsbkYRmWKEQkRFUTgcY4XYT/CZzAGT9b\nVfWyXIrR5HO7dsXy2GPzmDlzEwCNG/+LyZM72XjVxuQTmVU9rQAuA27KpVhMgElMTGbs2J959tnF\nnDiRQJEiobz00jU8/HATG0jImHwks0QhAKr6Zy7FYgLM0aPxvPLKMk6cSKBLlzq8+WZ7KlYs5u+w\njDHZlFmiKCMiAzJaqKqjfBCPyeeOHIkjIiKEsLAQoqIimDy5E2FhwXTseIm/QzPGnKfMyv/BQBGc\n7sDT+zMmlary8ce/UavWOEaM+CF1/q231rEkYUw+l1mJYo+qDsu1SEy+tXnzQfr2/YpFi7YDsHTp\nTlTV7mQyJkBk2UZhTEbi4hJ57bVlvPzyMk6fTiIqKoKRI9tw772NLEkYE0AySxTX5VoUJt/555/j\ntGz5Hlu2HALg3nsbMXJkG0qXjvRzZMaYnJZholDVQ7kZiMlfypUrzMUXFyckJIiJEzvSqlUVf4dk\njPER63nNeCU5WZkyZTXXXFOVSy4phYjw8ce3UrJkBKGhwf4OzxjjQ/bUk8nS2rX/0KLFVHr3/oq+\nfb8ipV/IcuWKWJIwpgCwEoXJ0PHjp3n++SW8+eZykpKUiy4qSu/e0f4OyxiTyyxRmHR9+eUmHnnk\na2JijhIUJDzySBNeeulaihUL83doxphcZonCnGP37qN06zaD+PgkLr+8PJMmdSI6+iJ/h2WM8RNL\nFAaAhIQkQkKCEBEqVCjG8OHXEhoaTN++V9iY1cYUcPYNYPjxx11cfvnbfPjhutR5TzxxJY880tSS\nhDHGEkVBdujQKR566H+0aDGV337bx4QJq7CRbo0xaVnVUwGkqnz44TqeeOIb9u8/SaFCQTz5ZAuG\nDLnaut4wxpzDEkUBs3fvcbp3/5zFi3cA0KpVZSZO7EidOmX8G5gxJs+yRFHAlCgRzp49xyldOpLX\nX2/D3Xc3tFKEMSZTligKgAUL/uSyy8pTqlQkYWEhfPbZ7ZQvX4RSpawDP2NM1qwxO4Dt2XOM7t0/\np23bD3nqqYWp8+vVK2tJwhjjNStRBKCkpGQmT17N4MGLOHo0noiIEGrVKmWDCRljzosligDzyy97\n6N17DitX/g1Ax441GTeuA1WqlPBzZMaY/MoSRQDZseMITZpMISlJqVChKGPH3sAtt9S2UoQx5oL4\nNFGISHtgDBAMvKOqr6ZZPgB4AEgE9gP3q+pfvowpkFWpUoL77mtE0aJhvPBCa4oWtQ78jDEXzmeN\n2SISDIwHbgDqAt1FpG6a1X4FolW1ATADGOGreALRjh1HuPHGT/juux2p895++0ZGjWpnScIYk2N8\nWaJoAmxV1W0AIjId6AxsSFlBVRd7rL8cuMuH8QSMhIQkRo36iRde+I5TpxI5cOAkP/3UC8CqmYwx\nOc6XiaICsMtjOgZomsn6vYCv01sgIg8CDwJUqlQpp+LLl5Yt20nv3nNYv34/AN261WPUqLZ+jsoY\nE8jyRGO2iNwFRAOt0luuqm8DbwNER0cXyF7rDh8+xcCBC3j33V8BqF69JBMmdKRt2+p+jswYE+h8\nmSh2Axd7TFd0551FRK4HhgCtVDXeh/Hka8nJyqxZf1CoUBCDBl3F4MFXERFRyN9hGWMKAF8mipVA\nTRGpipMgugF3eq4gIo2ByUB7Vd3nw1jypU2bDlC1agnCwkIoVSqSjz66lUqVilO7dml/h2aMKUB8\ndteTqiYC/YD5wEbgU1VdLyLDROQmd7WRQBHgMxFZIyKzs9zx3tXwhpz5C0AnTyYwZMgiGjSYyIgR\nP6TOb9u2uiUJY0yu82kbharOBeammfesx+vrc+RAVTvkyG7ygnnzttK371ds334EgAMHTvo5ImNM\nQZcnGrOz7YnAa8/+++9jPP74PD77zLl7uH79skya1Ikrr7w4iy2NMca38meiCDCbNx8kOvptjh07\nTWRkIZ5/vhWPP96MQoWC/R2aMcZYosgLataM4oorKlC4cCHeeusGKle2DvyMMXmHJQo/OHo0nmef\nXUzfvldwySWlEBFmz+5G4cKh/g7NGGPOYYkiF6kqM2Zs4LHH5rFnz3E2bTrAvHlOryWWJIwxeZUl\nilyybdth+vWby9dfbwWgWbOKvPZaztz0ZYwxvmSJwsdOn07i9dd/5MUXlxIXl0iJEuG8+up1/Pvf\nlxMUFJjPgRhjAoslCh/btSuWYcO+Iz4+iR496vPGG20pV66Iv8MyxhivWaLwgcOHT1GiRDgiQvXq\nUYwZ054aNaK47rpq/g7NGGOyzWddeBREycnK1Km/UqPGW3z44brU+Q89FG1JwhiTb1miyCHr1++j\ndetp9Oo1m0OHTqU2WhtjTH5nVU8X6OTJBF588Ttef/0nEhOTKVu2MKNHt6N793r+Ds0YY3KEJYoL\nsHnzQdq1+5AdO44gAr17X87LL19HyZIR/g7NGGNyjCWKC1C5cnHCw0No2LAckyZ1olmziv4OyeQh\nCQkJxMTEEBcX5+9QTAESHh5OxYoVKVQo5wY2s0SRDYmJyUyatIru3etRqlQkYWEhzJvXgwoVihES\nYs095mwxMTEULVqUKlWqIGLPzBjfU1UOHjxITEwMVatWzbH92rebl1as2E2TJlN45JGveeqphanz\nK1cuYUnCpCsuLo5SpUpZkjC5RkQoVapUjpdirUSRhdjYOIYM+ZYJE1aiCpUqFadz51r+DsvkE5Yk\nTG7zxXvOEkUGVJX//nc9/fvP559/jhMSEsSAAc149tlW1oGfMaZAsTqTDKxdu5fu3T/nn3+Oc+WV\nF/PLLw/y2mttLEmYfCU4OJhGjRpRr149brzxRo4cOZK6bP369Vx77bXUqlWLmjVr8uKLL6J6ZvTI\nr7/+mujoaOrWrUvjxo154okn/HEKmfr111/p1auXv8PI1CuvvEKNGjWoVasW8+fPT3edRYsWcdll\nl9GoUSOuuuoqtm51nsPq378/jRo1olGjRlxyySWUKOGMVbN//37at2+fa+eAquarv8sror6SmJh0\n1nT//vN0ypTVmpSU7LNjmsC1YcMGf4eghQsXTn19991360svvaSqqidPntRq1arp/PnzVVX1xIkT\n2r59ex03bpyqqv72229arVo13bhxo6qqJiYm6oQJE3I0toSEhAvex2233aZr1qzJ1WNmx/r167VB\ngwYaFxen27Zt02rVqmliYuI569WsWTP1/TJ+/Hi95557zlln7Nixet9996VO33vvvbps2bJ0j5ve\new9Ypef5vWtVT67Fi7fTt+9cJk/uRMuWlQEYNaqdn6MyAeMNH7VVZGP8+ObNm7NundO1zMcff0yL\nFi1o27YtAJGRkYwbN47WrVvz8MMPM2LECIYMGULt2rUBp2TSp0+fc/Z5/PhxHnnkEVatWoWI8Nxz\nz9GlSxeKFCnC8ePHAZgxYwZz5sxh2rRp3HvvvYSHh/Prr7/SokULvvjiC9asWZP6S7lmzZosW7aM\noKAgevfuzc6dOwF48803adGixVnHPnbsGOvWraNhw4YArFixgscee4y4uDgiIiJ47733qFWrFtOm\nTeOLL77g+PHjJCUl8d133zFy5Eg+/fRT4uPjueWWW3jhhRcAuPnmm9m1axdxcXE89thjPPjgg15f\n3/TMmjWLbt26ERYWRtWqValRowYrVqygefPmZ60nIhw9ehSA2NhYLrroonP29cknn6TGmRLrRx99\ndM518YUCnyj27TvBwIELeP/9tQCMGvVTaqIwJlAkJSWxaNGi1Gqa9evXc/nll5+1TvXq1Tl+/DhH\njx7l999/96qq6cUXX6R48eL89ttvABw+fDjLbWJiYvjxxx8JDg4mKSmJmTNnct999/Hzzz9TuXJl\nypUrx5133kn//v256qqr2LlzJ+3atWPjxo1n7WfVqlXUq3emB4TatWvz/fffExISwsKFC3n66af5\n/PPPAfjll19Yt24dUVFRfPPNN2zZsoUVK1agqtx0000sXbqUli1bMnXqVKKiojh16hRXXHEFXbp0\noVSpUmcdt3///ixevPic8+rWrRuDBg06a97u3btp1qxZ6nTFihXZvXv3Odu+8847dOjQgYiICIoV\nK8by5cvPWv7XX3+xfft2rr322tR50dHRDB06NKvLnSMKbKJITlbeffcXnnpqIYcPxxEWFszQoS0Z\nOPBKf4dmAlE2fvnnpFOnTtGoUSN2795NnTp1aNOmTY7uf+HChUyfPj11umTJklluc/vttxMcHAxA\n165dGTZsGPfddx/Tp0+na9euqfvdsGFD6jZHjx7l+PHjFClypov+PXv2UKZMmdTp2NhY7rnnHrZs\n2YKIkJCQkLqsTZs2REVFAfDNN9/wzTff0LhxY8ApFW3ZsoWWLVsyduxYZs6cCcCuXbvYsmXLOYli\n9OjR3l2cbBg9ejRz586ladOmjBw5kgEDBvDOO++kLp8+fTq33XZb6nUDKFu2LH///XeOx5KeApko\ntm8/zF13zeTHH3cB0LZtdcaP70CNGlF+jsyYnBUREcGaNWs4efIk7dq1Y/z48Tz66KPUrVuXpUuX\nnrXutm3bKFKkCMWKFePSSy9l9erVqdU62eV5i2bae/oLFy6c+rp58+Zs3bqV/fv38+WXX6b+Qk5O\nTmb58uWEh4dnem6e+37mmWe45pprmDlzJjt27KB169bpHlNVGTx4MA899NBZ+1uyZAkLFy7kp59+\nIjIyktatW6f7PEJ2ShQVKlRg165dqdMxMTFUqFDhrHX279/P2rVradq0KeAkz7QN1dOnT2f8+PFn\nzUupYssNBfKup2LFwti8+SD/+lcRpk/vwrx5PSxJmIAWGRnJ2LFjeeONN0hMTKRHjx4sW7aMhQud\nh0dPnTrFo48+ypNPPgnAwIEDefnll9m8eTPgfHFPmjTpnP22adPmrC+wlKqncuXKsXHjRpKTk1N/\noadHRLjlllsYMGAAderUSf313rZtW956663U9dasWXPOtnXq1Em9OwicEkXKl/C0adMyPGa7du2Y\nOnVqahvK7t272bdvH7GxsZQsWZLIyEg2bdp0TvVPitGjR7NmzZpz/tImCYCbbrqJ6dOnEx8fz/bt\n29myZQtNmjQ5a52SJUsSGxubeq0XLFhAnTp1Updv2rSJw4cPn9OusXnz5rOq3nypwCSK+fO3Eh+f\nCECpUpHMnt2NTZsepmvXevZQlCkQGjduTIMGDfjkk0+IiIhg1qxZvPTSS9SqVYv69etzxRVX0K9f\nPwAaNGjAm2++Sffu3alTpw716tVj27Zt5+xz6NChHD58mHr16tGwYcPUX9qvvvoqnTp14sorr6R8\n+fKZxtW1a1c+/PDD1GongLFjx7Jq1SoaNGhA3bp1001StWvXJjY2lmPHjgHw5JNPMnjwYBo3bkxi\nYmKGx2vbti133nknzZs3p379+tx2220cO3aM9u3bk5iYSJ06dRg0aNBZbQvn69JLL+WOO+6gbt26\ntG/fnvHjx6dWH3Xo0IG///6bkJAQpkyZQpcuXWjYsCEffPABI0eOTN3H9OnT6dat2znfU4sXL6Zj\nx44XHKM3RNU/dafnK/pi0VW7vI95165YHn10Hl9+uYkXX7yGoUNb+jA6Y87YuHHjWb8MTc4bPXo0\nRYsW5YEHHvB3KLmuZcuWzJo1K912ofTeeyKyWlWjz+dYAVuiSExMZtSon6hTZzxffrmJIkVCiYqy\n7r+NCSR9+vQhLCzM32Hkuv379zNgwACvbh7ICQHZmL18eQy9e89h7dq9AHTpUocxY9pToUIxP0dm\njMlJ4eHh9OzZ099h5LoyZcpw880359rxAi5R/PxzDFde+S6qUKVKCcaNu4GOHS/xd1imgFJVawMz\nucoXzQkBlyiaNKlAu3Y1aNz4Xwwd2pLIyJwbvMOY7AgPD+fgwYPW1bjJNeqOR5HZbcXnI983Zm/Z\ncpD+/eczalQ7LrnEubUuOVkJCrIPpvEvG+HO+ENGI9xdSGN2vi1RxMcn8uqry3jllWXExycRHh7C\njBl3AFiSMHlCoUKFcnSUMWP8xad3PYlIexH5Q0S2isg5T6OISJiI/Ndd/rOIVPFmv4sWbaNBg0k8\n//x3xMcncd99jZg0qVNOh2+MMQYflihEJBgYD7QBYoCVIjJbVTd4rNYLOKyqNUSkG/Aa0PXcvZ2x\n/VAJrr/+AwDq1CnNpEmdrBM/Y4zxIV+WKJoAW1V1m6qeBqYDndOs0xn4P/f1DOA6yaLV7/CpSMLD\nQ3j55WtZs6a3JQljjPExnzVmi8htQHtVfcCd7gk0VdV+Huv87q4T407/6a5zIM2+HgRSOoavB/zu\nk6Dzn9LAgSzXKhjsWpxh1+IMuxZn1FLVouezYb5ozFbVt4G3AURk1fm23AcauxZn2LU4w67FGXYt\nzhCRVee7rS+rnnYDF3tMV3TnpbuOiIQAxYGDPozJGGNMNvkyUawEaopIVREJBboBs9OsMxu4x319\nG/Ct5rcHO4wxJsD5rOpJVRNFpB8wHwgGpqrqehEZhjPI92zgXeADEdkKHMJJJll521cx50N2Lc6w\na3GGXYsz7Fqccd7XIt89mW2MMSZ3BWw348YYY3KGJQpjjDGZyrOJwlfdf+RHXlyLASKyQUTWicgi\nEQnYpxCzuhYe63URERWRgL010ptrISJ3uO+N9SLycW7HmFu8+IxUEpHFIvKr+znp4I84fU1EporI\nPvcZtfSWi4iMda/TOhG5zKsdq2qe+8Np/P4TqAaEAmuBumnW6QtMcl93A/7r77j9eC2uASLd130K\n8rVw1ysKLAWWA9H+jtuP74uawK9ASXe6rL/j9uO1eBvo476uC+zwd9w+uhYtgcuA3zNY3gH4GhCg\nGfCzN/vNqyUKn3T/kU9leS1UdbGqnnQnl+M8sxKIvHlfALyI029YIPfv7c21+DcwXlUPA6jqvlyO\nMbd4cy0USBnisjjwdy7Gl2tUdSnOHaQZ6Qy8r47lQAkRKZ/VfvNqoqgA7PKYjnHnpbuOqiYCsUCp\nXIkud3lzLTz1wvnFEIiyvBZuUfpiVf0qNwPzA2/eF5cAl4jIDyKyXETa51p0ucuba/E8cJeIxABz\ngUdyJ7Q8J7vfJ0A+6cLDeEdE7gKigVb+jsUfRCQIGAXc6+dQ8ooQnOqn1jilzKUiUl9Vj/g1Kv/o\nDkxT1TdEpDnO81v1VDXZ34HlB3m1RGHdf5zhzbVARK4HhgA3qWp8LsWW27K6FkVxOo1cIiI7cOpg\nZwdog7Y374sYYLaqJqjqdmAzTuIINN5ci17ApwCq+hMQjtNhYEHj1fdJWnk1UVj3H2dkeS1EpDEw\nGSdJBGo9NGRxLVQ1VlVLq2oVVa2C015zk6qed2doeZg3n5EvcUoTiEhpnKqobbkZZC7x5lrsBK4D\nEJE6OIlif65GmTfMBu52735qBsSq6p6sNsqTVU/qu+4/8h0vr8VIoAjwmduev1NVb/Jb0D7i5bUo\nELy8FvOBtiKyAUgCBqpqwJW6vbwWTwBTRKQ/TsP2vYH4w1JEPsH5cVDabY95DigEoKqTcNpnOgBb\ngZPAfV7tNwCvlTHGmByUV6uejDHG5BGWKIwxxmTKEoUxxphMWaIwxhiTKUsUxhhjMmWJwuQ5IpIk\nIms8/qpksm6VjHrKzOYxl7i9j651u7yodR776C0id7uv7xWRizyWvSMidXM4zpUi0siLbR4XkcgL\nPbYpuCxRmLzolKo28vjbkUvH7aGqDXE6mxyZ3Y1VdZKqvu9O3gtc5LHsAVXdkCNRnolzAt7F+Thg\nicKcN0sUJl9wSw7fi8gv7t+V6axzqYiscEsh60Skpjv/Lo/5k0UkOIvDLQVquNte545h8Jvb13+Y\nO/9VOTMGyOvuvOdF5D8ichtOn1sfuceMcEsC0W6pI/XL3S15jDvPOH/Co0M3EZkoIqvEGXviBXfe\nozgJa7GILHbntRWRn9zr+JmIFMniOKaAs0Rh8qIIj2qnme68fUAbVb0M6AqMTWe73sAYVW2E80Ud\n43bX0BVo4c5PAnpkcfwbgd9EJByYBnRV1fo4PRn0EZFSwC3AparaAHjJc2NVnQGswvnl30hVT3ks\n/tzdNkVXYPp5xtkep5uOFENUNRpoALQSkQaqOhanS+1rVPUatyuPocD17rVcBQzI4jimgMuTXXiY\nAu+U+2XpqRAwzq2TT8Lptyitn4AhIlIR+EJVt4jIdcDlwEq3e5MInKSTno9E5BSwA6cb6lrAdlXd\n7C7/P+BhYBzOWBfvisgcYI63J6aq+0Vkm9vPzhagNvCDu9/sxBmK022L53W6Q0QexPlcl8cZoGdd\nmm2bufN/cI8TinPdjMmQJQqTX/QH9gINcUrC5wxKpKofi8jPQEdgrog8hDOS1/+p6mAvjtHDswNB\nEYlKbyW3b6EmOJ3M3Qb0A67NxrlMB+4ANgEzVVXF+db2Ok5gNU77xFvArSJSFfgPcIWqHhaRaTgd\n36UlwAJV7Z6NeE0BZ1VPJr8oDuxxxw/oidP521lEpBqwza1umYVTBbMIuE1EyrrrRIn3Y4r/AVQR\nkRrudE/gO7dOv7iqzsVJYA3T2fYYTrfn6ZmJM9JYd5ykQXbjdDu0ewZoJiK1cUZvOwHEikg54IYM\nYlkOtEg5JxEpLCLplc6MSWWJwuQXE4B7RGQtTnXNiXTWuQP4XUTW4IxL8b57p9FQ4BsRWQcswKmW\nyZKqxuH0rvmZiPwGJAOTcL5057j7W0b6dfzTgEkpjdlp9nsY2AhUVtUV7rxsx+m2fbyB0yvsWpzx\nsTcBH+NUZ6V4G5gnIotVdT/OHVmfuMf5Ced6GpMh6z3WGGNMpqxEYYwxJlOWKIwxxmTKEoUxxphM\nWaIwxhiTKUsUxhhjMmWJwhhjTKYsURhjjMnU/wOuuJxcC4be4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4d232ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_val,y_val_proba[:,1],drop_intermediate=False)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.1, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.1, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.1, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.15, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.15, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.15, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.1, max_depth=3, total=   6.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.1, max_depth=3, total=   9.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.1, max_depth=3, total=   9.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.15, max_depth=3, total=  10.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3, total=  11.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.15, max_depth=3, total=  11.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.15, max_depth=3, total=  12.1s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3, total=  13.6s\n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3, total=   8.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.2, max_depth=3, total=  12.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3, total=   9.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3, total=  13.7s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3, total=  12.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1400, subsample=0.25, max_depth=3, total=  14.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.1, max_depth=3, total=   9.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.15, max_depth=3, total=  12.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.15, max_depth=3, total=  10.7s\n",
      "[CV] learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.15, max_depth=3, total=  11.9s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3, total=  12.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3, total=  14.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.2, max_depth=3, total=  14.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.1, max_depth=3, total=   9.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3, total=  14.7s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3, total=  13.1s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.1, max_depth=3, total=   9.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1500, subsample=0.25, max_depth=3, total=  14.7s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.1, max_depth=3, total=  10.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.25, max_depth=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  27 tasks      | elapsed:   48.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.15, max_depth=3, total=  13.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.15, max_depth=3, total=  13.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1700, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.15, max_depth=3, total=  13.7s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.2, max_depth=3, total=  13.1s\n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.2, max_depth=3, total=  12.2s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.1, max_depth=3 \n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.2, max_depth=3, total=  14.5s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.25, max_depth=3, total=  14.6s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.25, max_depth=3, total=  12.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.1, max_depth=3, total=  12.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1700, subsample=0.25, max_depth=3, total=  13.8s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.1, max_depth=3, total=  12.3s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.1, max_depth=3, total=  12.4s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.15, max_depth=3, total=  13.0s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.15, max_depth=3, total=  13.1s\n",
      "[CV] learning_rate=0.05, n_estimators=1900, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.15, max_depth=3, total=  11.6s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.2, max_depth=3, total=  13.2s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.2, max_depth=3, total=  14.0s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.1, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.2, max_depth=3, total=  13.8s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.25, max_depth=3, total=  14.1s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.25, max_depth=3, total=  13.1s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.15, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=1900, subsample=0.25, max_depth=3, total=  13.5s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.1, max_depth=3, total=  13.7s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.1, max_depth=3, total=  13.5s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.2, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.15, max_depth=3, total=  12.6s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.1, max_depth=3, total=  13.5s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.15, max_depth=3, total=  10.4s\n",
      "[CV] learning_rate=0.05, n_estimators=2100, subsample=0.25, max_depth=3 \n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.15, max_depth=3, total=  14.6s\n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.2, max_depth=3, total=  13.3s\n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.2, max_depth=3, total=  15.0s\n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.2, max_depth=3, total=  10.6s\n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.25, max_depth=3, total=  10.4s\n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.25, max_depth=3, total=  10.9s\n",
      "[CV]  learning_rate=0.05, n_estimators=2100, subsample=0.25, max_depth=3, total=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  60 out of  60 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'learning_rate': 0.05, 'n_estimators': 2100, 'subsample': 0.2, 'max_depth': 3} with a score of -0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Cross validation of gradient boosted tree classifier\n",
    "gbc = GradientBoostingClassifier(random_state=0,max_features=307)\n",
    "scorer = make_scorer(log_loss,greater_is_better=False,needs_proba=True)\n",
    "\n",
    "\n",
    "estimators_range = [1400,1500,1700,1900,2100]\n",
    "lr_range = [0.05]\n",
    "subsample_range = [0.10,0.15,0.20,0.25]\n",
    "max_depth_range = [3]\n",
    "param_grid = {'n_estimators':estimators_range,'learning_rate':lr_range,\n",
    "             'subsample':subsample_range,'max_depth':max_depth_range}\n",
    "cv = StratifiedShuffleSplit(n_splits=3,test_size = 0.2,random_state = 0)\n",
    "grid = GridSearchCV(gbc,param_grid=param_grid,cv=cv,n_jobs=7,verbose=2,scoring=scorer)\n",
    "\n",
    "grid.fit(X_train[:,importance_idx],y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>Mean_minus_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.653617</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>-0.076066</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1500, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>-0.086098</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.100307</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>1.203729</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.024919</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.100985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12.940099</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.075743</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>2100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 2100, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.085424</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.100900</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>1.832989</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.025431</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.101174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.653267</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>-0.075932</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1900</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1900, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.085529</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.100929</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>0.316417</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.025257</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.101189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.465597</td>\n",
       "      <td>0.011843</td>\n",
       "      <td>-0.076798</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1400, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.086640</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>-0.101219</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>0.828779</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.024948</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.101746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.251170</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>-0.076396</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>1700</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 1700, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>-0.086266</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.101700</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.929715</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.025657</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.102054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "6       13.653617         0.011632        -0.076066         -0.000215   \n",
       "18      12.940099         0.009612        -0.075743         -0.000205   \n",
       "14      13.653267         0.010859        -0.075932         -0.000207   \n",
       "2       12.465597         0.011843        -0.076798         -0.000229   \n",
       "10      13.251170         0.010663        -0.076396         -0.000208   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_subsample  \\\n",
       "6                 0.05               3               1500             0.2   \n",
       "18                0.05               3               2100             0.2   \n",
       "14                0.05               3               1900             0.2   \n",
       "2                 0.05               3               1400             0.2   \n",
       "10                0.05               3               1700             0.2   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "6   {'learning_rate': 0.05, 'n_estimators': 1500, ...                3   \n",
       "18  {'learning_rate': 0.05, 'n_estimators': 2100, ...                1   \n",
       "14  {'learning_rate': 0.05, 'n_estimators': 1900, ...                2   \n",
       "2   {'learning_rate': 0.05, 'n_estimators': 1400, ...                5   \n",
       "10  {'learning_rate': 0.05, 'n_estimators': 1700, ...                4   \n",
       "\n",
       "         ...        split0_train_score  split1_test_score  split1_train_score  \\\n",
       "6        ...                 -0.000218          -0.086098           -0.000213   \n",
       "18       ...                 -0.000207          -0.085424           -0.000205   \n",
       "14       ...                 -0.000208          -0.085529           -0.000207   \n",
       "2        ...                 -0.000230          -0.086640           -0.000229   \n",
       "10       ...                 -0.000211          -0.086266           -0.000208   \n",
       "\n",
       "    split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "6           -0.100307           -0.000213      1.203729        0.000112   \n",
       "18          -0.100900           -0.000204      1.832989        0.001907   \n",
       "14          -0.100929           -0.000204      0.316417        0.001777   \n",
       "2           -0.101219           -0.000227      0.828779        0.000679   \n",
       "10          -0.101700           -0.000206      0.929715        0.001739   \n",
       "\n",
       "    std_test_score  std_train_score  Mean_minus_STD  \n",
       "6         0.024919         0.000002       -0.100985  \n",
       "18        0.025431         0.000001       -0.101174  \n",
       "14        0.025257         0.000002       -0.101189  \n",
       "2         0.024948         0.000002       -0.101746  \n",
       "10        0.025657         0.000002       -0.102054  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results['Mean_minus_STD']=results['mean_test_score']-results['std_test_score']\n",
    "results.sort_values('Mean_minus_STD',inplace=True,ascending=False)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data class proportions are different than training data proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 Total Samples.\n",
      "150.0 Total positives, corresponding to 67.0% of the data\n"
     ]
    }
   ],
   "source": [
    "print(\"{} Total Samples.\".format(len(y_val)))\n",
    "print(\"{0} Total positives, corresponding to {1:.1f}% of the data\".format(sum(y_val),sum(y_val)*100/len(y_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 5 (early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many consecutive decreases of loss on validation set(10): stopping early at iteration 323.\n",
      "Validation Scores:\n",
      "Log-Loss: 0.4027154581158788\n",
      "Positive Label\n",
      "Precision: 0.8304093567251462, Recall: 0.9466666666666667, F1: 0.8847352024922118, Support: 150\n",
      "Negative Label\n",
      "Precision: 0.8490566037735849, Recall: 0.6081081081081081, F1: 0.7086614173228346, Support: 74\n",
      "Accuracy: 0.8348214285714286\n",
      "\n",
      "Training Scores:\n",
      "Log-Loss: 0.045037239466096154\n",
      "Positive Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Negative Label\n",
      "Precision: 1.0, Recall: 1.0, F1: 1.0, Support: 544\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.ensemble._gradient_boosting import predict_stage\n",
    "\n",
    "#Early stopping monitor from https://henri.io/posts/using-gradient-boosting-with-early-stopping.html\n",
    "class Monitor():\n",
    "    \"\"\"Monitor for early stopping in Gradient Boosting for classification.\n",
    "\n",
    "    The monitor checks the validation loss between each training stage. When\n",
    "    too many successive stages have increased the loss, the monitor will return\n",
    "    true, stopping the training early.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_valid : array-like, shape = [n_samples, n_features]\n",
    "      Training vectors, where n_samples is the number of samples\n",
    "      and n_features is the number of features.\n",
    "    y_valid : array-like, shape = [n_samples]\n",
    "      Target values (integers in classification, real numbers in\n",
    "      regression)\n",
    "      For classification, labels must correspond to classes.\n",
    "    max_consecutive_decreases : int, optional (default=5)\n",
    "      Early stopping criteria: when the number of consecutive iterations that\n",
    "      result in a worse performance on the validation set exceeds this value,\n",
    "      the training stops.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_valid, y_valid, max_consecutive_decreases=5):\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.max_consecutive_decreases = max_consecutive_decreases\n",
    "        self.losses = []\n",
    "\n",
    "\n",
    "    def __call__(self, i, clf, args):\n",
    "        if i == 0:\n",
    "            self.consecutive_decreases_ = 0\n",
    "            self.predictions = clf._init_decision_function(self.X_valid)\n",
    "\n",
    "        predict_stage(clf.estimators_, i, self.X_valid, clf.learning_rate,\n",
    "                      self.predictions)\n",
    "        self.losses.append(clf.loss_(self.y_valid, self.predictions))\n",
    "\n",
    "        if len(self.losses) >= 2 and self.losses[-1] > self.losses[-2]:\n",
    "            self.consecutive_decreases_ += 1\n",
    "        else:\n",
    "            self.consecutive_decreases_ = 0\n",
    "\n",
    "        if self.consecutive_decreases_ >= self.max_consecutive_decreases:\n",
    "            print(\"Too many consecutive decreases of loss on validation set\"\n",
    "                  \"({}): stopping early at iteration {}.\".format(self.consecutive_decreases_, i))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "monitor = Monitor(X_val[:,importance_idx],y_val,10)\n",
    "# Retrain using best params\n",
    "gbc = GradientBoostingClassifier(random_state=0,subsample=0.20,learning_rate=0.05,n_estimators=1500)\n",
    "gbc.fit(X_train[:,importance_idx],y_train,monitor=monitor)\n",
    "\n",
    "# Make predictions\n",
    "y_val_pred = gbc.predict(X_val[:,importance_idx])\n",
    "y_val_proba = gbc.predict_proba(X_val[:,importance_idx])\n",
    "y_train_pred = gbc.predict(X_train[:,importance_idx])\n",
    "y_train_proba = gbc.predict_proba(X_train[:,importance_idx])\n",
    "\n",
    "# Validation scores\n",
    "logl = log_loss(y_val,y_val_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_val,y_val_pred)\n",
    "acc = accuracy_score(y_val,y_val_pred)\n",
    "print(\"Validation Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\\n\".format(acc))\n",
    "\n",
    "# Training Scores\n",
    "logl = log_loss(y_train,y_train_proba)\n",
    "p,r,f,s = precision_recall_fscore_support(y_train,y_train_pred)\n",
    "acc = accuracy_score(y_train,y_train_pred)\n",
    "print(\"Training Scores:\")\n",
    "print(\"Log-Loss: {}\".format(logl))\n",
    "print(\"Positive Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[1],r[1],f[1],s[1]))\n",
    "print(\"Negative Label\")\n",
    "print(\"Precision: {}, Recall: {}, F1: {}, Support: {}\".format(p[0],r[0],f[0],s[0]))\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZMkShTHGmCz9P/EBMKRAAUsfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1848f022e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_val,y_val_proba[:,1],drop_intermediate=False)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.7s\n",
      "[CV] ................................................. , total=   5.7s\n",
      "[CV] ................................................. , total=   5.8s\n",
      "[CV] ................................................. , total=   5.5s\n",
      "[CV] ................................................. , total=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  20 out of  20 | elapsed:   24.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   7.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.7s\n",
      "[CV] ................................................. , total=   6.0s\n",
      "[CV] ................................................. , total=   5.9s\n",
      "[CV] ................................................. , total=   5.4s\n",
      "[CV] ................................................. , total=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  20 out of  20 | elapsed:   23.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score,f1_score,auc,roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# Retrain using best params\n",
    "gbc = GradientBoostingClassifier(random_state=0,subsample=0.20,learning_rate=0.05,n_estimators=323)\n",
    "\n",
    "#Scorers\n",
    "#Log-Loss\n",
    "logl_scoring = make_scorer(log_loss,needs_proba=True)\n",
    "\n",
    "def calc_auc(y,y_pred,**kwargs):\n",
    "    fpr,tpr, _ = roc_curve(y,y_pred[:,1],drop_intermediate=False)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    \n",
    "    return roc_auc\n",
    "#AUC\n",
    "auc_scoring = make_scorer(calc_auc,needs_proba=True)\n",
    "\n",
    "#Cross-Val \n",
    "logl_ary = cross_val_score(gbc,X_train[:,importance_idx],y_train,cv=20,scoring=logl_scoring,verbose=2,n_jobs=5)\n",
    "auc_ary = cross_val_score(gbc,X_train[:,importance_idx],y_train,cv=20,scoring=auc_scoring,verbose=2,n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Log-Loss was 0.16 with std 0.06\n",
      "Average AUC was 0.99 with std 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAE/CAYAAABin0ZUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1MAwJUmS1OD/A49vVBTmCRBuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1878084a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "sns.boxplot(logl_ary,ax=axes[0])\n",
    "axes[0].set_title(\"Logloss: 10 Fold Cross-Validation of Final Model\")\n",
    "sns.boxplot(auc_ary,ax=axes[1])\n",
    "axes[1].set_title(\"AUC: 10 Fold Cross-Validation of Final Model\")\n",
    "\n",
    "print(\"Average Log-Loss was {0:.2f} with std {1:.2f}\".format(np.mean(logl_ary),np.std(logl_ary)))\n",
    "print(\"Average AUC was {0:.2f} with std {1:.2f}\".format(np.mean(auc_ary),np.std(auc_ary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store results so that we don't lose this data again\n",
    "with h5py.File(\"feature_data.hdf5\",\"r\") as f:\n",
    "    importance_idx = f[\"importance_idx\"].value\n",
    "    feature_importances = f[\"feature_importances\"].value\n",
    "feature_importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FeatureN</th>\n",
       "      <th>Importance</th>\n",
       "      <th>Angle</th>\n",
       "      <th>LayerN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>9766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57766</th>\n",
       "      <td>57766</td>\n",
       "      <td>0.906104</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>1766</td>\n",
       "      <td>0.399107</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75497</th>\n",
       "      <td>75497</td>\n",
       "      <td>0.372471</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27162</th>\n",
       "      <td>27162</td>\n",
       "      <td>0.350269</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37199</th>\n",
       "      <td>37199</td>\n",
       "      <td>0.336560</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66347</th>\n",
       "      <td>66347</td>\n",
       "      <td>0.334686</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75462</th>\n",
       "      <td>75462</td>\n",
       "      <td>0.327850</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30628</th>\n",
       "      <td>30628</td>\n",
       "      <td>0.323317</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97928</th>\n",
       "      <td>97928</td>\n",
       "      <td>0.299064</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121674</th>\n",
       "      <td>121674</td>\n",
       "      <td>0.274433</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73766</th>\n",
       "      <td>73766</td>\n",
       "      <td>0.248438</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48075</th>\n",
       "      <td>48075</td>\n",
       "      <td>0.229929</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69985</th>\n",
       "      <td>69985</td>\n",
       "      <td>0.225570</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121692</th>\n",
       "      <td>121692</td>\n",
       "      <td>0.222121</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95011</th>\n",
       "      <td>95011</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17991</th>\n",
       "      <td>17991</td>\n",
       "      <td>0.177595</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34757</th>\n",
       "      <td>34757</td>\n",
       "      <td>0.168886</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77503</th>\n",
       "      <td>77503</td>\n",
       "      <td>0.168199</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83013</th>\n",
       "      <td>83013</td>\n",
       "      <td>0.165966</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FeatureN  Importance  Angle LayerN\n",
       "9766        9766    1.000000      1      4\n",
       "57766      57766    0.906104      7      4\n",
       "1766        1766    0.399107      0      4\n",
       "75497      75497    0.372471      9      6\n",
       "27162      27162    0.350269      3      6\n",
       "37199      37199    0.336560      4      8\n",
       "66347      66347    0.334686      8      4\n",
       "75462      75462    0.327850      9      6\n",
       "30628      30628    0.323317      3      9\n",
       "97928      97928    0.299064     12      4\n",
       "121674    121674    0.274433     15      4\n",
       "73766      73766    0.248438      9      4\n",
       "48075      48075    0.229929      6      0\n",
       "69985      69985    0.225570      8      9\n",
       "121692    121692    0.222121     15      4\n",
       "95011      95011    0.221239     11      9\n",
       "17991      17991    0.177595      2      4\n",
       "34757      34757    0.168886      4      5\n",
       "77503      77503    0.168199      9      8\n",
       "83013      83013    0.165966     10      5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Information about feature extraction process\n",
    "num_features = X_train.shape[1]\n",
    "features_per_angle = num_features // 16\n",
    "layer_size = [256,288,288,768,768,768,768,768,1280,2048]\n",
    "layer_bins = [0]\n",
    "for size in layer_size:\n",
    "    layer_bins.append(size+layer_bins[-1])\n",
    "layer_labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "# Create dataframe with feature importances and other information about feature provenance\n",
    "feature_n = np.arange(0,num_features)\n",
    "df = pd.DataFrame({'FeatureN':feature_n,'Importance':feature_importances/feature_importances.max()})\n",
    "df['Angle'] = df['FeatureN']//features_per_angle\n",
    "df['LayerN'] = pd.cut(df['FeatureN']%sum(layer_size),layer_bins,labels=layer_labels,right=False,include_lowest=True)\n",
    "\n",
    "df.sort_values('Importance',inplace=True,ascending=False)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2472b35b00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCiIiElFSEBGRyP8H9kFBB7dMmaMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24732390b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "% matplotlib inline\n",
    "\n",
    "df_no_zero = df.loc[lambda df: df.Importance > 0 ,:]\n",
    "sns.boxplot(x=\"LayerN\",y=\"Importance\",data=df_no_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2424ec87f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf41TV+oJI4DcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2472aaa240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"Angle\",y=\"Importance\",data=df_no_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x7f246ef2edd8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHLxJREFUeJzt3XmQnPWd3/H3t7une+5DmtE9YiQQp8BIGTBGEPC5sOuF\nJN7YYDs+wEuSWlybPVLlVFJOivzjXVcllWzwOhT24mMBs97atRZrFzs2YG4kxKEDJHSOZjSaQ3Mf\n3T3d/c0f3ZKGQWJamp55uns+rypVP8evn+erQfrox+95nt9j7o6IiJSXUNAFiIhI4SncRUTKkMJd\nRKQMKdxFRMqQwl1EpAwp3EVEypDCXUSkDCncRUTKkMJdRKQMRYI6cXNzs7e1tQV1ehGRkvTaa6/1\nu3vLbO0CC/e2tjZ27NgR1OlFREqSmR3Np52GZUREypDCXUSkDCncRUTKkMJdRKQMKdxFRMrQrOFu\nZt83s14z232O/WZm/9vMDpjZW2a2ufBliojI+cin5/4IcNsH7L8d2JD7dR/wl3MvS0RE5mLWcHf3\n3wADH9DkTuCHnvUy0GhmKwtVoIiInL9CjLmvBo5NW+/MbRMRkYAs6AVVM7vPzHaY2Y6+vr6FPLWI\nyKJSiHDvAlqnra/JbXsfd3/I3dvdvb2lZdapEURE5AIVYm6ZrcD9ZvY48GFg2N27C3BcEZH3SGec\nqXQm98tJpTMkpy1PpZ2MO+mMk3Ynk5m+DKlMJrc/e6xTbU9/J7ecykz/LtnlU22nHTv1nvNwznNP\nP3Z6Rtvp537Pd3N1ZmZsy9es4W5mjwG3As1m1gn8V6ACwN2/C2wDfhs4AEwAXz3v/2IiUtKm0hkm\nEmnGkinGEynGEqnseiK7Pp4817Y0E4kUU+kMydMBnQ3p6SEen0qTzjj5R9vCCBmEzLD3fdrpfSHj\n9Pr07afbkmsXOrMtZGBkP8Mho2LaMfM1a7i7+92z7HfgD/I/pYgApNIZ+seS9I8liE+lmZxKM5mc\n8TmVJp5ME09lyGScjIPjuIP7mfWMc3qbn20b2Z5idt+ZbafS8swxs+tpzwZtKtdTzvaYnVQmQyoX\nvMl0hvFcWCdTmbx+zwbEKkLEImGi4RCxihDRcIhI2AibEYuEqIqGiYSMcMgImZ1Zzn1G7MxyOJT9\nXnha+3MFqpkRPr3+/kA+V/iePbyzn0HYmme7wKb8FSkXj77S8b5tqUw2uAfHk4zEpxiNpxiZzH6O\nxqcYiWd7r/n0RA2IhLM9NwNOZYqRDRkjuzGUa5xtk21kM9enfT97hNzGMx+575wKS84Eq50J0Opo\nhLqQsaohRCwSIhoJE4ucWs6G95nlELGK7HokZKdrkfmlcBeZg3TGOTmWoGckzomR7GfPSJz+sQSZ\nacltQE0sQn1lhLrKClY1VlFfVUFdZYSaaIRYJERFOERFJERF2IiGsz3aCgWiXCCFuywKZ+tdn690\nxjkxEqdzcILOwUlODMfpHY0zlT6T4k3VFSyvr+SKlfUsr6+kuTZKXWUFtbEI4fMZMBWZI4W7yFlk\n3BkYS3JscILOoUk6ByboHo6TynXHq6NhVjVUcX3bEpbXV7K8vpJl9TFikXDAlYtkKdxl0cu40z+a\n4PhwnO7hSbqH4nQOTRCfyl4krAgbqxuruWH9UtY0VbGmqZqm6goNlUhRU7jLojKVztAzEqd7KM7x\n4UmOD01yYuTM0Eo4ZKyor+Sa1Y2ng7ylLqYhFSk5CncpS/GpNAf7xjjQO8a7PWP8+p1eekcTDIyf\nudAZi4RY2VDFdW1LWNVQxcrGSpbVVSrIpSwo3KWonM+Fz1Qmw/DEFIMTUwxOJDk5lqRvNE7PaILB\n8eTp2wxDBktqYiyri7FxdT0rG6pY1VBJU000sHuVReabwl2KUjKVYTz3tONEMs3IZDbEhyaSDEwk\nGZqYYmRy6j33iYfNWFobZVVjFde2NrKsLsay+kqaa6JEwnrpmCwuCndZEO7O8OQUvaMJekcS9I3F\n6R1J0Dua4ORYgpPjSQYnkhwbmGQimXrP7YWnGNBQVUFjdZSLW2porI7SVB2lqaaCpuoo9ZUVGlIR\nyVG4ywU51/BJOuN0D0/SMTBBx8AEg+NJRhMpxuKp07cRThcNh6iJhamJZR/mubilhppohOpYhJro\nqe1haisraKhSeIvkS+EuczKRSNExMMHRXJh3Dk6c7nU3VFXQXBulrbaGutyTmdnPCPWx7HKsQveF\ni8wHhXsZK8RTmWfTOxrnhQMnOdI/Tt9YAshetFzVmL3zZO2Sai5aWkNDVcW8nF9EZqdwl7wNTST5\n1Tu97Dw6SEU4xPqWGjavbWTt0hpWN1YRjeiipUixULjLrMYSKZ7d18srhwdw4MaLl3LLZcuojemP\nj0ix0t9OOafEVJrnD/Tz/IF+kqkMm9c28bErltFUHQ26NBGZhcJd3mcqneHVwwM8va+XiWSaq1bV\n84krlrO8vjLo0kQkTwp3eY9jAxM89moHQ5NTXNxSw6euXEHrkuqgyxKR86Rwl9M6Byf4/guHqYlF\nuGfLOi5ZVht0SSJygRTuAkDX0CTff+Ew1dEwX7tpHY0aVxcpabp3TegenuT7zx+msiLM125er2AX\nKQMK90XuxEic7z1/mGgkxNduWq87YUTKhMJ9EevNBXskZHztpnUsqVGwi5QLhfsi1T+a4HvPHyYE\n3HvTepbWxoIuSUQKSOG+CJ0cS/Dw84fIuHPPTetoqVOwi5QbhfsiMzCe5OHnD5PKOPfevF4PJomU\nKYX7IjI0keTh5w+RTGW4Z8s6VijYRcqWwn2RcHd++lonk8k092xZx6rGqqBLEpF5pHBfJHYfH+FQ\n/zi/ddUKVjcp2EXKncJ9EUimMmzb1c3KhkquX7ck6HJEZAEo3BeBZ/f3Mjw5xaevWUXI9A5SkcVA\n4V7mBsaTPPduPx9a08C65pqgyxGRBZLXxGFmdhvwv4Aw8LC7f2vG/rXAD4DGXJtvuPu2Atdatubr\nXacAP3/rOCEzbtu4ct7OISLFZ9aeu5mFgQeB24ErgbvN7MoZzf4L8IS7bwLuAr5T6ELl/O07Mcrb\nJ0b56OXL9LJqkUUmn2GZ64ED7n7I3ZPA48CdM9o4UJ9bbgCOF65EuRCpdIYn3zrO0pooWy5eGnQ5\nIrLA8gn31cCxaeuduW3T/Tfgi2bWCWwDvl6Q6uSCvXDwJCfHk3z6mlVEwrq0IrLYFOpv/d3AI+6+\nBvht4Edm9r5jm9l9ZrbDzHb09fUV6NQy0/DkFE+/08vlK+q4bEVd0OWISADyCfcuoHXa+prctunu\nBZ4AcPeXgEqgeeaB3P0hd2939/aWlpYLq1hm9U+7u8m48ztX6yKqyGKVT7hvBzaY2Tozi5K9YLp1\nRpsO4OMAZnYF2XBX1zwAh/vHebNzmJs3NGsaX5FFbNZwd/cUcD/wFPA22bti9pjZA2Z2R67ZnwC/\nb2ZvAo8BX3F3n6+i5ewy7jz51nEaqiq45dJlQZcjIgHK6z733D3r22Zs++a05b3AlsKWJufr1cMD\ndA/Hufv6tUQjuogqspgpAcrEeCLFL/f2sL65ho2r6mf/goiUNYV7mfjVOz0kUml+90OrMM0fI7Lo\nKdzLQHwqzWtHB9nU2qQ3K4kIoHAvC292DjGVdk3nKyKnKdzLwI4jg6yor2SNXsIhIjkK9xLXNTRJ\n19Ak7W1NGmsXkdMU7iVu+5EBIiFjU2tT0KWISBFRuJewZCrDm8eGuHp1A1XRcNDliEgRUbiXsF1d\nQyRSGdrbdCFVRN5L4V7Cth8ZpKU2RtvS6qBLEZEio3AvUT0jcToGJnQhVUTOSuFeorYfGSBsxqa1\nupAqIu+ncC9BU+kMr3cMceWqempjec39JiKLjMK9BO05PsLkVJrrdCFVRM5B4V6Cth8ZoKm6gvUt\nNUGXIiJFSuFeYvpHExzuH+e6tiWEdCFVRM5B4V5ith8dIGSw+SJdSBWRc1O4l5BUJsPOo4NcvqKe\n+sqKoMsRkSKmcC8hb3ePMp5Mc12beu0i8sEU7iVkx5EBGqoq2LC8LuhSRKTIKdxLxOB4kgO9Y/yz\ni5p0IVVEZqVwLxE7jg4A0K4LqSKSB4V7CUhnnNeODrJheS2N1dGgyxGREqBwLwH7e0YZiaf0RKqI\n5E3hXgK2HxmgNhbh8hX1QZciIiVC4V7kJhIp9veMsnltI+GQLqSKSH4U7kVuT/cIGYer1zQGXYqI\nlBCFe5Hb3TXMkpooqxoqgy5FREqIwr2ITSRSHOwb4+rVDXrbkoicF4V7ETs1JLNxdUPQpYhIiVG4\nFzENyYjIhVK4FykNyYjIXCjci5SGZERkLvIKdzO7zcz2mdkBM/vGOdp81sz2mtkeM3u0sGUuPhqS\nEZG5iMzWwMzCwIPAJ4FOYLuZbXX3vdPabAD+E7DF3QfNbNl8FbwYnBqSuXlDi4ZkROSC5NNzvx44\n4O6H3D0JPA7cOaPN7wMPuvsggLv3FrbMxUVDMiIyV/mE+2rg2LT1zty26S4FLjWzF8zsZTO7rVAF\nLkYakhGRuZp1WOY8jrMBuBVYA/zGzK5296HpjczsPuA+gLVr1xbo1OVFQzIiUgj59Ny7gNZp62ty\n26brBLa6+5S7Hwb2kw3793D3h9y93d3bW1paLrTmsqYhGREphHzCfTuwwczWmVkUuAvYOqPN35Pt\ntWNmzWSHaQ4VsM5FQ0MyIlIIs4a7u6eA+4GngLeBJ9x9j5k9YGZ35Jo9BZw0s73A08B/dPeT81V0\nudKDSyJSKHmNubv7NmDbjG3fnLbswB/nfskF2qshGREpED2hWkR2aUhGRApE4V4kNCQjIoWkcC8S\nGpIRkUJSuBcJDcmISCEp3IuAhmREpNAU7kVAQzIiUmgK9yKgIRkRKTSFe8AGx5MakhGRglO4B+wX\ne09oSEZECk7hHrAn3+rWkIyIFJzCPUAD40lePHhSQzIiUnCFms99UXj0lY6CHu/Fg/2kM841azQk\nIyKFpZ57gF7vGGJVQyUrG6qCLkVEyozCPSA9I3G6hibZtLYp6FJEpAwp3AOys2OQkMGHWhuDLkVE\nypDCPQDpjPPGsSEuW15HbUyXPUSk8BTuATjYN8ZoPKUhGRGZNwr3AOzsGKSqIszlK+qCLkVEypTC\nfYFNJtPsPT7Ch1obiIT14xeR+aF0WWC7uoZJZZzNGpIRkXmkcF9gOzsGaamLsbpR97aLyPxRuC+g\n/rEEHQMTbF7bpOkGRGReKdwX0Osdgxhwre5tF5F5pnBfIBl3Xu8Y4pJltTRUVQRdjoiUOYX7Ajnc\nP87Q5JTubReRBaFwXyCvdwwSi4S4cmV90KWIyCKgcF8AiVSa3V0jXL26gWhEP3IRmX9KmgWw5/gI\nyXRG97aLyIJRuC+AnR2DLKmJctHS6qBLEZFFQuE+z4YmkhzuG2fT2kbd2y4iC0bhPs9ePzaEA5tb\nNSQjIgtH4T6P3J2dRwdZ11xDU0006HJEZBHJK9zN7DYz22dmB8zsGx/Q7jNm5mbWXrgSS1fHwAQn\nx5NsXqsnUkVkYc0a7mYWBh4EbgeuBO42syvP0q4O+EPglUIXWap2dgxRETY2rmoIuhQRWWTy6blf\nDxxw90PungQeB+48S7v/DvwZEC9gfSVrKp1hV9cQV61qIFYRDrocEVlk8gn31cCxaeuduW2nmdlm\noNXdf17A2krars5h4lO6t11EgjHnC6pmFgL+B/AnebS9z8x2mNmOvr6+uZ66aGXceXZ/HyvqK7m4\npSbockRkEcon3LuA1mnra3LbTqkDNgLPmNkR4AZg69kuqrr7Q+7e7u7tLS0tF151kdt7fIS+sQS3\nXtaie9tFJBD5hPt2YIOZrTOzKHAXsPXUTncfdvdmd29z9zbgZeAOd98xLxUXOXfnmf29LK2JsnG1\nLqSKSDBmDXd3TwH3A08BbwNPuPseM3vAzO6Y7wJLzbu9YxwfinPLpS2E1GsXkYBE8mnk7tuAbTO2\nffMcbW+de1ml65l9vTRUVXCt7m0XkQDpCdUCOtw/zpGTE9y8oZlISD9aEQmOEqiAnt3fS000TPtF\nS4IuRUQWOYV7gXQNTbK/Z4wtlzTrhRwiEjilUIE8u6+XWCTEDeuXBl2KiIjCvRB6R+PsOT7CR9Yv\npVJTDYhIEVC4F8Bv9vcTCRs3XtIcdCkiIoDCfc4GJ5K8cWyQ69qWUBvL685SEZF5p3Cfo+fe7cMw\nblKvXUSKiMJ9DkbjU+w4MsimtY00VutNSyJSPBTuc/DCgZOkM84/v7R8J0ETkdKkcL9Ak8k0rxw+\nydVrGmiujQVdjojIeyjcL9BLh/pJpDLcol67iBQhhfsFSKTSvHDgJJevqGNlQ1XQ5YiIvI/C/QK8\nfPAkk1Npbr1sWdCliIiclcL9PA1NJPn1vl6uWFnP2iXVQZcjInJWCvfz9PNd3QB8+pqVAVciInJu\nCvfzsO/ECHuOj/Cxy5bRpPvaRaSIKdzzFJ9K8w9vddNSG2PLBj2NKiLFTeGep+88c5CB8SR3XLtK\nb1kSkaKnlMrD4f5xvvvMQa5tbeTiltqgyxERmZXCfRbuzjd/tptYJMTtG1cEXY6ISF4U7rPYtusE\nz73bz5/+1mXUVVYEXY6ISF4U7h9gLJHigSf3cNWqer54w0VBlyMikreye7vEo690FOxY23Z10zuS\n4F9tWsNPth8r2HFFROabeu7n0D08yYsH+7mubQmtehJVREqMwv0sMu787I3jVFaE+dRVy4MuR0Tk\nvCncz+L1jkE6Bia4feNKqqNlN3IlIouAwn2GiUSKf9x9gouWVLNpbWPQ5YiIXBCF+wzbdncTn0pz\nx7WrCJkFXY6IyAVRuE+zs2OQnR1D3HJpi17CISIlTeGe0zsS52dvdLGuuYaPXa6LqCJS2hTuQDKV\n4dFXO4hGwnzuulbCIQ3HiEhpU7gD//DmcfpGE3y2fQ31mmJARMpAXuFuZreZ2T4zO2Bm3zjL/j82\ns71m9paZ/crMSuZZ/Z1HB3mtY5BbL1vGhmV1QZcjIlIQs4a7mYWBB4HbgSuBu83syhnNXgfa3f0a\n4KfAnxe60PnQMxLnZ29mx9k/foVedi0i5SOfnvv1wAF3P+TuSeBx4M7pDdz9aXefyK2+DKwpbJmF\nl0xleGzaOLtuexSRcpJPuK8Gps+a1Znbdi73Av94th1mdp+Z7TCzHX19fflXOQ+25sbZP9feqnF2\nESk7Bb2gamZfBNqBb59tv7s/5O7t7t7e0tJSyFOfl9eODrKzY5CPXr6MS5bpzUoiUn7ymTilC2id\ntr4mt+09zOwTwH8GbnH3RGHKK7yekThb3+xifXMNH7tc4+wiUp7y6blvBzaY2ToziwJ3AVunNzCz\nTcD/Be5w997Cl1kYp+5nj2mcXUTK3Kzh7u4p4H7gKeBt4Al332NmD5jZHblm3wZqgb8xszfMbOs5\nDhcYd+fv3+iifzTBZ9tb9co8ESlrec1n6+7bgG0ztn1z2vInClxXwT29r483jg3xiSs0zi4i5W9R\nPKH6xrFB/t/bPWxqbeSjl2mcXUTKX9mH++H+cf52Z/ZBpX+5eTWmcXYRWQTKOtz7RhP8+OWjLKmO\n8sUPX0QkVNa/XRGR08o27cYSKX7w0hFCIePLN7ZRFQ0HXZKIyIIpy3CfSmf40UtHGJmc4ks3XMSS\nmmjQJYmILKiyC/eMO3+z4xidg5N8tr2V1iXVQZckIrLgyi7cn9pzgt3HR7h94wo2rm4IuhwRkUCU\nVbj/+OWjPPduPzesX8KWS5qDLkdEJDB5PcQ0HwbGkzz6SkfBjrfvxCg/fOkIly2v43euXqVbHkVk\nUSuLnnvX4CSPbe9gZUMld12vd6CKiJR8uPePJXjkxcPURMN86SNtxCK65VFEpKTDfTQ+xV+9cBgH\nvnrjOuqrNBmYiAiUcLjHp9I88uIRxhNpvvyRNprrYkGXJCJSNEoy3FPpDD9+5Sg9I3E+/+G1updd\nRGSGkgv3jDtPvNbJob5xPrN5DZcurwu6JBGRolNS4e7uPPlWN7u7hrl94wo2rW0KuiQRkaJUUuH+\n7P4+Xj50kpsuaebmDcG9YFtEpNiVTLjvODLAL/b2cG1rI7dtXBF0OSIiRa0kwv3t7hH+7vUuNiyr\n5TOb1+jF1iIisyj6cD/YN8Zjr3awuqmKz394rZ4+FRHJQ2Bzy+TjQO8YP3zpCEtqonr6VETkPBRt\nuL/bM8qPXj5Kc22Me25aR22saEsVESk6RZmY+3tG+fHLR2mpi3HPlnXUKNhFRM5L0aXmvhMj/PiV\nDpbngr1awS4ict6KKjnf6R7hr1/tYEV9JV/d0kZ1tKjKExEpGUWTnnuPj/DYqx2sbKzkqzeuoyqq\ni6ciIheqKMJ9z/Hh7O2OjVV8RcEuIjJngYf77q5hHt+eDfavbllHZYWCXURkrgILd3d4el8vv3q7\nhzVN1XzlxjYFu4hIgQQW7j2jcX65t4eNq+r5zOY1xBTsIiIFE1i4hzDuvWkdF7fUBlWCiEjZCmxu\nmWX1MQW7iMg8ySvczew2M9tnZgfM7Btn2R8zs5/k9r9iZm2FLlRERPI3a7ibWRh4ELgduBK428yu\nnNHsXmDQ3S8B/ifwZ4UuVERE8pdPz/164IC7H3L3JPA4cOeMNncCP8gt/xT4uJkmXRcRCUo+4b4a\nODZtvTO37axt3D0FDANLC1GgiIicvwW9W8bM7gPuy60mvnDDRbsX8vwiImXgonwa5RPuXUDrtPU1\nuW1na9NpZhGgATg580Du/hDwEICZ7XD39nyKFBGR85PPsMx2YIOZrTOzKHAXsHVGm63Al3PLvwf8\n2t29cGWKiMj5mLXn7u4pM7sfeAoIA9939z1m9gCww923At8DfmRmB4ABsv8AiIhIQCyoDraZ3Zcb\nphERkQILLNxFRGT+BDb9gIiIzJ9Awn226QxERGRuFnxYJjedwX7gk2QfiNoO3O3uexe0EBGRMhZE\nzz2f6QxERGQOggj3fKYzEBGROdAFVRGRMhREuOcznYGIiMxBEOGez3QGIiIyBwv+DtVzTWew0HWI\niJQzPaEqIlKGdEFVRKQMKdxFRMqQwl1EpAwp3EVEypDCXUSkDCncpSSY2dgCn6/NzD6/kOcUKSSF\nu8gMuZe8twEKdylZCncpKWZ2q5k9a2Y/M7NDZvYtM/uCmb1qZrvM7OJcu0fM7LtmtsPM9pvZp3Pb\nK83sr3JtXzezj+a2f8XMtprZr4FfAd8CbjazN8zsj3I9+efMbGfu143T6nnGzH5qZu+Y2V+bmeX2\nXWdmL5rZm7n66swsbGbfNrPtZvaWmf3bQH6QUvYW/AlVkQL4EHAF2ZexHwIedvfrzewPga8D/yHX\nro3sFNMXA0+b2SXAHwDu7leb2eXAL8zs0lz7zcA17j5gZrcCf+rup/5RqAY+6e5xM9sAPAa05763\nCbgKOA68AGwxs1eBnwCfc/ftZlYPTAL3AsPufp2ZxYAXzOwX7n54Pn5Qsngp3KUUbXf3bgAzOwj8\nIrd9F/DRae2ecPcM8K6ZHQIuB24C/gLA3d8xs6PAqXD/pbsPnOOcFcD/MbNrgfS07wC86u6duXre\nIPuPyjDQ7e7bc+caye3/FHCNmf1e7rsNwAZA4S4FpXCXUpSYtpyZtp7hvX+mZ86tMdtcG+MfsO+P\ngB6y/9cQAuLnqCfNB/+9MuDr7v7ULLWIzInG3KWc/WszC+XG4dcD+4DngC8A5IZj1ua2zzQK1E1b\nbyDbE88A/4bspHcfZB+w0syuy52rLneh9ing35tZxakazKzmQn+DIueinruUsw7gVaAe+He58fLv\nAH9pZruAFPAVd0/kroFO9xaQNrM3gUeA7wB/a2ZfAv6JD+7l4+5JM/sc8BdmVkV2vP0TwMNkh212\n5i689gH/ohC/WZHpNCuklCUzewR40t1/GnQtIkHQsIyISBlSz11EpAyp5y4iUoYU7iIiZUjhLiJS\nhhTuIiJlSOEuIlKGFO4iImXo/wMTsfMDdN+1zgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f246efb8fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.distplot(df_no_zero.Importance,kde=True,kde_kws={'cumulative':True},hist_kws={'cumulative':True})\n",
    "ax.set_xlim((0,0.3))\n",
    "ax.set_xticks([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FeatureN</th>\n",
       "      <th>Importance</th>\n",
       "      <th>Angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>387.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>387.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>64692.413437</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>7.599483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34746.393470</td>\n",
       "      <td>0.079768</td>\n",
       "      <td>4.316170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.050023</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35611.500000</td>\n",
       "      <td>0.060608</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66285.000000</td>\n",
       "      <td>0.068924</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93353.500000</td>\n",
       "      <td>0.083107</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>127592.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FeatureN  Importance       Angle\n",
       "count     387.000000  387.000000  387.000000\n",
       "mean    64692.413437    0.087967    7.599483\n",
       "std     34746.393470    0.079768    4.316170\n",
       "min       152.000000    0.050023    0.000000\n",
       "25%     35611.500000    0.060608    4.000000\n",
       "50%     66285.000000    0.068924    8.000000\n",
       "75%     93353.500000    0.083107   11.000000\n",
       "max    127592.000000    1.000000   15.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_50perc = df.loc[lambda df:df.Importance>0.05,:]\n",
    "df_top_50perc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f246ee2fb70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f246eefcf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"LayerN\",data=df_top_50perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should normalize the count plot by the number of features from each layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f246ed10400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f246edd2978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_size = [256,288,288,768,768,768,768,768,1280,2048]\n",
    "counts = df_top_50perc.groupby('LayerN').count()\n",
    "\n",
    "counts['N_Features'] = layer_size\n",
    "counts['Norm_Count'] = counts['Angle']/counts['N_Features']*100\n",
    "\n",
    "ax = sns.barplot(x=counts.index,y=\"Norm_Count\",data=counts)\n",
    "ax.set_xlabel(\"Layer\")\n",
    "ax.set_ylabel(\"% of Features\")\n",
    "ax.set_title(\"% of Features in Top 50% Features by Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUS6hAK+iEiX+P+x0j0IG0QUtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f246ed419e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=\"Importance\",y=\"LayerN\",data=df_top_50perc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f246eb0a860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f246eb0a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Angle\",data=df_top_50perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs above yield surprising results. The relevance of the layers from the neural net does not monotonically decrease. Layers 1 and 4 dominate with respect to their participation among the top 50% most important features. In the future, we might want to extract features from layer 10 and use a greater spatial resolution for the most important layers (1,4 and perhaps 8 and 9)--in the extraction process we used global max pooling.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DSHenv_3.5)",
   "language": "python",
   "name": "dhsenv_3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
