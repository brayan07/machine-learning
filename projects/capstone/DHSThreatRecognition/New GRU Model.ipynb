{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to first try training a CNN on the individual images.\n",
    "We will be using binary cross entropy across the 17 regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HelperFuncs as hfuncs\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.data_utils import Sequence\n",
    "import h5py\n",
    "import os\n",
    "import gc \n",
    "\n",
    "gc.collect()\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "FINAL_WIDTH = 400\n",
    "FINAL_HEIGHT = 600\n",
    "CHANNELS = 1\n",
    "ZONES = 17\n",
    "ANGLES = 16\n",
    "#Create directories for sequencer function if they don't exist\n",
    "for d in ['temp/train_scan/','temp/test_scan/','temp/val_scan/']:\n",
    "    if not os.path.isdir(d):\n",
    "        print(\"Created directory: {}\".format(d))\n",
    "        os.makedirs(d)\n",
    "        \n",
    "class ScanSequencer(Sequence):\n",
    "    idx_dict={}\n",
    "    \n",
    "    def __init__(self,num_batches,bucket_name,mode=\"train_scan\"):\n",
    "        self.num_batches = num_batches\n",
    "        self.bucket_name = bucket_name\n",
    "        self.mode = mode\n",
    "        self.key_id, self.secret_key = hfuncs.GetAWSCredentials()\n",
    "        self.mode = mode\n",
    "        self.angles = np.arange(0,64,64//ANGLES)\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    def __getitem__(self,idx):\n",
    "        #Get Client\n",
    "        client = hfuncs.GetAWSClient(self.key_id,self.secret_key)\n",
    "        bucket = client.Bucket(self.bucket_name)\n",
    "        \n",
    "        #Initialize vectors\n",
    "        X_train = np.zeros((BATCH_SIZE,ANGLES,FINAL_WIDTH,FINAL_HEIGHT,CHANNELS))\n",
    "        y_train = np.zeros((BATCH_SIZE,ZONES))\n",
    "        \n",
    "        j=0\n",
    "        for i in range(idx*BATCH_SIZE,(idx+1)*BATCH_SIZE):\n",
    "            #Download batch at index\n",
    "            path = \"temp/{}/batch_{}.hdf5\".format(self.mode,i)\n",
    "            key = \"{}/batch_{}.hdf5\".format(self.mode,i)\n",
    "            bucket.download_file(Key=key,Filename=path)\n",
    "        \n",
    "            f = h5py.File(path,\"r\")\n",
    "            try:\n",
    "                X_train[j,:,:,:,:] = f['/image'].value[self.angles,:,:,:]\n",
    "                y_train[j,:] = f['/labels'].value\n",
    "                j += 1\n",
    "            finally:\n",
    "                f.close()\n",
    "                os.remove(path) \n",
    "        return X_train, y_train\n",
    "class LegScanSequencer(Sequence):\n",
    "    idx_dict={}\n",
    "    \n",
    "    def __init__(self,num_batches,bucket_name,mode=\"train_scan\",batch_size=BATCH_SIZE):\n",
    "        self.num_batches = num_batches\n",
    "        self.bucket_name = bucket_name\n",
    "        self.mode = mode\n",
    "        self.key_id, self.secret_key = hfuncs.GetAWSCredentials()\n",
    "        self.mode = mode\n",
    "        self.angles = np.arange(0,64,64//ANGLES)\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    def __getitem__(self,idx):\n",
    "        #Get Client\n",
    "        client = hfuncs.GetAWSClient(self.key_id,self.secret_key)\n",
    "        bucket = client.Bucket(self.bucket_name)\n",
    "        \n",
    "        #Initialize vectors\n",
    "        X_train = np.zeros((self.batch_size,ANGLES,FINAL_WIDTH,FINAL_HEIGHT*3//5,CHANNELS))\n",
    "        y_train = np.zeros((self.batch_size,1))\n",
    "        s_weights = np.zeros((self.batch_size))\n",
    "        j=0\n",
    "        for i in range(idx*self.batch_size,(idx+1)*self.batch_size):\n",
    "            #Download batch at index\n",
    "            path = \"temp/{}/batch_{}.hdf5\".format(self.mode,i)\n",
    "            key = \"{}/batch_{}.hdf5\".format(self.mode,i)\n",
    "            bucket.download_file(Key=key,Filename=path)\n",
    "        \n",
    "            f = h5py.File(path,\"r\")\n",
    "            try:\n",
    "                X_train[j,:,:,:,:] = f['/image'].value[self.angles,:,:FINAL_HEIGHT*3//5,:]\n",
    "                r_leg = [7,8,9,10,11,12,13,14,15]\n",
    "                l_leg = [13,15]\n",
    "                r_y = np.amax(f['/labels'].value[r_leg])\n",
    "                #l_y = np.amax(f['/labels'].value[l_leg])\n",
    "                y_train[j,:] = r_y\n",
    "                s_weights[j] =np.squeeze(r_y*0 + 1) #np.squeeze(r_y + (-1 * r_y + 1)*2)\n",
    "                j += 1\n",
    "            finally:\n",
    "                f.close()\n",
    "                os.remove(path) \n",
    "        return X_train, y_train,s_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twilio.rest import Client\n",
    "import configparser\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class SMSNotifier(Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        #Execute every other epoch\n",
    "        if epoch % 2 == 0:\n",
    "            #Get config credentials\n",
    "            config = configparser.ConfigParser()\n",
    "            config.read('twilio.conf')\n",
    "            account_sid = config['DEFAULT']['AccountID']\n",
    "            auth_token = config['DEFAULT']['AuthToken']\n",
    "            #Get client\n",
    "            client = Client(account_sid, auth_token)\n",
    "            #Create message\n",
    "            if logs is not None:\n",
    "                message = \"Epoch {} complete. Loss: {} Val_loss: {} \".format(epoch,\n",
    "                                                                             logs.get('loss'),\n",
    "                                                                             logs.get('val_loss'))\n",
    "            else:\n",
    "                message = \"Epoch {} complete. No loss data available.\".format(epoch)\n",
    "            #Sendmessage\n",
    "            message = client.messages.create(\n",
    "                to=\"+16178884129\", \n",
    "                from_=\"+18572142288\",\n",
    "                body=message)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build pre-trained V2 model\n",
    "import numpy as np\n",
    "from keras.layers import Input,Flatten,Dense,Concatenate,Dropout,concatenate,GlobalMaxPool2D,GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from datetime import datetime\n",
    "from keras.callbacks import TensorBoard,EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam,Adadelta,SGD\n",
    "from keras.metrics import binary_accuracy\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "from keras.layers.core import Lambda\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.initializers import RandomUniform,glorot_uniform\n",
    "#from keras.applications.vgg19 import VGG19\n",
    "\n",
    "#K.set_learning_phase(1)\n",
    "def ToRGB(x):\n",
    "    max_v = tf.reduce_max(x)\n",
    "    min_v = tf.reduce_min(x)\n",
    "    max_rgb = tf.constant(255,dtype=x.dtype)\n",
    "    min_rgb = tf.constant(255//2,dtype=x.dtype)\n",
    "    x = tf.add(tf.floordiv(tf.multiply(tf.subtract(x,min_v),tf.subtract(max_rgb,min_rgb)),tf.subtract(max_v,min_v)),min_rgb)\n",
    "    return x\n",
    "def ToGreyScale(x):\n",
    "    #Divide RGB into 3\n",
    "   # scalar = tf.constant(3,dtype=x.dtype)\n",
    "    #x = tf.floordiv(x,scalar)\n",
    "    shape = x.get_shape()\n",
    "    #assume channel_last\n",
    "    mult = [[1 for d in shape[:-1]],[3]]\n",
    "    mult = [val for sublist in mult for val in sublist]\n",
    "    return tf.tile(x,mult)\n",
    "def ToNewShape(x):\n",
    "    ndim = len(x.shape)\n",
    "    if ndim == 5:\n",
    "        return tf.reverse(tf.transpose(x,[0,1,3,2,4]),[-3])\n",
    "    elif ndim == 4:\n",
    "        return tf.reverse(tf.transpose(x,[0,2,1,3]),[-3])\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected number of dims!\")\n",
    "def PrintActivation(x):\n",
    "    meanv = tf.reduce_mean(x)\n",
    "    minv = tf.reduce_min(x)\n",
    "    maxv = tf.reduce_max(x)\n",
    "    #print('Mean:{},Min:{},Max:{}'.format(meanv.eval(),minv.eval(),maxv.eval()))\n",
    "    return [meanv,minv,maxv]\n",
    "def getSingleLegModel(lstm_dim=10):\n",
    "    #Single model image\n",
    "    input_img = Input(shape=(FINAL_WIDTH,FINAL_HEIGHT*3//5,CHANNELS))\n",
    "    \n",
    "    #preprocess and extract channels\n",
    "    input_img_pp = Lambda(ToRGB)(input_img)\n",
    "    input_img_pp = Lambda(ToGreyScale)(input_img_pp)\n",
    "    input_img_pp = Lambda(preprocess_input)(input_img_pp)\n",
    "    input_img_pp = Lambda(ToNewShape)(input_img_pp)\n",
    "    \n",
    "    #Load resnet\n",
    "    incep = InceptionV3(include_top=False,\n",
    "                          weights='imagenet',\n",
    "                          input_tensor=None,\n",
    "                          input_shape=(FINAL_HEIGHT*3//5,FINAL_WIDTH,3),\n",
    "                          pooling='None')\n",
    "    for l in incep.layers:\n",
    "        l.trainable=False\n",
    "\n",
    "    #Take off top\n",
    "    reduced_net = Model(incep.input,incep.get_layer('mixed5').output)\n",
    "    #print(reduced_net.uses_learning_phase)\n",
    "    output = reduced_net(input_img_pp)\n",
    "   # output = Lambda(PrintActivation,name='PrintDist')(output)\n",
    "    output = GlobalMaxPool2D()(output)\n",
    "    print(output.shape)\n",
    "   # output = Lambda(PrintActivation,name='PrintDist2')(output)\n",
    "    #dropout = Dropout(0.5)(output)\n",
    "    #dense = Dense(100)(dropout)\n",
    "    #output = Dense(20,kernel_initializer=glorot_uniform(seed=0))(output)\n",
    "    #output = Lambda(PrintActivation,name='PrintDist3')(output)\n",
    "    #dense = Dense(1,activation='sigmoid',use_bias=False,\n",
    "     #            kernel_initializer=RandomUniform(minval=-0.5,\n",
    "      #                                            maxval=0.5,seed=0))(output)\n",
    "    #output = Lambda(PrintActivation,name='PrintDist3')(dense)\n",
    "    intermediate_model = Model(input_img,output)\n",
    "    #print(intermediate_model.uses_learning_phase)\n",
    "    #Time distributed model\n",
    "    input_scan = Input(shape=(ANGLES,FINAL_WIDTH,FINAL_HEIGHT*3//5,CHANNELS))\n",
    "    sequenced_model = TimeDistributed(intermediate_model)(input_scan)\n",
    "    #print(sequenced_model._uses_learning_phase)\n",
    "    sequenced_model._uses_learning_phase = True\n",
    "    #One GRU layer for now\n",
    "    lstm = LSTM(100,dropout=0.20,\n",
    "              kernel_initializer=RandomUniform(minval=-1,maxval=1,seed=0),\n",
    "                return_sequences=True)(sequenced_model)\n",
    "    lstm = LSTM(20,use_bias=False,kernel_initializer=RandomUniform(minval=-1,maxval=1,seed=0))(lstm)\n",
    "    #Finally, 1 dense layers\n",
    "    out = Dense(1,activation='sigmoid',use_bias=False,\n",
    "                kernel_initializer=RandomUniform(minval=-1,maxval=1,seed=0))(lstm)\n",
    "    #complete model\n",
    "    #out = GlobalAveragePooling1D()(sequenced_model)\n",
    "    model = Model(input_scan,out)\n",
    "    try:\n",
    "        return model#Model(input_scan, out)\n",
    "    finally:\n",
    "        del intermediate_model,incep,reduced_net\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a layer specific wrapper that plots histograms only for cpecified layers and loads validation data onto memory\n",
    "class TensorBoardWrapper(TensorBoard):\n",
    "    '''Sets the self.validation_data property for use with TensorBoard callback.'''\n",
    "\n",
    "    def __init__(self, batch_gen, nb_steps,layer_ary, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.batch_gen = batch_gen # The generator.\n",
    "        self.nb_steps = nb_steps     # Number of times to call next() on the generator.\n",
    "        self.layer_ary = layer_ary\n",
    "    def set_model(self,model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "        if self.histogram_freq and self.merged is None:\n",
    "            for l in self.layer_ary:\n",
    "                layer = self.model.layers[l]\n",
    "                for weight in layer.weights:\n",
    "                    mapped_weight_name = weight.name.replace(':', '_')\n",
    "                    tf.summary.histogram(mapped_weight_name, weight)\n",
    "                    if self.write_grads:\n",
    "                        grads = model.optimizer.get_gradients(model.total_loss,\n",
    "                                                              weight)\n",
    "\n",
    "                        def is_indexed_slices(grad):\n",
    "                            return type(grad).__name__ == 'IndexedSlices'\n",
    "                        grads = [\n",
    "                            grad.values if is_indexed_slices(grad) else grad\n",
    "                            for grad in grads]\n",
    "                        tf.summary.histogram('{}_grad'.format(mapped_weight_name), grads)\n",
    "                    if self.write_images:\n",
    "                        w_img = tf.squeeze(weight)\n",
    "                        shape = K.int_shape(w_img)\n",
    "                        if len(shape) == 2:  # dense layer kernel case\n",
    "                            if shape[0] > shape[1]:\n",
    "                                w_img = tf.transpose(w_img)\n",
    "                                shape = K.int_shape(w_img)\n",
    "                            w_img = tf.reshape(w_img, [1,\n",
    "                                                       shape[0],\n",
    "                                                       shape[1],\n",
    "                                                       1])\n",
    "                        elif len(shape) == 3:  # convnet case\n",
    "                            if K.image_data_format() == 'channels_last':\n",
    "                                # switch to channels_first to display\n",
    "                                # every kernel as a separate image\n",
    "                                w_img = tf.transpose(w_img, perm=[2, 0, 1])\n",
    "                                shape = K.int_shape(w_img)\n",
    "                            w_img = tf.reshape(w_img, [shape[0],\n",
    "                                                       shape[1],\n",
    "                                                       shape[2],\n",
    "                                                       1])\n",
    "                        elif len(shape) == 1:  # bias case\n",
    "                            w_img = tf.reshape(w_img, [1,\n",
    "                                                       shape[0],\n",
    "                                                       1,\n",
    "                                                       1])\n",
    "                        else:\n",
    "                            # not possible to handle 3D convnets etc.\n",
    "                            continue\n",
    "\n",
    "                        shape = K.int_shape(w_img)\n",
    "                        assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n",
    "                        tf.summary.image(mapped_weight_name, w_img)\n",
    "\n",
    "                if hasattr(layer, 'output'):\n",
    "                    tf.summary.histogram('{}_out'.format(layer.name),\n",
    "                                         layer.output)\n",
    "        self.merged = tf.summary.merge_all()\n",
    "\n",
    "        if self.write_graph:\n",
    "            self.writer = tf.summary.FileWriter(self.log_dir,\n",
    "                                                self.sess.graph)\n",
    "        else:\n",
    "            self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "\n",
    "        if self.embeddings_freq:\n",
    "            embeddings_layer_names = self.embeddings_layer_names\n",
    "\n",
    "            if not embeddings_layer_names:\n",
    "                embeddings_layer_names = [layer.name for layer in self.model.layers\n",
    "                                          if type(layer).__name__ == 'Embedding']\n",
    "\n",
    "            embeddings = {layer.name: layer.weights[0]\n",
    "                          for layer in self.model.layers\n",
    "                          if layer.name in embeddings_layer_names}\n",
    "\n",
    "            self.saver = tf.train.Saver(list(embeddings.values()))\n",
    "\n",
    "            embeddings_metadata = {}\n",
    "\n",
    "            if not isinstance(self.embeddings_metadata, str):\n",
    "                embeddings_metadata = self.embeddings_metadata\n",
    "            else:\n",
    "                embeddings_metadata = {layer_name: self.embeddings_metadata\n",
    "                                       for layer_name in embeddings.keys()}\n",
    "\n",
    "            config = projector.ProjectorConfig()\n",
    "            self.embeddings_ckpt_path = os.path.join(self.log_dir,\n",
    "                                                     'keras_embedding.ckpt')\n",
    "\n",
    "            for layer_name, tensor in embeddings.items():\n",
    "                embedding = config.embeddings.add()\n",
    "                embedding.tensor_name = tensor.name\n",
    "\n",
    "                if layer_name in embeddings_metadata:\n",
    "                    embedding.metadata_path = embeddings_metadata[layer_name]\n",
    "\n",
    "            projector.visualize_embeddings(self.writer, config)\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        # Fill in the `validation_data` property. Obviously this is specific to how your generator works.\n",
    "        # Below is an example that yields images and classification tags.\n",
    "        # After it's filled in, the regular on_epoch_end method has access to the validation_data.\n",
    "        X_val,y_val,w_val = None, None, None\n",
    "        for s in range(self.nb_steps):\n",
    "            X, y, w = self.batch_gen.__getitem__(s+1)\n",
    "            if X_val is None:\n",
    "                X_val = np.zeros((self.nb_steps * X.shape[0], *X.shape[1:]))\n",
    "                y_val = np.zeros((self.nb_steps * y.shape[0], *y.shape[1:]))\n",
    "                w_val = np.zeros((self.nb_steps * w.shape[0]))\n",
    "            X_val[s * X.shape[0]:(s + 1) * X.shape[0]] = X\n",
    "            y_val[s * y.shape[0]:(s + 1) * y.shape[0]] = y\n",
    "            w_val[s * w.shape[0]:(s + 1) * w.shape[0]] = w\n",
    "        self.validation_data = (X_val,y_val,w_val,0)\n",
    "        print(self.validation_data[1])\n",
    "        return super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 768)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5bbedc68b61e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSingleLegModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rnn Model Retrieved\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0c7652076c10>\u001b[0m in \u001b[0;36mgetSingleLegModel\u001b[0;34m(lstm_dim)\u001b[0m\n\u001b[1;32m     94\u001b[0m               \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 return_sequences=True)(sequenced_model)\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;31m#Finally, 1 dense layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     out = Dense(1,activation='sigmoid',use_bias=False,\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# modify the input spec to include the state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1903\u001b[0m                                       \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                                       \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m                                       initial_state=initial_state)\n\u001b[0m\u001b[1;32m   1906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    536\u001b[0m                                              \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m                                              input_length=timesteps)\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2535\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2536\u001b[0m         output_ta = tensor_array_ops.TensorArray(\n\u001b[1;32m   2537\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 \u001b[0minputs_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 \u001b[0minputs_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1707\u001b[0;31m             \u001b[0mx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m             \u001b[0mx_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_f\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m             \u001b[0mx_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                          as_ref=False):\n\u001b[1;32m    120\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/anaconda3/envs/DHSenv_3.5/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    362\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "rnn_model = getSingleLegModel()\n",
    "print(\"Rnn Model Retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_3 False (None, 16, 400, 360, 1)\n",
      "time_distributed_1 True (None, 16, 768)\n",
      "gru_1 True (None, 50)\n",
      "dense_1 True (None, 1)\n"
     ]
    }
   ],
   "source": [
    "for l in rnn_model.layers:\n",
    "    print(l.name, l.trainable,l.output_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing generators...\n",
      "Beginning training...\n",
      "Epoch 1/500\n",
      " 40/178 [=====>........................] - ETA: 1255s - loss: 5.6595 - binary_accuracy: 0.6450"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "description = \"Average_layer5\"\n",
    "#adad = Adadelta()\n",
    "#print(\"Loading weights\")\n",
    "#rnn_model.load_weights(\"check_points/TestAverageModel_03-0.63.hdf5\")\n",
    "adam = Adam(lr=0.001,beta_1=0.9,beta_2=0.999)\n",
    "#sgd = SGD(lr = 0.0001,momentum = 0.25,nesterov=True)\n",
    "rnn_model.compile(optimizer=adam,\n",
    "                          metrics=[binary_accuracy],\n",
    "                         loss= binary_crossentropy,)\n",
    "\n",
    "\n",
    "#Model checkpoint\n",
    "x = datetime.today()\n",
    "check_point_dir = 'check_points/'\n",
    "if not os.path.isdir(check_point_dir):\n",
    "    os.makedirs(check_point_dir)    \n",
    "chkpt = ModelCheckpoint(os.path.join(check_point_dir,\"TestAverageModel_{epoch:02d}-{val_loss:.2f}.hdf5\"),\n",
    "                       monitor='val_loss',\n",
    "                       verbose=1,\n",
    "                       save_best_only=True)\n",
    "#Reduce learning rate on plateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                             factor=0.2,\n",
    "                             patience=2,\n",
    "                             verbose=1,\n",
    "                             min_lr=0.00001,\n",
    "                             cooldown = 10)\n",
    "#Notifications\n",
    "notify = SMSNotifier()\n",
    "\n",
    "#Early stopping callback\n",
    "estop = EarlyStopping(monitor='val_loss',min_delta=0.001,patience=25)\n",
    "\n",
    "#Generators and fit\n",
    "print(\"Initializing generators...\")\n",
    "#Bucket with clean data\n",
    "UPLOAD_BUCKET = 'cleandhsdata' #bucket where clean data was stored\n",
    "key_id, secret_key = hfuncs.GetAWSCredentials()\n",
    "client = hfuncs.GetAWSClient(key_id,secret_key)\n",
    "bucket = client.Bucket(UPLOAD_BUCKET)\n",
    "\n",
    "#Initialize train sequencer\n",
    "mode =\"train_scan\"\n",
    "num_batches_train = (sum([1 if \"{}/\".format(mode) in k.key else 0 for k in bucket.objects.all()])-1)//BATCH_SIZE #train,test,val root directories have their own keys\n",
    "#num_batches = 660//BATCH_SIZE\n",
    "train_seq = LegScanSequencer(num_batches_train,UPLOAD_BUCKET,mode=mode)\n",
    "#Initialize validation sequencer\n",
    "mode = \"val_scan\"\n",
    "num_batches_val = (sum([1 if \"{}/\".format(mode) in k.key else 0 for k in bucket.objects.all()])-1)//BATCH_SIZE #train,test,val root directories have their own keys\n",
    "val_seq = LegScanSequencer(num_batches_val,UPLOAD_BUCKET,mode=mode)\n",
    "\n",
    "#Tensorboard\n",
    "stamp = \"FullModelTestAverage_layer5_0.01_v1\"\n",
    "tensorboard = TensorBoardWrapper(val_seq,nb_steps=1,layer_ary=[-1],\n",
    "                                 log_dir=\"logs/{}\".format(stamp),\n",
    "                                 histogram_freq=1,\n",
    "                                 batch_size=2,#Must be greater than 1 for it to run\n",
    "                              write_grads=True,\n",
    "                                 write_images=False)\n",
    "\n",
    "print(\"Beginning training...\")\n",
    "#recurrent_model.load_weights('check_points/2017_10_3_17_ScanModel_01-1.29.hdf5')\n",
    "\n",
    "hist= rnn_model.fit_generator(train_seq,\n",
    "                                   steps_per_epoch = num_batches_train*2,\n",
    "                                   epochs = 500,\n",
    "                                   validation_data = val_seq,\n",
    "                                    validation_steps = num_batches_val,\n",
    "                                   callbacks=[chkpt,tensorboard,estop,reduce_lr],\n",
    "                                  use_multiprocessing = True,workers=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 16, 400, 360, 1)\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]] [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#Bucket with clean data\n",
    "UPLOAD_BUCKET = 'cleandhsdata' #bucket where clean data was stored\n",
    "key_id, secret_key = hfuncs.GetAWSCredentials()\n",
    "client = hfuncs.GetAWSClient(key_id,secret_key)\n",
    "bucket = client.Bucket(UPLOAD_BUCKET)\n",
    "\n",
    "#Initialize train sequencer\n",
    "mode =\"train_scan\"\n",
    "num_batches_train = 25 #(sum([1 if \"{}/\".format(mode) in k.key else 0 for k in bucket.objects.all()])-1)//BATCH_SIZE #train,test,val root directories have their own keys\n",
    "#num_batches = 660//BATCH_SIZE\n",
    "train_seq = LegScanSequencer(num_batches_train,UPLOAD_BUCKET,mode=mode)\n",
    "X,y,w =train_seq.__getitem__(14)\n",
    "print(X.shape)\n",
    "print(y,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "img = load_img('individualImage.png',grayscale=False,target_size=(FINAL_WIDTH,FINAL_HEIGHT*3//5))\n",
    "img_ary = np.array([img_to_array(img)])\n",
    "print(img_ary.shape)\n",
    "fig = plt.figure(figsize = (16,16))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img_ary[0])#, cmap = 'viridis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(img_ary.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test modelchanges\n",
    "sess = tf.InteractiveSession()\n",
    "slm = getSingleLegModel(16)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50808924]\n",
      " [ 0.50716865]\n",
      " [ 0.50631207]\n",
      " [ 0.50819927]\n",
      " [ 0.50655884]\n",
      " [ 0.50680494]\n",
      " [ 0.50691116]\n",
      " [ 0.50672114]\n",
      " [ 0.50663632]\n",
      " [ 0.50650519]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "result = rnn_model.predict(X)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,16))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(result[0,1,:,:,:])#, cmap = 'viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test how many positive samples\n",
    "import pickle\n",
    "labels = hfuncs.GetLabelsDict(r'stage1_labels.csv')\n",
    "#filename = \"data_separated.pickle\"\n",
    "#with open(filename,\"rb\") as f:\n",
    "#   save = pickle.load(f)\n",
    "#   K_test= save['K_test']\n",
    "#   K_val = save['K_val']\n",
    "#   K_train = save['K_train']\n",
    "#s = 0\n",
    "#pos = 0\n",
    "s= 0\n",
    "pos = 0\n",
    "for k_clean in labels.keys():\n",
    "    label = np.array(labels[k_clean])\n",
    "    val = np.amax(label[[7,8,9,10,11,12,13,14,15]])\n",
    "    if val == 1:\n",
    "        s += 1\n",
    "        pos += 1\n",
    "    else:\n",
    "        s += 1\n",
    "print(\"total={},pos={}\".format(s,pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "710/1147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DHSenv_3.5]",
   "language": "python",
   "name": "conda-env-DHSenv_3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
